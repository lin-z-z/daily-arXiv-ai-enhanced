<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)
*Shuide Wen,Yu Sun,Beier Ku,Zhi Gao,Lijun Ma,Yang Yang,Can Jiao*

Main category: cs.AI

TL;DR: 本研究提出了一种基于多模态大语言模型(MLLM)和多智能体协作框架的房树人(HTP)绘画测试自动化解释系统,通过角色分工将特征识别与心理推断解耦,实现了与人类专家解释约0.75-0.85的语义相似度,为投射测验的标准化和数字心理健康服务提供了新范式。


<details>
  <summary>Details</summary>
Motivation: 房树人绘画测试作为临床心理学中广泛使用的投射技术,长期面临评分标准不统一、依赖评估者主观经验、缺乏统一量化编码系统等挑战。研究旨在利用多模态大语言模型技术解决这些问题,建立标准化的投射评估工具,减少主观性并提高评估的一致性和可靠性。

Method: 研究采用多模态大语言模型(MLLM)结合多智能体协作框架的方法。通过角色分工机制将特征识别与心理推断解耦,整合社会心理学视角和去污名化叙事策略,纠正视觉幻觉问题。使用余弦相似度(cosine similarity)量化评估模型解释与人类专家解释之间的语义相似性,并在结构化专家数据集上进行验证。

Result: 定量实验显示,多模态大语言模型解释与人类专家解释之间的平均语义相似度约为0.75(标准差约0.05)。在结构化导向的专家数据集中,相似度提升至0.85,达到专家级基线理解水平。定性分析表明,多智能体系统能够有效纠正视觉幻觉,生成具有高生态效度和内部一致性的心理报告。

Conclusion: 研究证实了多模态大语言模型作为投射评估标准化工具的潜力。所提出的多智能体框架通过角色分工实现了特征识别与心理推断的解耦,为数字心理健康服务提供了新的范式。该方法有望解决传统房树人测试中存在的主观性和标准化问题,推动计算心理学和人工智能在临床心理评估领域的应用。

Abstract: Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unified quantitative coding system.
  Results: Quantitative experiments showed that the mean semantic similarity between Multimodal Large Language Model (MLLM) interpretations and human expert interpretations was approximately 0.75 (standard deviation about 0.05). In structurally oriented expert data sets, this similarity rose to 0.85, indicating expert-level baseline comprehension. Qualitative analyses demonstrated that the multi-agent system, by integrating social-psychological perspectives and destigmatizing narratives, effectively corrected visual hallucinations and produced psychological reports with high ecological validity and internal coherence.
  Conclusions: The findings confirm the potential of multimodal large models as standardized tools for projective assessment. The proposed multi-agent framework, by dividing roles, decouples feature recognition from psychological inference and offers a new paradigm for digital mental-health services.
  Keywords: House-Tree-Person test; multimodal large language model; multi-agent collaboration; cosine similarity; computational psychology; artificial intelligence

</details>


### [2] [A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers](https://arxiv.org/abs/2512.21365)
*Chung-Chin Shih,Ti-Rong Wu,Ting Han Wei,Yu-Shan Hsu,Hung Guei,I-Chen Wu*

Main category: cs.AI

TL;DR: 本文分析了当前最先进的计算机围棋求解器在解决围棋死活问题时的行为,使用相关区域搜索(RZS)和相关区域模式表两种技术,通过对著名死活题集的测试发现了求解器的优势和局限性。


<details>
  <summary>Details</summary>
Motivation: 研究当前最先进的计算机围棋求解器在处理围棋死活问题时的表现,特别是基于相关区域的搜索技术的有效性和局限性。通过分析求解器在经典死活题上的解答,了解其与人类棋手思维方式的差异,为未来改进提供方向。

Method: 使用相关区域搜索(RZS)和相关区域模式表两种技术,对来自围棋大师赵治勋所著《死活辞典》中的七个死活问题进行求解和分析。通过对比求解器的解答与标准答案,研究求解器识别的相关区域、发现的模式以及解题策略。

Result: 研究发现:(1)求解器能够为每个问题识别出突出关键区域的相关区域;(2)求解器发现了一系列模式,包括一些罕见模式;(3)在两个问题上,求解器找到了与给定标准答案不同的解法。同时也发现了两个问题:(a)求解器对罕见模式的价值判断存在偏差;(b)求解器倾向于优先考虑做活而非最大化地盘,这与人类棋手的行为不同。

Conclusion: 基于相关区域的围棋死活求解器在识别关键区域和发现模式方面表现出色,甚至能找到与标准答案不同的解法。但存在对罕见模式价值判断不准确以及优先策略与人类棋手不同的问题。研究提出了未来改进这些问题的可能方法,为计算机围棋求解器的进一步发展提供了方向。

Abstract: This paper analyzes the behavior of solving Life-and-Death (L&D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We examined the solutions derived by relevance-zone based solvers on seven L&D problems from the renowned book "Life and Death Dictionary" written by Cho Chikun, a Go grandmaster, and found several interesting results. First, for each problem, the solvers identify a relevance-zone that highlights the critical areas for solving. Second, the solvers discover a series of patterns, including some that are rare. Finally, the solvers even find different answers compared to the given solutions for two problems. We also identified two issues with the solver: (a) it misjudges values of rare patterns, and (b) it tends to prioritize living directly rather than maximizing territory, which differs from the behavior of human Go players. We suggest possible approaches to address these issues in future work. Our code and data are available at https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ.

</details>


### [3] [Three-way decision with incomplete information based on similarity and satisfiability](https://arxiv.org/abs/2512.21421)
*Junfang Luo,Mengjun Hu,Keyun Qin*

Main category: cs.AI

TL;DR: 本文将三路决策理论从完全信息扩展到不完全信息场景,提出了基于相似度的计算公式化方法和基于满足度的概念公式化方法,为处理实际应用中的不完全信息提供了新的理论框架。


<details>
  <summary>Details</summary>
Motivation: 现有的三路决策与粗糙集理论主要针对完全信息进行处理,包括基于等价关系的计算公式化和基于逻辑公式可满足性的概念公式化两种方法。然而,实际应用中更常遇到不完全信息的情况,因此需要将这两种公式化方法推广到不完全信息场景,以提高三路决策理论的实用性。

Method: 针对计算公式化方法,提出了对象相似度度量作为等价关系的推广,并基于此讨论了使用alpha-相似类和对象可近似性的两种三路决策方法。针对概念公式化方法,提出了公式满足度度量作为完全信息下可满足性的量化推广,并基于此研究了使用公式的alpha-意义集和公式置信度的两种三路决策方法。

Result: 成功将三路决策的两种互补公式化方法推广到不完全信息场景。在计算公式化中,相似类方法是文献中处理不完全信息的常用方法,而提出的可近似性概念提供了新的分析视角。在概念公式化中,提出的两种方法为处理不完全信息指出了新的有前景的研究方向。

Conclusion: 本文通过引入相似度和满足度度量,成功地将三路决策理论从完全信息推广到不完全信息场景,提出了四种新的三路决策方法。特别是可近似性概念和概念公式化中的两种方法为该领域开辟了新的研究方向,使三路决策理论更适用于实际应用中的不完全信息处理问题。

Abstract: Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a briefly review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using alpha-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using alpha-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.

</details>


### [4] [LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis](https://arxiv.org/abs/2512.21482)
*Fanwei Zeng,Changtao Miao,Jing Huang,Zhiya Tan,Shutao Gong,Xiaoming Yu,Yang Wang,Huazhe Tan,Weibin Yao,Jianshu Li*

Main category: cs.AI

TL;DR: 本文提出LogicLens框架,通过视觉-文本协同推理统一处理文本中心伪造检测、定位和解释任务,引入跨线索感知思维链(CCT)机制和PR²多智能体标注系统,构建了包含5,397张图像的RealText数据集,在多个基准测试中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前AIGC技术快速发展导致复杂的文本中心伪造威胁社会安全和信息真实性,现有方法局限于粗粒度视觉分析,缺乏复杂推理能力,且将检测、定位和解释作为独立子任务处理,忽视了它们之间的内在关系,无法实现整体性能提升。

Method: 提出LogicLens统一框架,将检测、定位和解释重构为联合任务;设计跨线索感知思维链(CCT)机制,迭代交叉验证视觉线索与文本逻辑;采用基于GRPO优化的加权多任务奖励函数确保任务对齐;构建PR²(感知者-推理者-审查者)分层迭代多智能体标注系统;创建包含5,397张图像的RealText数据集,提供细粒度标注(文本解释、像素级分割、真实性标签)。

Result: 在T-IC13零样本评估中,宏平均F1分数超越专用框架41.4%,超越GPT-4o 23.4%;在密集文本T-SROIE数据集上,在mF1、CSS和宏平均F1指标上显著领先其他基于MLLM的方法;在多个基准测试中展现出优越性能。

Conclusion: LogicLens通过视觉-文本协同推理和跨线索感知思维链机制,成功统一了文本中心伪造的检测、定位和解释任务,显著提升了对复杂文本伪造的分析能力。PR²标注系统和RealText数据集为该领域提供了高质量训练资源,实验结果证明该框架在多个基准测试中达到最先进性能,为应对AIGC时代的信息安全挑战提供了有效解决方案。

Abstract: Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.

</details>


### [5] [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)
*Yanhao Li,Lu Ma,Jiaran Zhang,Lexiang Tang,Wentao Zhang,Guibo Luo*

Main category: cs.AI

TL;DR: 本文提出了Leash框架,一种基于强化学习的自适应长度惩罚方法,通过拉格朗日对偶优化动态调整惩罚系数,在保持模型推理性能的同时将平均推理长度减少60%,实现了大语言模型推理效率与准确性的有效平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定长度惩罚,难以调优且无法适应大语言模型不断演进的推理能力,导致准确性和简洁性之间的权衡不理想。需要一种能够动态适应模型推理能力、在保证任务性能的同时实现简洁推理的自适应机制。

Method: 提出Leash(自适应长度惩罚和奖励塑形)框架,将长度控制建模为约束优化问题,采用拉格朗日原始-对偶方法动态调整惩罚系数。当生成内容超过目标长度时增强惩罚,当内容较短时放松惩罚,通过这种自适应机制引导模型产生简洁推理。

Result: 在Deepseek-R1-Distill-Qwen-1.5B和Qwen3-4B-Thinking-2507模型上的实验表明,Leash在多样化任务(包括分布内数学推理和分布外的编码、指令遵循等领域)中将平均推理长度减少了60%,同时保持了竞争力的性能表现。

Conclusion: 本研究提出了一种实用且有效的范式,用于开发可控且高效的大语言模型,成功平衡了推理能力与计算预算。Leash框架通过自适应长度控制机制,解决了固定惩罚方法的局限性,为构建高效推理的LLM提供了新的解决方案。

Abstract: Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise reasoning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen-1.5B and Qwen3-4B-Thinking-2507 show that Leash reduces the average reasoning length by 60% across diverse tasks - including in-distribution mathematical reasoning and out-of-distribution domains such as coding and instruction following - while maintaining competitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational budgets.

</details>


### [6] [A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning](https://arxiv.org/abs/2512.21583)
*Zelin Zang,Wenyi Gu,Siqi Ma,Dan Yang,Yue Shen,Zhu Zhang,Guohui Fan,Wing-Kuen Ling,Fuji Yang*

Main category: cs.AI

TL;DR: 本文提出了一个基于LLaVA的医学诊断框架,通过视觉-语言对齐和逻辑正则化推理来解决现有多模态医学模型产生幻觉和推理不一致的问题,在多个基准测试中提升了诊断准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学领域大语言模型和视觉-语言模型虽然快速发展,但简单整合临床文本和医学影像并不能保证可靠的推理。现有多模态模型经常产生幻觉或不一致的思维链,限制了临床信任度。因此需要开发一个能够提供可靠、可解释推理的医学诊断框架。

Method: 提出了一个基于LLaVA构建的诊断框架,结合视觉-语言对齐和逻辑正则化推理。系统包含四个核心组件:1)用于文本和图像的输入编码器;2)用于跨模态对齐的投影模块;3)将诊断任务分解为步骤的推理控制器;4)将逐步前提组装成可验证结论的逻辑树生成器。

Result: 在MedXpertQA等基准测试上的评估显示,该方法提高了诊断准确性,在多模态任务上产生了更具可解释性的推理轨迹,同时在纯文本设置上保持了竞争力。

Conclusion: 研究结果表明,该框架通过结合视觉-语言对齐和逻辑正则化推理,朝着构建可信赖的多模态医学AI迈出了有希望的一步,为提升医学诊断系统的准确性和可解释性提供了新的解决方案。

Abstract: With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.

</details>


### [7] [Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design](https://arxiv.org/abs/2512.21623)
*Takahide Suzuki,Kazuki Nakanishi,Takashi Fujiwara,Hideyuki Shimizu*

Main category: cs.AI

TL;DR: 本文介绍了OrchestRA,一个人机协作的多智能体平台,通过整合生物学、化学和药理学领域,将药物发现从随机搜索转变为可编程的循环优化过程,实现了从靶点识别、分子设计到药代动力学评估的自主化治疗药物发现。


<details>
  <summary>Details</summary>
Motivation: 当前治疗药物发现面临专业领域碎片化和计算设计与生理验证之间执行鸿沟的挑战。现有生成式AI模型往往只是被动助手而非自主执行者,无法有效整合生物学、化学和药理学知识进行端到端的药物发现。需要一个能够自主执行模拟、推理结果并驱动迭代优化的智能平台。

Method: 构建了OrchestRA多智能体平台,包含三个核心智能体:1)生物学家智能体利用超过1000万关联的大规模知识图谱进行深度推理以识别高置信度靶点;2)化学家智能体自主检测结构口袋进行从头设计或药物重定位;3)药理学家智能体通过基于生理的药代动力学(PBPK)模拟评估候选药物。由协调器统一管理,建立药代动力学和毒性特征直接触发结构再优化的动态反馈循环,实现人机协作的迭代优化。

Result: OrchestRA成功将生物学、化学和药理学统一为自主发现引擎,智能体能够主动执行模拟并推理结果驱动优化。系统建立了从靶点识别到分子设计再到药代动力学评估的完整闭环,通过动态反馈实现结构的迭代优化,将人类指导与自主执行无缝整合。

Conclusion: OrchestRA平台通过多智能体协作和人机交互,成功将药物发现从随机搜索过程转变为可编程的、基于证据的工程学科,使治疗药物设计民主化,为解决药物发现中的领域碎片化和执行鸿沟问题提供了创新解决方案。

Abstract: Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.

</details>


### [8] [Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing](https://arxiv.org/abs/2512.21626)
*Hong Xie,Haoran Gu,Yanying Huang,Tao Tan,Defu Lian*

Main category: cs.AI

TL;DR: 本文针对大语言模型应用和边缘智能等资源分配问题,提出了一种多臂赌博机的变体模型。该模型基于优先级权重的资源共享机制,设计了离线优化算法和在线学习算法,并证明了regret上下界的匹配性。


<details>
  <summary>Details</summary>
Motivation: 现有的多臂赌博机模型无法很好地处理LLM应用、边缘智能等场景中的资源分配问题。这些场景中存在多个竞争者(plays)需要共享有限的资源容量(arm capacity),且不同竞争者具有不同的优先级权重。需要设计一种新的模型和算法来处理这种带优先级的资源共享机制下的在线学习问题。

Method: 1) 建立了包含M个臂和K个plays的随机赌博机模型,每个臂具有随机容量,每个play具有优先级权重,资源按优先级分配;2) 设计了离线优化算法MSB-PRS-OffOpt,在已知模型参数时以O(MK^3)复杂度找到最优策略;3) 基于MSB-PRS-OffOpt作为子程序,设计了近似UCB(上置信界)算法用于在线学习;4) 针对优先级资源共享机制引入的非线性组合效用函数,解决了优化和学习中的技术挑战。

Result: 证明了实例无关的regret下界为Ω(α₁σ√(KMT)),实例相关的regret下界为Ω(α₁σ²M/Δ·lnT)。设计的UCB算法达到了与下界相匹配的上界,实例无关情况下相差√(KlnKT)因子,实例相关情况下相差α₁K²因子。离线优化算法MSB-PRS-OffOpt的计算复杂度为O(MK³)。

Conclusion: 本文成功将多臂赌博机框架扩展到带优先级的资源共享场景,为LLM应用和边缘智能等实际问题提供了理论基础和算法支持。通过设计高效的离线优化算法和在线学习算法,实现了接近理论下界的性能保证,解决了优先级资源分配机制带来的非线性组合优化挑战。

Abstract: This paper proposes a variant of multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, edge intelligence, etc. The model is composed of $M$ arms and $K$ plays. Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function. Each play is associated with a priority weight. When multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first manner. Instance independent and instance dependent regret lower bounds of $Ω( α_1 σ\sqrt{KM T} )$ and $Ω(α_1 σ^2 \frac{M}Δ \ln T)$ are proved, where $α_1$ is the largest priority weight and $σ$ characterizes the reward tail. When model parameters are given, we design an algorithm named \texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(MK^3)$. Utilizing \texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $ \sqrt{K \ln KT }$ and $α_1 K^2$ respectively. To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.

</details>


### [9] [Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning](https://arxiv.org/abs/2512.21699)
*Eranga Bandara,Tharaka Hewa,Ross Gore,Sachin Shetty,Ravi Mukkamala,Peter Foytik,Abdul Rahman,Safdar H. Bouk,Xueping Liang,Amin Hass,Sachini Rajapakse,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.AI

TL;DR: 本文提出了一种基于多模型共识和推理层治理的负责任(RAI)和可解释(XAI)的AI智能体架构,通过异构LLM和VLM智能体联盟独立生成候选输出,并由专门的推理智能体进行结构化整合,以提高自主AI系统的鲁棒性、透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 当前的智能体AI系统虽然功能强大且可扩展,但在自主性增强的同时,面临可解释性、问责制、鲁棒性和治理方面的关键挑战。现有实现往往缺乏理解决策原理或在智能体交互中强制执行责任的有效机制,特别是当智能体输出影响下游行动或决策时,这些问题变得更加突出。

Method: 提出了一种基于多模型共识和推理层治理的生产级智能体工作流架构。该架构由异构LLM和VLM智能体联盟组成,从共享输入上下文中独立生成候选输出,明确暴露不确定性、分歧和替代解释。专门的推理智能体对这些输出进行结构化整合,执行安全和策略约束,减轻幻觉和偏见,并生成可审计的、有证据支持的决策。通过显式的跨模型比较和保留的中间输出实现可解释性,通过集中式推理层控制和智能体级约束强制执行责任。

Result: 在多个真实世界的智能体AI工作流中进行评估,结果表明共识驱动的推理方法在不同应用领域中提高了系统的鲁棒性、透明度和操作信任度。该架构成功实现了既自主可扩展,又具有内在责任性和可解释性的智能体AI系统。

Conclusion: 本研究为设计生产级智能体AI系统提供了实用指导,证明了通过多模型共识和推理层治理机制,可以构建既具有自主性和可扩展性,又天然具备责任性和可解释性的智能体系统。这种架构设计为解决自主AI系统在实际应用中的关键挑战提供了有效方案。

Abstract: Agentic AI represents a major shift in how autonomous systems reason, plan, and execute multi-step tasks through the coordination of Large Language Models (LLMs), Vision Language Models (VLMs), tools, and external services. While these systems enable powerful new capabilities, increasing autonomy introduces critical challenges related to explainability, accountability, robustness, and governance, especially when agent outputs influence downstream actions or decisions. Existing agentic AI implementations often emphasize functionality and scalability, yet provide limited mechanisms for understanding decision rationale or enforcing responsibility across agent interactions. This paper presents a Responsible(RAI) and Explainable(XAI) AI Agent Architecture for production-grade agentic workflows based on multi-model consensus and reasoning-layer governance. In the proposed design, a consortium of heterogeneous LLM and VLM agents independently generates candidate outputs from a shared input context, explicitly exposing uncertainty, disagreement, and alternative interpretations. A dedicated reasoning agent then performs structured consolidation across these outputs, enforcing safety and policy constraints, mitigating hallucinations and bias, and producing auditable, evidence-backed decisions. Explainability is achieved through explicit cross-model comparison and preserved intermediate outputs, while responsibility is enforced through centralized reasoning-layer control and agent-level constraints. We evaluate the architecture across multiple real-world agentic AI workflows, demonstrating that consensus-driven reasoning improves robustness, transparency, and operational trust across diverse application domains. This work provides practical guidance for designing agentic AI systems that are autonomous and scalable, yet responsible and explainable by construction.

</details>


### [10] [Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets](https://arxiv.org/abs/2512.21775)
*Matyas Bohacek,Ignacio Vilanova Echavarri*

Main category: cs.AI

TL;DR: 本文针对生成式人工智能数据集构建中的伦理和法律问题,提出了合规评级方案(CRS)框架,用于评估数据集在透明度、问责制和安全性方面的合规性,并发布了基于数据溯源技术的开源Python库来实现该框架。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的快速发展依赖于大规模开源数据集,但这些数据集的构建往往采用不受限制且不透明的数据收集方式。现有文献主要关注GAI模型的开发和应用,而忽视了数据集创建过程中的伦理和法律考量。此外,随着数据集在线共享、编辑和复制,其来源、合法性和安全性信息经常丢失,亟需建立评估和规范机制。

Method: 提出了合规评级方案(CRS)框架,用于评估数据集在透明度、问责制和安全性等关键原则方面的合规性。开发了基于数据溯源技术的开源Python库来实现该框架,可无缝集成到现有的数据集处理和AI训练流程中。该库具有反应性和主动性双重功能,既能评估现有数据集的CRS评级,也能指导负责任地抓取和构建新数据集。

Result: 成功构建了CRS评估框架和配套的开源Python库,该库能够实现数据集合规性的自动化评估,并可集成到现有AI开发流程中。该工具既可用于评估已有数据集的合规性,也可用于指导新数据集的负责任构建。

Conclusion: 本研究通过引入CRS框架和开源工具,填补了生成式AI数据集伦理和法律评估的空白,为数据集的透明度、问责制和安全性提供了可操作的评估标准和实施工具,有助于促进AI领域更负责任的数据实践和数据集构建。

Abstract: Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.

</details>


### [11] [SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?](https://arxiv.org/abs/2512.21907)
*Kenny Workman,Zhen Yang,Harihara Muralidharan,Hannah Le*

Main category: cs.AI

TL;DR: 本文介绍了SpatialBench，一个包含146个可验证问题的基准测试集，用于评估前沿AI模型在空间转录组学数据分析中的生物学洞察提取能力。测试结果显示当前模型准确率较低（20-38%），且性能受任务类型、平台和工具设计等多因素影响。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学技术规模和复杂性快速增长，计算分析成为生物学发现的主要瓶颈。尽管前沿AI在软件工程和数据分析方面表现出色，但其能否从真实、复杂的空间数据集中提取生物学洞察仍不明确，因此需要一个标准化的基准测试来评估和改进AI模型在这一领域的能力。

Method: 构建了SpatialBench基准测试集，包含146个可验证问题，涵盖5种空间技术和7个任务类别。每个问题提供分析步骤前的实验数据快照和确定性评分器来评估关键生物学结果的恢复情况。使用该基准测试评估多个前沿AI模型的表现，并分析模型-任务、模型-平台交互以及工具设计（提示、控制流、执行环境）对性能的影响。

Result: 前沿AI模型在基准测试中的基础准确率较低，不同模型家族的准确率在20-38%之间。研究发现存在显著的模型-任务和模型-平台交互效应。工具设计（包括工具选择、提示工程、控制流和执行环境）对性能有重大影响，表明这些因素应作为一级对象进行评估和优化。

Conclusion: SpatialBench既是一个测量工具，也是诊断性框架，可用于开发能够忠实、透明和可重复地处理真实空间数据集的AI智能体。当前前沿AI模型在空间转录组学分析中的表现仍有很大提升空间，需要在模型能力、工具设计和执行环境等多个维度进行改进，以实现更可靠的生物学发现自动化。

Abstract: Spatial transcriptomics assays are rapidly increasing in scale and complexity, making computational analysis a major bottleneck in biological discovery. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world spatial datasets. We introduce SpatialBench, a benchmark of 146 verifiable problems derived from practical spatial analysis workflows spanning five spatial technologies and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on frontier models shows that base model accuracy remains low (20-38% across model families), with strong model-task and model-platform interactions. Harness design has a large empirical effect on performance, indicating that tools, prompts, control flow, and execution environment should be evaluated and improved as first-class objects. SpatialBench serves both as a measurement tool and a diagnostic lens for developing agents that can interact with real spatial datasets faithfully, transparently, and reproducibly.

</details>

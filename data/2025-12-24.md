<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution](https://arxiv.org/abs/2512.19882)
*Mahdi Mostajabdaveh,F. Sibel Salman,Walter J. Gutjahr*

Main category: cs.AI

TL;DR: 本文提出了一个最小化不公平性（基尼指数）和旅行时间（效率）的双目标混合整数规划模型来解决灾后有限物资的分配和路径规划问题。通过开发分支定价算法，该方法在不牺牲效率的前提下，将分配不公平性降低了34%。


<details>
  <summary>Details</summary>
Motivation: 解决灾后人道主义物流中，在物资有限的情况下，如何规划车辆路径（从配送中心到避难所）并合理分配救援物资。目标是平衡配送的效率（及时性）和公平性（未满足需求的不公平性）。

Method: 建立了最小化未满足需求的不公平性（基于Gini指数）和最小化总旅行时间（效率）的双目标混合整数规划（MIP）模型。使用$\epsilon$-约束法处理双目标。通过推导数学性质引入了有效不等式，并设计了最优分配算法。最终开发了分支定价（B&P）算法来高效求解。

Result: 分支定价（B&P）算法在现实数据集上显著优于商业MIP求解器。双目标方法能够在不牺牲效率的情况下，将援助分配的不公平性降低34%。研究发现，在时间约束极宽松或极紧张时，优先覆盖需求的词典序优化是有效的；而在中等限制的时间约束下，平衡的分配方法对于避免不公平结果至关重要。

Conclusion: 提出的双目标模型和分支定价算法有效解决了灾后物资分配中的公平性与效率权衡问题，并在实际应用中显著提升了分配的公平性，为中等时间限制下的灾后物流规划提供了重要指导。

Abstract: The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and equity, we formulate a bi-objective problem: minimizing a Gini-index-based measure of inequity in unsatisfied demand for fair distribution and minimizing total travel time for timely delivery. We propose a Mixed Integer Programming (MIP) model and use the $ε$-constraint method to handle the bi-objective nature. By deriving mathematical properties of the optimal solution, we introduce valid inequalities and design an algorithm for optimal delivery allocations given feasible vehicle routes. A branch-and-price (B&P) algorithm is developed to solve the problem efficiently. Computational tests on realistic datasets from a past earthquake in Van, Turkey, and predicted data for Istanbul's Kartal region show that the B&P algorithm significantly outperforms commercial MIP solvers. Our bi-objective approach reduces aid distribution inequity by 34% without compromising efficiency. Results indicate that when time constraints are very loose or tight, lexicographic optimization prioritizing demand coverage over fairness is effective. For moderately restrictive time constraints, a balanced approach is essential to avoid inequitable outcomes.

</details>


### [2] [Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs](https://arxiv.org/abs/2512.19937)
*Eric Yeh,John Cadigan,Ran Chen,Dick Crouch,Melinda Gervasio,Dayne Freitag*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high fidelity to drive simulations to test human behavioral hypotheses, exhibiting more nuance and range than the rule-based agents often employed in behavioral economics. One key area of interest is the effect of personality on decision making, but the requirement that a prompt must be created for every tested personality profile introduces experimental overhead and degrades replicability. To address this issue, we leverage interpolative decoding, representing each dimension of personality as a pair of opposed prompts and employing an interpolation parameter to simulate behavior along the dimension. We show that interpolative decoding reliably modulates scores along each of the Big Five dimensions. We then show how interpolative decoding causes LLMs to mimic human decision-making behavior in economic games, replicating results from human psychological research. Finally, we present preliminary results of our efforts to ``twin'' individual human players in a collaborative game through systematic search for points in interpolation space that cause the system to replicate actions taken by the human subject.

</details>


### [3] [Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification](https://arxiv.org/abs/2512.19957)
*Luciano Araujo Dourado Filho,Almir Moreira da Silva Neto,Rodrigo Pereira David,Rodrigo Tripodi Calumby*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test set images. To obtain these representations, the proposed method extracts features from training dataset images and create clusters, by applying K-Means, with $K$ equals to the number of classes in the dataset. The segmentation model is a customized narrow ViT, built by replacing the patch embedding layer with a frozen DinoV2, pre-trained on the training dataset for individual species classification. This model is trained to reconstruct the class prototypes of the training dataset from the test dataset images. We then use this model to obtain attention scores that enable to identify and localize areas of interest and consequently guide the classification process. The proposed approach enabled a domain-adaptation from multi-class identification with individual species, into multi-label classification from high-resolution vegetation plots. Our method achieved fifth place in the PlantCLEF 2025 challenge on the private leaderboard, with an F1 score of 0.33331. Besides that, in absolute terms our method scored 0.03 lower than the top-performing submission, suggesting that it may achieved competitive performance in the benchmark task. Our code is available at \href{https://github.com/ADAM-UEFS/PlantCLEF2025}{https://github.com/ADAM-UEFS/PlantCLEF2025}.

</details>


### [4] [FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification](https://arxiv.org/abs/2512.19960)
*Luciano Araujo Dourado Filho,Rodrigo Tripodi Calumby*

Main category: cs.AI

TL;DR: 针对细粒度视觉分类（FGVC）中高类内差异的问题，本文提出了一种新颖的方法。该方法通过对每个类别内部进行聚类分配伪标签，然后利用分层分类过程学习更细粒度的特征，从而减轻类内差异。在PlantNet300k数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 细粒度视觉分类（FGVC）任务中，高类内差异性（intra-class variability）会阻碍深度学习模型的学习过程，尤其当这些类别同时是样本不足（underrepresented）时。本文旨在通过学习细粒度特征来提高FGVC任务中的分类性能，从而减轻类内差异问题。

Method: 提出了一种通过对“类别内聚类分配”进行分类来学习细粒度特征的新方法。具体做法是：对每个类别单独应用聚类，以发现编码图像潜在相似度的伪标签。然后，将这些伪标签用于分层分类过程，从而学习更细粒度的视觉特征，有效解决类内差异问题。

Result: 在PlantNet300k数据集上进行了初步实验。即使方法中的某些组件尚未完全优化，本文提出的方法仍然在该数据集上实现了最先进的（state-of-the-art）性能。

Conclusion: 初步实验证明了该方法的有效性，并为未来的工作指明了几个关键点，以期找到更具决定性的证据并进一步优化方法组件。

Abstract: Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.

</details>


### [5] [S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test](https://arxiv.org/abs/2512.19992)
*Zhe Sun,Xueyuan Yang,Yujie Lu,Zhenliang Zhang*

Main category: cs.AI

TL;DR: 本文引入了S$^{3}$IT基准测试来评估具身智能体的社交智能，核心是一个3D环境中的座位排序任务，要求智能体整合物理和社交约束。评估结果显示，最先进的LLM在空间智能方面表现较差，但其文本冲突解决能力接近人类。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法未能充分测试具身智能体在现实环境中整合社交规范和物理限制的能力。现有方法要么只关注脱离实体的社交推理（如文本），要么只关注缺乏社交因素的物理任务，无法评估智能体在现实具身环境中权衡两类约束的能力。

Method: 提出了S$^{3}$IT（Spatially Situated Social Intelligence Test）基准测试，专注于评估具身社交智能。核心任务是要求智能体在一个3D环境中，为一群由LLM驱动、具有复杂人际关系和偏好的NPC安排座位的“座位排序任务”。该框架通过程序化生成场景，要求智能体通过主动对话获取偏好、自主探索环境，并进行多目标优化。

Result: 评估了最先进的LLM模型，发现它们在S$^{3}$IT任务上表现不佳，与人类基线存在明显差距。结果表明，LLM在空间智能方面存在缺陷，但在解决具有明确文本线索的冲突时，能达到接近人类的水平。

Conclusion: LLM在整合具身和社交约束方面仍有不足，尤其是在空间智能方面存在明显的缺陷。这强调了S$^{3}$IT作为评估具身社交智能整合能力的必要性，并指出了未来研究需弥补的差距。

Abstract: The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.

</details>


### [6] [Discovering Lie Groups with Flow Matching](https://arxiv.org/abs/2512.20043)
*Jung Yeon Park,Yuxuan Chen,Floor Eijkelboom,Jan-Willem van de Meent,Lawson L. S. Wong,Robin Walters*

Main category: cs.AI

TL;DR: 提出Lieflow，一种基于李群流匹配的方法，用于直接从数据中发现对称性，包括离散群（如反射）。该方法比现有工作更灵活，并引入了一种新颖的插值方案来解决“最后一刻收敛”的挑战。


<details>
  <summary>Details</summary>
Motivation: 对称性是理解物理系统和提高机器学习性能/样本效率的基础。然而，这两项应用都需要事先了解数据中潜在的对称性。

Method: 提出了\lieflow方法，通过在李群上进行流匹配（flow matching）来直接从数据中学习对称性。它将对称性发现表述为学习一个覆盖较大假设群的分布，以匹配数据中观察到的对称性。此外，为了应对目标模式的对称排列导致的“最后一刻收敛”问题，作者引入了一种新颖的流匹配插值方案。

Result: 在2D和3D点云上的实验成功地发现了离散群，包括通过复数域上的流匹配实现的反射。该方法展示了比先前工作更高的灵活性和更少的假设。

Conclusion: 本文成功地展示了通过李群上的流匹配（\lieflow）直接从数据中学习对称性的能力，包括离散群。该方法比现有方法更灵活，并通过引入新颖的插值方案解决了对称性发现中的关键训练挑战。

Abstract: Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.

</details>


### [7] [Learning Skills from Action-Free Videos](https://arxiv.org/abs/2512.20052)
*Hung-Chieh Fang,Kuo-Han Hung,Chu-Rong Chen,Po-Jung Chou,Chun-Kai Yang,Po-Chen Ko,Yu-Chiang Wang,Yueh-Hua Wu,Min-Hung Chen,Shao-Hua Sun*

Main category: cs.AI

TL;DR: 提出SOF（基于光流的技能抽象）框架，利用光流作为中间表示，从无动作视频中学习潜在技能空间。这使得模型能够同时实现高层规划并将视频习得的技能有效地转化为机器人动作，显著提高了多任务和长周期任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型虽然视觉预测效果好，但难以转化为低级动作。而潜在动作模型虽然能更好地对齐视频和动作，但缺乏高级规划能力，且通常只在单步级别操作。该研究旨在弥合视频学习和可执行的低级动作及高层规划之间的差距，以推动通用型机器人的发展。

Method: 提出了“基于光流的技能抽象”（SOF）框架。核心方法是利用**光流**作为中间表示，来学习一个潜在技能空间，该光流捕捉的运动信息与视频动态和机器人动作都对齐。通过在这个基于光流的潜在空间中学习技能，SOF能够实现对视频衍生技能的高级规划，并更容易地将这些技能转化为具体的动作。

Result: 实验结果表明，SOF方法在**多任务**和**长周期**（长距离）设置中持续提高了性能，成功展示了直接从原始视觉数据中获取和组合技能的能力。

Conclusion: 通过引入基于光流的中间表示来学习潜在技能，SOF成功弥合了视频动态与机器人低级动作及高层规划能力之间的鸿沟，为从无动作视频中学习通用机器人技能提供了有效的框架。

Abstract: Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.

</details>


### [8] [Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach](https://arxiv.org/abs/2512.20056)
*Hao Li,Fabian Deuser,Wenping Yin,Steffen Knoblauch,Wufan Zhao,Filip Biljecki,Yong Xue,Wei Huang*

Main category: cs.AI

TL;DR: 提出ProbGLC，一个概率跨视图地理定位方法，用于快速灾害响应。它结合了概率和确定性模型，提高了定位准确性（Acc@25km达0.97）和模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致极端天气和灾害更加频繁和强烈，快速有效的灾害响应至关重要。灾害响应中的关键挑战是快速准确地识别灾害地点，以便支持决策和资源分配。

Method: 提出了一种名为ProbGLC的概率跨视图地理定位方法（Probabilistic Cross-view Geolocalization approach）。ProbGLC将概率模型和确定性模型整合到一个统一框架中，旨在同时提高模型可解释性（通过不确定性量化）和实现最先进的地理定位性能。它能够处理多种灾害事件的跨视图地理定位，并提供概率分布和可定位性分数等独特特征。

Result: 在两个跨视图灾害数据集（MultiIAN和SAGAINDisaster）上进行了广泛实验。初步结果证实了ProbGLC具有优越的地理定位精度（Acc@1km为0.86，Acc@25km为0.97）以及良好的模型可解释性（通过概率分布和可定位性分数）。

Conclusion: 所提出的ProbGLC方法利用生成式跨视图方法，在促进位置感知方面具有巨大潜力，有助于实现更好、更快的灾害响应。

Abstract: As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC

</details>


### [9] [Scaling Reinforcement Learning for Content Moderation with Large Language Models](https://arxiv.org/abs/2512.20061)
*Hamed Firooz,Rui Liu,Yuchen Lu,Zhenyu Hou,Fangzhou Xiong,Xiaoyang Zhang,Changshu Jian,Zhicheng Zhu,Jiayuan Ma,Jacob Tao,Chaitali Gupta,Xiaochang Peng,Shike Mei,Hang Cui,Yang Qin,Shuo Tang,Jason Gaedtke,Arpit Mittal*

Main category: cs.AI

TL;DR: 本文系统研究了将强化学习（RL）用于LLM内容审核的扩展性，发现RL在处理复杂策略推理任务上表现出显著提升，且比监督微调（SFT）高出多达100倍的数据效率。其性能提升遵循S型曲线。


<details>
  <summary>Details</summary>
Motivation: 大规模内容审核是当前数字生态系统的主要挑战，需要持续评估数十亿用户和AI生成的内容。尽管LLM潜力巨大，但在标签稀疏、政策不断演变以及需要细致推理的实际场景中，如何将LLM训练到专家级精度是一个尚未充分探索的实际难题。

Method: 提出了一项关于强化学习（RL）应用于内容分类扩展性的全面实证研究。系统评估了多种RL训练方案和奖励塑造策略（包括可验证奖励和“LLM作为评判者”框架），旨在将通用语言模型转化为专业的、符合政策的分类器，并在三个真实的审核任务中进行了测试。

Result: RL的性能扩展表现出S型（sigmoid-like）行为，即性能随着训练数据、Rollouts和优化步骤的增加而平稳提升，随后逐渐饱和。RL在需要复杂政策驱动推理的任务上显著提高了性能。RL比监督微调（SFT）高出多达100倍的数据效率。

Conclusion: 强化学习（RL）是一种高度有效且数据高效的方法，用于将通用LLM转化为专业的、与政策对齐的内容分类器。这对于专家标注稀缺或成本高昂，且需要复杂推理的工业级审核系统尤其重要。

Abstract: Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.

</details>


### [10] [Reason2Decide: Rationale-Driven Multi-Task Learning](https://arxiv.org/abs/2512.20074)
*H M Quamran Hasan,Housam Khalifa Bashier,Jiayi Dai,Mi-Young Kim,Randy Goebel*

Main category: cs.AI

TL;DR: Reason2Decide是一个用于临床决策支持系统的两阶段训练框架，它利用计划采样解决了LLM中解释与预测不一致的问题（暴露偏差）。该方法在保持高准确性和理由保真度的同时，使用的模型比现有基础模型小40倍，并且可以有效地利用LLM生成的理由，降低了对人工标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）得到广泛应用，临床决策支持系统（CDSS）面临一个关键挑战：在实现高预测准确性的同时，生成的解释（理由）必须与预测结果一致。现有方法存在“暴露偏差”，导致解释与预测不一致。

Method: 提出 Reason2Decide，一个两阶段训练框架，旨在解决自解释中的关键挑战（包括暴露偏差和任务分离）。第一阶段（Stage-1）训练模型生成理由；第二阶段（Stage-2）联合训练标签预测和理由生成，并应用“计划采样”（scheduled sampling）机制，逐步从依赖真实标签转向依赖模型的预测结果进行条件化。

Result: 在三个医学数据集上进行评估（包括专有的分诊数据集和公共生物医学问答数据集）。Reason2Decide 在预测准确性（F1）和理由保真度（BERTScore, BLEU, LLM-as-a-Judge）方面优于其他微调基线和某些零样本LLMs。该方法对理由来源具有鲁棒性。值得注意的是，仅在第一阶段使用LLM生成的理由进行预训练，效果优异，降低了对人工标注的依赖。此外，该模型比现有基础模型小 40 倍，仍能实现性能提升。

Conclusion: Reason2Decide 框架通过两阶段训练和计划采样有效解决了临床决策支持系统中解释和预测不一致的问题（暴露偏差），显著提高了性能和理由保真度。由于模型尺寸大幅缩小（比现有基础模型小 40 倍），它使得可解释的临床推理能够在资源受限的环境中更易部署。

Abstract: Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.

</details>


### [11] [Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches](https://arxiv.org/abs/2512.20082)
*Chaithra,Kamesh Kadimisetty,Biju R Mohan*

Main category: cs.AI

TL;DR: 本文提出了一个自适应框架，将指令微调的大语言模型（LLaMA 3.2 3B）与实时市场反馈（次日股票收益）和PPO强化学习相结合，用于印度股市的情感分析，显著提升了模型的准确性和市场一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的金融情感分析工作未能考虑股票价格或市场反馈对情感分析的影响，限制了模型的实用性和市场感知能力。

Method: 该方法提出了一个自适应框架：1. 使用指令学习在SentiFin数据集上微调 LLaMA 3.2 3B 模型。2. 采用检索增强生成（RAG）管道，基于句子嵌入的余弦相似度动态选择多源上下文信息。3. 引入反馈驱动模块，通过比较预测情感与实际次日股票回报来调整信息源的可靠性。4. 整合了使用近端策略优化（PPO）训练的强化学习智能体，以根据情感与回报的一致性信号优化信息源的加权策略，实现跨时间数据的泛化。

Result: 在收集自2024年至2025年的NIFTY 50新闻头条数据集上进行的实验表明，所提出的系统在分类准确率、F1分数和市场匹配度上均显著优于基线模型和静态检索方法。

Conclusion: 结果验证了将指令微调的大语言模型（LLMs）、动态市场反馈和强化学习相结合，可以构建出强大且具备市场感知能力的金融情感模型，具有巨大的应用潜力。

Abstract: Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.

</details>


### [12] [MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization](https://arxiv.org/abs/2512.20135)
*Zhuo Yang,Yeyun chen,Jiaqing Xie,Ben Gao,Shuaike Shen,Wanhao Liu,Liujia Yang,Beilun Wang,Tianfan Fu,Yuqiang Li*

Main category: cs.AI

TL;DR: 提出了MolAct，一个用于分子编辑和优化的智能体强化学习框架（Agentic RL）。它采用两阶段训练，将分子设计视为多步、工具辅助的决策过程，并在编辑和优化任务中均超越了强大的基线模型。


<details>
  <summary>Details</summary>
Motivation: 分子编辑和优化是多步骤的问题，需要迭代地改进分子属性，同时必须确保分子的化学有效性和结构相似性。

Method: 引入了MolAct，这是一个智能体强化学习（Agentic RL）框架，将分子设计任务形式化为顺序的、工具引导的决策过程。该框架采用两阶段训练范式：首先训练编辑能力，然后重用已学到的编辑行为进行属性优化。MolAct是首个将分子设计形式化为智能体强化学习问题的研究，它使大型语言模型（LLM）智能体能够交错进行推理、工具使用和分子优化，通过多轮交互和化学工具（用于有效性、属性、相似性检查）的反馈来迭代地精炼编辑。

Result: 该框架实例化为MolEditAgent（分子编辑）和MolOptAgent（分子优化）两个模型家族。在分子编辑任务中，MolEditAgent-7B在添加、删除和替换编辑的有效率上表现优异（分别为100%, 95%, 98%），超越了包括DeepSeek-R1在内的强封闭式基线。在分子优化任务中，MolOptAgent-7B在LogP上超越了最佳的封闭式推理基线（如Claude 3.7），并在溶解度方面保持了竞争力。

Conclusion: 将分子设计视为一个多步骤、工具增强的过程，是实现可靠且可解释改进的关键。

Abstract: Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed "thinking" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open "thinking" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed "thinking" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.

</details>


### [13] [Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection](https://arxiv.org/abs/2512.20140)
*Xingyou Yin,Ceyao Zhang,Min Hu,Kai Chen*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.

</details>


### [14] [A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers](https://arxiv.org/abs/2512.20161)
*Dhivya Dharshini Kannan,Anupam Trivedi,Dipti Srinivasan*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Data centers account for significant global energy consumption and a carbon footprint. The recent increasing demand for edge computing and AI advancements drives the growth of data center storage capacity. Energy efficiency is a cost-effective way to combat climate change, cut energy costs, improve business competitiveness, and promote IT and environmental sustainability. Thus, optimizing data center energy management is the most important factor in the sustainability of the world. Power Usage Effectiveness (PUE) is used to represent the operational efficiency of the data center. Predicting PUE using Neural Networks provides an understanding of the effect of each feature on energy consumption, thus enabling targeted modifications of those key features to improve energy efficiency. In this paper, we have developed Bidirectional Gated Recurrent Unit (BiGRU) based PUE prediction model and compared the model performance with GRU. The data set comprises 52,560 samples with 117 features using EnergyPlus, simulating a DC in Singapore. Sets of the most relevant features are selected using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm for different parameter settings. These feature sets are used to find the optimal hyperparameter configuration and train the BiGRU model. The performance of the optimized BiGRU-based PUE prediction model is then compared with that of GRU using mean squared error (MSE), mean absolute error (MAE), and R-squared metrics.

</details>


### [15] [Concept Generalization in Humans and Large Language Models: Insights from the Number Game](https://arxiv.org/abs/2512.20162)
*Arghavan Bazigaran,Hansem Sohn*

Main category: cs.AI

TL;DR: 本文在“数字博弈”任务中比较了人类和LLM的概念泛化能力。结果显示，人类的泛化更灵活（规则与相似性结合）且是强大的少样本学习者，而LLM更依赖数学规则并需要更多样本才能泛化。


<details>
  <summary>Details</summary>
Motivation: 比较人类和大型语言模型（LLM）在概念推理任务（数字博弈）中的泛化能力，从而探究两者归纳偏见和推理策略的差异。

Method: 使用“数字博弈”概念推理任务，并采用贝叶斯模型作为分析框架，检验人类和LLM的归纳偏见和推理策略。

Result: 人类的泛化能力更加灵活，能够结合基于规则和基于相似性的概念，并且表现出强大的少样本泛化能力（甚至从单个示例中）。相比之下，LLM更依赖于数学规则，需要更多的样本才能进行泛化。贝叶斯模型对人类行为的捕捉优于对LLM行为的捕捉。

Conclusion: 人类和大型语言模型（LLM）在数学概念的推理和泛化方式上存在根本性的差异。

Abstract: We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.

</details>


### [16] [Offline Safe Policy Optimization From Heterogeneous Feedback](https://arxiv.org/abs/2512.20173)
*Ze Gong,Pradeep Varakantham,Akshat Kumar*

Main category: cs.AI

TL;DR: 本文针对离线基于偏好的强化学习（PbRL）在长时序连续控制任务中，因显式学习奖励和成本模型导致的误差积累问题，提出了 $	ext{PreSa}$ (偏好与安全对齐) 框架。$	ext{PreSa}$ 通过一个拉格朗日约束优化问题，直接从人类偏好和安全标签中学习安全策略，避免了传统安全RLHF对模型的需求，并在经验评估中显著超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 离线基于偏好的强化学习（PbRL）可以避免复杂的奖励工程。然而，在长时序连续控制任务中，传统的安全RLHF（先学习奖励和成本模型，再使用约束RL）方法中的模型误差会累积，严重损害策略的性能和安全性。

Method: 提出 $	ext{PreSa}$（偏好与安全对齐）方法。该方法(a) 引入一个框架，基于对智能体行为的奖励成对偏好以及轨迹片段的二元安全标签来直接学习策略，而非间接学习；(b) 将偏好学习模块与安全对齐结合，形成一个约束优化问题；(c) 在拉格朗日范式内求解该问题，直接学习奖励最大化的安全策略，从而避免了显式地学习奖励和成本模型，也无需使用约束强化学习。

Result: 经验评估在具有合成和真实人类反馈的连续控制任务上进行。结果显示，$	ext{PreSa}$ 成功地学习了具有高回报的安全策略，并且性能显著优于最先进的基线方法，甚至超越了使用真实奖励和成本信息的离线安全强化学习方法。

Conclusion: $	ext{PreSa}$ 框架通过创新的直接策略学习方式，有效地解决了传统安全RLHF在处理长时序连续控制任务时模型误差累积和性能下降的关键挑战，为离线基于偏好的安全强化学习提供了一个强大且优越的解决方案。

Abstract: Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.

</details>


### [17] [TongSIM: A General Platform for Simulating Intelligent Machines](https://arxiv.org/abs/2512.20206)
*Zhe Sun,Kunlun Wu,Chuanjian Fu,Zeming Song,Langyong Shi,Zihe Xue,Bohan Jing,Ying Yang,Xiaomeng Gao,Aijia Li,Tianyu Guo,Huiying Li,Xueyuan Yang,Rongkai Liu,Xinyi He,Yuxi Wang,Yue Li,Mingyuan Liu,Yujie Lu,Hongzhao Xie,Shiyun Zhao,Bo Dai,Wei Wang,Tao Yuan,Song-Chun Zhu,Yujia Peng,Zhenliang Zhang*

Main category: cs.AI

TL;DR: TongSIM是一个高保真、通用型的具身智能训练和评估平台，旨在解决现有具身AI模拟环境过于狭隘的问题。它提供多样化的室内场景和开放的室外城镇环境，支持从低级导航到高级人机协作的广泛研究，从而加速通用具身智能的发展。


<details>
  <summary>Details</summary>
Motivation: 随着AI发展，研究重点转向多模态大语言模型（MLLMs）和具身智能。具身智能需要通过现实模拟环境和物理交互进行训练。然而，大多数现有模拟平台设计狭隘，仅针对特定任务，缺乏一个能支持从低级导航到高级复合活动（如多智能体社交和人机协作）的通用、多功能训练环境。

Method: 引入TongSIM，一个高保真、通用型的具身智能体训练和评估平台。它提供超过100个多样的室内场景以及一个开放、交互丰富的室外城镇模拟，确保广泛的适用性。TongSIM具备定制化场景、任务自适应保真度、多样智能体类型和动态环境模拟等功能，并配有全面的评估框架和基准，以精确评估智能体能力。

Result: TongSIM具有广泛的适用性，能够精确评估智能体的感知、认知、决策、人机协作以及空间和社交推理等能力。它为研究人员提供了灵活性和可扩展性，成功弥补了现有专用平台之间的空白。

Conclusion: TongSIM作为一个统一平台，能够加速具身智能体的训练、评估和推动通用具身智能的发展。

Abstract: As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.

</details>


### [18] [ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge](https://arxiv.org/abs/2512.20276)
*Yuntao Dai,Hang Gu,Teng Wang,Qianyu Cheng,Yifei Zheng,Zhiyong Qiu,Lei Gong,Wenqi Lou,Xuehai Zhou*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.

</details>


### [19] [Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation](https://arxiv.org/abs/2512.20278)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.

</details>


### [20] [A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice](https://arxiv.org/abs/2512.20344)
*Yaowei Bai,Ruiheng Zhang,Yu Lei,Xuhua Duan,Jingfeng Yao,Shuguang Ju,Chaoyang Wang,Wei Yao,Yiwan Guo,Guilin Zhang,Chao Wan,Qian Yuan,Lei Chen,Wenjuan Tang,Biqiang Zhu,Xinggang Wang,Tao Sun,Wei Zhou,Dacheng Tao,Yongchao Xu,Chuansheng Zheng,Huangxuan Zhao,Bo Du*

Main category: cs.AI

TL;DR: 针对放射科医生短缺和胸片工作量大，本文提出了基于DeepSeek Janus-Pro的轻量级胸片解读系统Janus-Pro-CXR (1B)。该系统通过首个多中心前瞻性临床试验验证，在报告准确性上优于包括ChatGPT 4o在内的现有模型，并显著提高了解读效率（时间减少18.3%）和报告质量。系统架构将开源。


<details>
  <summary>Details</summary>
Motivation: 解决全球放射科医生短缺和初级护理中巨大的胸片工作量问题。现有的大语言模型（LLMs）在医学影像解读方面的评估主要依赖回顾性分析或自动化指标，缺乏严格的前瞻性临床验证。

Method: 开发了基于DeepSeek Janus-Pro模型的胸片解读系统Janus-Pro-CXR (1B)。该系统采用了轻量级架构和领域特定优化。通过一项多中心前瞻性临床试验（NCT07117266）对其进行严格验证，并与现有SOTA模型（包括ChatGPT 4o）进行回顾性报告准确性比较和前瞻性临床部署效果评估。

Result: 在自动化报告生成方面，Janus-Pro-CXR (1B) 优于包括ChatGPT 4o (200B) 在内的更大规模模型和现有SOTA模型。回顾性评估显示其报告准确性显著高于Janus-Pro和ChatGPT 4o。在前瞻性临床部署中，AI辅助显著提高了报告质量分数，将解读时间缩短了18.3%（P < 0.001），并且在54.3%的病例中获得专家偏好。系统能够可靠地检测六种临床关键影像学发现。

Conclusion: Janus-Pro-CXR系统通过轻量级架构和领域优化，提高了诊断可靠性和工作流程效率，尤其适用于资源受限的环境。该模型的架构和实施框架将开源，以促进AI辅助放射学解决方案的临床转化。

Abstract: A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.

</details>


### [21] [Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale](https://arxiv.org/abs/2512.20469)
*Linfeng Zhang,Siheng Chen,Yuzhu Cai,Jingyi Chai,Junhan Chang,Kun Chen,Zhi X. Chen,Zhaohan Ding,Yuwen Du,Yuanpeng Gao,Yuan Gao,Jing Gao,Zhifeng Gao,Qiangqiang Gu,Yanhui Hong,Yuan Huang,Xi Fang,Xiaohong Ji,Guolin Ke,Zixing Lei,Xinyu Li,Yongge Li,Ruoxue Liao,Hang Lin,Xiaolu Lin,Yuxiang Liu,Xinzijian Liu,Zexi Liu,Jintan Lu,Tingjia Miao,Haohui Que,Weijie Sun,Yanfeng Wang,Bingyang Wu,Tianju Xue,Rui Ye,Jinzhe Zeng,Duo Zhang,Jiahui Zhang,Linfeng Zhang,Tianhan Zhang,Wenchang Zhang,Yuzhi Zhang,Zezhong Zhang,Hang Zheng,Hui Zhou,Tong Zhu,Xinyu Zhu,Qingguo Zhou,Weinan E*

Main category: cs.AI

TL;DR: 提出了一个名为 Bohrium+SciMaster 的基础设施和编排堆栈，旨在解决扩展“智能体科学”（Agentic Science）的挑战，通过提供可追踪的资产中心和工作流编排，实现科学流程的加速和自动化。


<details>
  <summary>Details</summary>
Motivation: 尽管AI智能体在多步骤科学工作流中具有潜力，但大规模应用面临挑战：工作流难以观察和复现、许多科学工具非智能体友好、执行追踪和治理困难，且现有系统往往是定制的，缺乏可重用性。需要一个基础设施来支持可扩展的智能体科学。

Method: 提出了 Bohrium+SciMaster 基础设施生态系统。Bohrium 作为 AI4S 资产的托管、可追踪中心（类似于科学界的 HuggingFace），将异构资源转化为智能体可用的能力。SciMaster 负责将这些能力编排成长周期科学工作流。两者之间由一个“科学智能基质”连接，用于组织可重用模型和知识，以实现可组合性、可审计性和改进。

Result: 通过十一个代表性的主智能体在真实工作流中进行了演示，实现了端到端科学周期时间的数量级减少，并从数百万规模的真实工作负载中生成了以执行为基础的信号。

Conclusion: 扩展智能体科学需要一个基础设施和生态系统方法（如 Bohrium+SciMaster），该方法通过提供可追踪的资产中心和工作流编排，有效地解决了现有瓶颈，显著缩短了科学研究周期。

Abstract: AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.
  However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.
  We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.
  We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.

</details>


### [22] [Benchmarking LLMs for Predictive Applications in the Intensive Care Units](https://arxiv.org/abs/2512.20520)
*Chehak Malhotra,Mehak Gopal,Akshaya Devadiga,Pradeep Singh,Ridam Pal,Ritwik Kashyap,Tavpritesh Sethi*

Main category: cs.AI

TL;DR: 本研究比较了LLMs和SLMs在基于MIMIC III数据的危重症患者休克预测任务上的性能。结果显示，尽管GatorTron Base表现突出，但LLMs在预测未来临床事件方面并未展现出对SLMs的绝对优势，提示未来LLM应聚焦于临床轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLMs）彻底改变了自然语言处理领域，但它们在临床预测任务中的应用研究仍较少。及时预测休克能够实现早期干预，从而改善危重症患者的预后。

Method: 研究使用了MIMIC III数据库中17,294次ICU住院的文本数据，筛选出355例正常休克指数和87例异常休克指数的患者。比较了大型语言模型（GatorTron-Base、Llama 8B、Mistral 7B）和小型语言模型（BioBERT、DocBERT、Word2Vec等）在预测危重症患者休克方面的性能。微调时，使用了Focal Loss和交叉熵损失来处理类别不平衡问题。

Result: GatorTron Base模型获得了最高的加权召回率（80.5%）。然而，总体性能指标显示，LLMs和小型语言模型（SLMs）在预测休克方面具有可比性。

Conclusion: 研究结果表明，尽管LLMs在文本任务上表现强劲，但在预测未来的临床事件方面，它们并不一定比小型语言模型（SLMs）更具优势。为了获得有意义的临床结果，未来训练LLMs的工作应侧重于开发能够预测临床轨迹的模型，而不是专注于命名实体识别或表型分析等简单任务。

Abstract: With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.

</details>


### [23] [Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model](https://arxiv.org/abs/2512.20548)
*Zhiyi Duan,Xiangren Wang,Hongyu Yuan,Qianli Xing*

Main category: cs.AI

TL;DR: 为解决教师情绪分析的准确性问题，本文构建了首个大规模多模态教师情感数据集T-MED（包含教学信息），并提出了基于非对称注意力机制的AAM-TSA模型，该模型在情感分类准确性和可解释性上显著超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 教师的情绪状态对教学效率、学生参与度和学习成绩至关重要。然而，现有研究往往因教师行为的表演性（performative nature）和忽略教学信息对情感表达的关键影响，而未能准确捕捉教师的真实情绪。

Method: (1) 数据集：构建了首个大规模教师多模态情感分析数据集T-MED（14,938个实例，涵盖K-12到高等教育的250个真实课堂），整合了文本、音频、视频和教学信息，并采用人机协作标注确保准确性。(2) 模型：提出了新型的基于非对称注意力机制的多模态教师情感分析模型AAM-TSA，该模型利用非对称注意力机制和分层门控单元来实现差异化的跨模态特征融合和精确的情感分类。

Result: 实验结果表明，AAM-TSA模型在T-MED数据集上，无论是在准确性还是可解释性方面，均显著优于现有的最先进方法。

Conclusion: 本文通过构建包含教学信息的首个大规模教师多模态情感数据集T-MED，并提出了新型的AAM-TSA模型，系统地解决了教师情感分析中现有方法准确性不足的挑战，实验证明AAM-TSA在准确性和可解释性方面表现优越。

Abstract: Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.

</details>


### [24] [LongVideoAgent: Multi-Agent Reasoning with Long Videos](https://arxiv.org/abs/2512.20618)
*Runtao Liu,Ziyi Liu,Jiaqi Tang,Yue Ma,Renjie Pi,Jipeng Zhang,Qifeng Chen*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.

</details>

<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 23]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models](https://arxiv.org/abs/2512.23850)
*Rahul Baxi*

Main category: cs.AI

TL;DR: 本文提出了Drill-Down and Fabricate Test (DDFT)协议,用于评估语言模型在语义压缩和对抗性干扰下维持事实准确性的认知鲁棒性。研究发现认知鲁棒性与模型参数量和架构类型无关,而与错误检测能力强相关,挑战了模型规模与可靠性关系的传统假设。


<details>
  <summary>Details</summary>
Motivation: 现有的静态基准测试(如MMLU和TruthfulQA)只能评估模型在理想条件下的知识掌握程度,无法区分缺乏知识的模型和在信息退化或对抗性探测下验证机制崩溃的模型。需要一种新的评估方法来测量模型在现实压力下的认知鲁棒性,以确保其在关键应用中的可靠性。

Method: 提出DDFT(Drill-Down and Fabricate Test)协议,基于双系统认知模型:语义系统(生成流畅文本)和认知验证器(验证事实准确性)。对9个前沿模型在8个知识领域、5个压缩级别下进行评估,共进行1,800次轮次级评估。测试包括渐进式语义压缩和对抗性伪造两个维度,以评估模型在信息退化和对抗性干扰下维持事实准确性的能力。

Result: 认知鲁棒性与传统设计范式正交:参数量(r=0.083, p=0.832)和架构类型(r=0.153, p=0.695)均不能显著预测鲁棒性。错误检测能力与整体鲁棒性强相关(rho=-0.817, p=0.007),是关键瓶颈。大型旗舰模型表现出脆弱性,而较小模型可以实现鲁棒性能,挑战了模型规模与可靠性的传统关系假设。

Conclusion: 认知鲁棒性源于训练方法和验证机制,而非模型规模或架构。错误检测能力是提升鲁棒性的关键瓶颈。DDFT框架为评估语言模型在关键应用部署前的认知鲁棒性提供了理论基础和实用工具,强调需要超越传统参数规模竞赛,关注验证机制的开发。

Abstract: Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model's ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.

</details>


### [2] [A Proof-of-Concept for Explainable Disease Diagnosis Using Large Language Models and Answer Set Programming](https://arxiv.org/abs/2512.23932)
*Ioanna Gemou,Evangelos Lamprou*

Main category: cs.AI

TL;DR: 本文提出了McCoy框架,通过结合大语言模型(LLM)和答案集编程(ASP)来实现疾病预测,该框架能够将医学文献转化为ASP代码并结合患者数据进行诊断推理,在小规模疾病诊断任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 符号AI在医疗领域的应用受限于构建高质量知识库所需的大量工作。为了克服这一障碍,需要一种能够自动化知识获取并保持推理可解释性的方法,同时确保疾病预测的准确性以实现及时干预和有效治疗。

Method: McCoy框架采用大语言模型(LLM)与答案集编程(ASP)相结合的方法。具体流程为:使用LLM将医学文献翻译成ASP代码,将其与患者数据结合,然后通过ASP求解器进行处理以得出最终诊断结果。这种集成方式结合了两种范式的优势,构建了一个鲁棒且可解释的预测框架。

Result: 初步实验结果显示,McCoy在小规模疾病诊断任务上表现出强劲的性能,证明了该框架在疾病预测方面的有效性。

Conclusion: McCoy框架成功地将大语言模型的知识提取能力与答案集编程的逻辑推理能力相结合,为医疗诊断提供了一个既准确又可解释的解决方案,有效降低了构建医疗知识库的门槛,为符号AI在医疗领域的应用开辟了新途径。

Abstract: Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.

</details>


### [3] [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)
*Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 本文提出了ROAD(通过自动调试进行反思优化)框架,这是一种无需大规模标注数据集的自动提示优化方法,通过将优化过程视为动态调试而非随机搜索,利用多智能体架构将非结构化失败日志转换为决策树协议,在学术基准和生产环境中均展现出高样本效率和显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的自动提示优化方法依赖大规模标注的黄金标准开发集来计算适应度分数,但在实际软件工程的冷启动阶段,这类精心策划的数据集很少可用,工程师面对的是混乱的生产日志和不断演变的失败模式。因此需要一种能够绕过精炼数据集需求、更贴近真实工程场景的优化方法。

Method: ROAD采用专门的多智能体架构,包括三个核心组件:Analyzer(分析器)负责根因分析,Optimizer(优化器)负责模式聚合,Coach(教练)负责策略集成。该框架将优化过程视为动态调试调查而非随机搜索,能够将非结构化的失败日志转换为健壮的结构化决策树协议,模拟人类工程师的失败分析和修补循环。

Result: 在标准化学术基准测试中,ROAD仅通过三次自动迭代就实现了5.6%的成功率提升(从73.6%提升到79.2%)和3.8%的搜索准确率提升。在实际生产的知识管理引擎中也得到验证。在零售领域的复杂推理任务上,ROAD相对基线提升了约19%的智能体性能。展现出高样本效率特性。

Conclusion: 研究表明,模拟人类工程循环的失败分析和修补方法为部署可靠的大语言模型智能体提供了一种可行的、数据高效的替代方案,相比资源密集型的强化学习训练更适合实际应用场景。ROAD框架证明了将优化视为调试过程而非随机搜索的有效性,特别适用于缺乏精炼数据集的冷启动阶段。

Abstract: Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.

</details>


### [4] [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)
*Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao*

Main category: cs.AI

TL;DR: LoongFlow是一个自进化智能体框架,通过将LLM集成到"计划-执行-总结"认知范式中,并结合混合进化记忆系统,在算法发现和机器学习管道优化任务中实现了最先进的解决方案质量,同时显著降低了计算成本,在进化效率上比领先基线方法提升高达60%。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型向自改进智能体的转变受到传统进化方法缺乏结构化推理的阻碍。现有方法在高维代码空间中常常面临过早收敛和低效探索的问题。需要一种能够平衡探索-利用权衡、维持多样性并防止优化停滞的新框架。

Method: 提出LoongFlow框架,将LLM集成到认知"计划-执行-总结"(PES)范式中,将进化搜索映射为推理密集型过程,替代"盲目"的变异算子。引入混合进化记忆系统,结合多岛模型、MAP-Elites和自适应玻尔兹曼选择机制,以维持长期架构一致性和行为多样性。实例化为通用智能体(用于算法发现)和机器学习智能体(用于管道优化)。

Result: 在AlphaEvolve基准测试和Kaggle竞赛上的广泛评估表明,LoongFlow在进化效率上比领先基线方法(如OpenEvolve、ShinkaEvolve)提升高达60%,同时发现了更优的解决方案。能够以更低的计算开销生成专家级解决方案。

Conclusion: LoongFlow在自主科学发现方面取得了重大进展,通过结构化推理和混合进化记忆系统,成功解决了传统进化方法的过早收敛和低效探索问题,为构建能够自主发现高质量解决方案的自进化智能体提供了有效途径,显著降低了计算成本的同时提升了解决方案质量。

Abstract: The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike "blind" mutation operators, LoongFlow integrates LLMs into a cognitive "Plan-Execute-Summarize" (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.

</details>


### [5] [SCP: Accelerating Discovery with a Global Web of Autonomous Scientific Agents](https://arxiv.org/abs/2512.24189)
*Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.

</details>


### [6] [Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment](https://arxiv.org/abs/2512.24263)
*Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang*

Main category: cs.AI

TL;DR: 本文提出了风险感知逐步对齐(RSA)方法,通过在策略优化过程中引入嵌套风险度量,在token级别进行风险感知的约束策略优化,以在保持语言模型有用性的同时增强安全性并抑制尾部风险。


<details>
  <summary>Details</summary>
Motivation: 现有的安全对齐方法(如Safe RLHF和SACPO)通常采用风险中性范式,无法充分应对偏离参考策略带来的风险,且对罕见但可能灾难性的有害行为缺乏鲁棒性。需要一种能够明确考虑风险意识的对齐方法来确保语言模型的安全性和可信度。

Method: 提出风险感知逐步对齐(RSA)方法,将安全对齐问题形式化为token级别的风险感知约束策略优化问题。通过利用嵌套风险度量类别,采用逐步对齐程序求解,得到基于嵌套风险度量的token级别策略更新。该方法在温和假设下提供了策略最优性的理论分析。

Result: 实验结果表明,RSA方法在保持高水平有用性的同时确保了强安全性,并显著抑制了尾部风险(即低概率但高影响的不安全响应)。该方法有效缓解了模型过度偏离参考策略引起的风险,并明确抑制了低概率高影响的有害行为。

Conclusion: RSA方法通过在策略优化中明确引入风险感知机制,成功解决了现有安全对齐方法的局限性。该方法不仅在理论上具有策略最优性保证,在实践中也实现了有用性与安全性的良好平衡,特别是在抑制罕见但严重的有害行为方面表现出色,为语言模型的安全对齐提供了更可靠的解决方案。

Abstract: When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.

</details>


### [7] [What Drives Success in Physical Planning with Joint-Embedding Predictive World Models?](https://arxiv.org/abs/2512.24497)
*Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun*

Main category: cs.AI

TL;DR: 本文研究了JEPA-WM（在学习表示空间中进行规划的世界模型）家族方法，通过系统性实验分析了模型架构、训练目标和规划算法等关键组件，提出了一个在导航和操作任务中优于现有基线方法的改进模型。


<details>
  <summary>Details</summary>
Motivation: AI领域长期面临的挑战是开发能够解决广泛物理任务并泛化到新任务和环境的智能体。虽然从状态-动作轨迹训练世界模型并用于规划是流行方法，但在输入空间规划效率较低。在学习表示空间中进行规划的JEPA-WM方法有望通过抽象无关细节提高规划效率，但其技术选择和最优配置尚不明确，需要系统性研究。

Method: 本文对JEPA-WM家族方法进行了全面的系统性研究，包括：1）将该家族方法统一表征为JEPA-WM框架；2）在模拟环境和真实机器人数据上进行实验；3）系统分析模型架构、训练目标和规划算法三个关键组件对规划成功率的影响；4）综合实验发现提出改进模型。

Result: 提出的改进模型在导航和操作任务中均优于两个已建立的基线方法DINO-WM和V-JEPA-2-AC。实验在模拟环境和真实机器人数据上验证了模型的有效性，并公开了代码、数据和检查点。

Conclusion: 通过系统性研究JEPA-WM家族方法的关键技术组件，本文确定了该类方法的最优配置方案，并提出了性能更优的世界模型。研究表明在学习表示空间中进行规划相比输入空间规划更加高效，为开发能够泛化到新任务和环境的AI智能体提供了有效途径。

Abstract: A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at https://github.com/facebookresearch/jepa-wms.

</details>


### [8] [Thinking on Maps: How Foundation Model Agents Explore, Remember, and Reason Map Environments](https://arxiv.org/abs/2512.24504)
*Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial understanding.In this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.

</details>


### [9] [Evaluating the Reasoning Abilities of LLMs on Underrepresented Mathematics Competition Problems](https://arxiv.org/abs/2512.24505)
*Samuel Golladay,Majid Bani-Yaghoub*

Main category: cs.AI

TL;DR: 本研究通过密苏里大学数学竞赛题目评估了三个主流大语言模型(GPT-4o-mini、Gemini-2.0-Flash和DeepSeek-V3)在微积分、解析几何和离散数学领域的数学推理能力,发现DeepSeek-V3表现最佳,但所有模型在几何问题上均表现较弱,且不同模型呈现出不同的错误模式。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要使用相同的数据集对大语言模型的数学推理能力进行基准测试,这限制了研究结果的普适性,无法充分捕捉数学任务中的多样化挑战。因此,本研究旨在使用代表性不足的数学竞赛问题来分析大语言模型的表现,以获得更深入的洞察。

Method: 研究使用密苏里大学数学竞赛中的微积分、解析几何和离散数学问题对三个主流大语言模型(GPT-4o-mini、Gemini-2.0-Flash和DeepSeek-V3)进行提示测试,将模型的回答与已知正确解答进行比较,以确定每个问题领域的准确率,并分析模型的推理过程以探索不同问题类型和模型之间的错误模式。

Result: DeepSeek-V3在微积分、解析几何和离散数学三个类别中均表现最佳,无论是推理过程还是最终答案的准确性都优于其他模型。所有三个模型在几何问题上的表现都明显较弱。不同模型呈现出不同的错误模式:DeepSeek-V3的错误主要归因于计算和逻辑错误,GPT-4o-mini经常出现逻辑和方法相关的错误,而Gemini则倾向于推理不完整和过早得出结论。

Conclusion: 在代表性不足的数学竞赛数据集上评估大语言模型可以更深入地揭示它们独特的错误模式,并突出结构化推理中持续存在的挑战,特别是在几何领域。这种评估方法有助于更全面地理解大语言模型在数学推理方面的局限性。

Abstract: Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.

</details>


### [10] [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)
*Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段方法来提升大语言模型的空间推理能力:首先通过监督微调学习基础空间变换(旋转、平移、缩放),然后冻结模型并使用LoRA适配器在GRPO框架下学习多步规划策略。该方法在ASCII艺术数据集和强化学习环境中验证,相比基线模型表现更优且训练更稳定。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型具有强大的通用语言能力,但在导航和规划等应用场景中,它们在空间变换和结构化环境中的多步规划方面仍然存在困难。现有模型缺乏对基础空间物理规律的理解,难以将原子级空间操作组合成复杂的推理任务。

Method: 提出两阶段分解方法:(1)第一阶段:对基础空间变换(旋转、平移、缩放)进行监督微调,使模型具备基本的空间物理知识;(2)第二阶段:冻结物理感知模型,在GRPO强化学习框架下训练轻量级LoRA适配器,以闭环方式学习组合这些基础模块进行多步规划的策略。构建了ASCII艺术数据集和相应的ASCII强化学习环境来支持该流程,并在动态环境(显式状态更新)和静态环境(依赖内部状态)下进行测试。

Result: 该方法在两种环境设置下均持续优于基线模型,包括通用骨干模型、物理感知模型和端到端强化学习模型。相比从零开始的端到端强化学习,该方法收敛速度更快且训练过程更稳定。注意力模式分析表明微调确实在空间理解方面带来了有意义的改进。

Conclusion: 通过将空间推理分解为基础空间变换学习和策略组合学习两个阶段,可以有效提升大语言模型在结构化环境中的空间推理和多步规划能力。这种模块化方法不仅性能更优,而且训练效率更高、稳定性更好,为LLMs在导航和规划等实际应用中的空间推理能力提供了可行的解决方案。

Abstract: Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.

</details>


### [11] [Recursive Language Models](https://arxiv.org/abs/2512.24601)
*Alex L. Zhang,Tim Kraska,Omar Khattab*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.

</details>


### [12] [Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization](https://arxiv.org/abs/2512.24609)
*Dong Qiu,Duo Xu,Limengxi Yue*

Main category: cs.AI

TL;DR: 本文提出了一种基于强化学习增强的大语言模型多智能体协作框架，通过将协作建模为去中心化部分可观测马尔可夫决策过程(Dec-POMDP)，采用集中训练分散执行(CTDE)策略和组相对策略优化(GRPO)方法，在协作写作和编程任务中实现了任务处理速度提升3倍、写作一致性达98.7%、代码测试通过率达74.6%的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在单一语言任务中表现优异，但在多智能体场景中缺乏协作意识，难以优化全局性能。现有LLM智能体在复杂工作流中的可靠协作能力不足，需要一种能够有效协调多个智能体、平衡任务质量、速度和协调成本的框架来解决这一问题。

Method: 提出了一种强化学习增强的LLM智能体框架，主要包括：(1)将多智能体协作问题形式化为去中心化部分可观测马尔可夫决策过程(Dec-POMDP)；(2)采用集中训练分散执行(CTDE)的训练范式；(3)引入组相对策略优化(GRPO)算法，在训练阶段利用全局信号联合优化智能体策略；(4)设计简化的联合奖励函数，综合平衡任务质量、处理速度和协调成本三个维度。

Result: 在协作写作和编程基准测试中取得显著成果：(1)相比单智能体基线，任务处理速度提升3倍；(2)在写作任务中实现98.7%的结构/风格一致性；(3)在编程任务中达到74.6%的测试通过率；(4)在各项指标上持续优于现有的强多智能体LLM基线方法。

Conclusion: 该研究成功将强化学习与大语言模型结合，通过Dec-POMDP建模、CTDE训练范式和GRPO优化算法，有效解决了多智能体LLM协作中的全局优化问题。实验结果证明该框架在协作写作和编程等复杂工作流中具有实用性和可靠性，为构建高效的多智能体LLM协作系统提供了切实可行的技术路径。

Abstract: Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

</details>


### [13] [Group Deliberation Oriented Multi-Agent Conversational Model for Complex Reasoning](https://arxiv.org/abs/2512.24613)
*Zheyu Shi,Dong Qiu,Shanlong Yu*

Main category: cs.AI

TL;DR: 本文提出了一种面向群体协商的多智能体对话模型,通过三层角色分工架构(生成、验证、整合)、自博弈机制和检索增强模块,结合改进的近端策略优化算法,在多跳推理任务上显著提升了准确率和一致性,为复杂推理任务提供了高效稳定的解决方案。


<details>
  <summary>Details</summary>
Motivation: 单一大语言模型在处理复杂推理任务时存在局限性,难以保证推理的多样性、事实准确性和逻辑一致性。现有方法缺乏有效的多智能体协作机制和外部知识整合能力,因此需要设计一种能够模拟群体协商过程的多智能体系统,通过角色分工和协同训练来提升复杂推理能力。

Method: 采用三层角色分工架构:意见生成智能体产生多样化推理视角,证据验证智能体检索外部知识并量化事实支持度,一致性仲裁智能体整合逻辑连贯的结论。引入自博弈机制扩展多路径推理轨迹,设计检索增强模块动态补充外部知识。构建结合事实一致性和逻辑连贯性的复合奖励函数,应用改进的近端策略优化(PPO)策略进行协同训练。

Result: 在HotpotQA数据集上多跳推理准确率提升16.8%,在2WikiMultihopQA上提升14.3%,在MeetingBank上提升19.2%,同时一致性提升21.5%。模型推理效率高于主流多智能体方法,展现出优异的性能和稳定性。

Conclusion: 提出的群体协商导向多智能体对话模型通过三层角色分工、自博弈机制和检索增强有效解决了单一大语言模型在复杂推理任务中的局限性。实验结果验证了该方法在多跳推理准确率、一致性和效率方面的显著优势,为复杂推理任务提供了一种有效且稳定的解决方案,具有良好的应用前景。

Abstract: This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.

</details>


### [14] [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)
*Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun*

Main category: cs.AI

TL;DR: 本文提出Youtu-Agent框架,通过模块化设计实现LLM智能体的自动生成和持续进化,解决了现有框架配置成本高和能力静态的问题,在多个基准测试上取得了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型智能体框架面临两大挑战:一是构建高质量智能体需要大量人工进行工具集成和提示工程,配置成本高昂;二是已部署的智能体难以适应动态环境变化,且需要昂贵的微调才能更新能力。这些问题限制了LLM智能体的实际应用和规模化部署。

Method: Youtu-Agent采用模块化框架设计,包含三个核心组件:(1)结构化配置系统,解耦执行环境、工具包和上下文管理,支持灵活复用和自动合成;(2)两种生成范式:Workflow模式处理标准任务,Meta-Agent模式处理复杂非标准需求,可自动生成工具代码、提示和配置;(3)混合策略优化系统:Agent Practice模块通过上下文优化实现经验积累和性能提升(无需参数更新),Agent RL模块集成分布式训练框架实现端到端大规模强化学习。

Result: 在WebWalkerQA上使用开源权重模型达到71.47%的准确率,在GAIA上达到72.8%,均为最先进水平。自动生成流程的工具合成成功率超过81%。Practice模块在AIME 2024/2025上分别提升2.7%和5.4%的性能。Agent RL训练在7B参数的LLM上实现40%的加速,在数学基准测试上编码/推理能力提升35%,在通用/多跳问答基准测试上搜索能力提升21%。

Conclusion: Youtu-Agent成功解决了LLM智能体框架的配置成本和静态能力问题,通过模块化设计、自动生成范式和混合优化系统,实现了智能体的高效构建和持续进化。实验结果验证了该框架在多个任务上的有效性和优越性,为LLM智能体的实际应用和规模化部署提供了可行的解决方案。

Abstract: Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbf{Youtu-Agent}, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbf{Workflow} mode for standard tasks and a \textbf{Meta-Agent} mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbf{Agent Practice} module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbf{Agent RL} module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\%) and GAIA (72.8\%) using open-weight models. Our automated generation pipeline achieves over 81\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\% and +5.4\% respectively. Moreover, our Agent RL training achieves 40\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\% and 21\% on Maths and general/multi-hop QA benchmarks.

</details>


### [15] [Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions](https://arxiv.org/abs/2512.24679)
*Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu*

Main category: cs.AI

TL;DR: 本文提出了一种基于双解耦的多模态跨域混合融合模型，用于机械故障诊断。该方法通过解耦模态不变/特定特征和域不变/特定表示，结合跨域混合融合策略和三模态融合机制，在未见工况条件下实现了优于现有方法的故障诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能故障诊断方法在未见工况条件下性能显著下降，域自适应方法依赖目标域样本，且大多数研究仅使用单模态信号，忽视了多模态信息的互补性对提升模型泛化能力的作用。因此需要开发能够利用多模态信息并在无目标域样本情况下实现跨域泛化的故障诊断方法。

Method: 提出了一个多模态跨域混合融合模型，包含三个核心组件：(1)双解耦框架，分别解耦模态不变/特定特征和域不变/特定表示，实现全面的多模态表示学习和鲁棒的域泛化；(2)跨域混合融合策略，通过随机混合跨域的模态信息进行模态和域多样性增强；(3)三模态融合机制，自适应整合多模态异构信息。

Result: 在感应电机故障诊断的恒定和时变工况条件下进行了大量实验。结果表明，所提方法在未见工况条件下始终优于先进方法，全面的消融研究进一步验证了每个提出组件和多模态融合的有效性。代码已在GitHub开源。

Conclusion: 本文成功解决了故障诊断中的跨域泛化和多模态融合问题。通过双解耦框架、跨域混合融合策略和三模态自适应融合机制，该方法能够在不依赖目标域样本的情况下，充分利用多模态信息的互补性，实现在未见工况条件下的鲁棒故障诊断，为实际工业应用提供了有效的解决方案。

Abstract: Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: https://github.com/xiapc1996/MMDG.

</details>


### [16] [BatteryAgent: Synergizing Physics-Informed Interpretation with LLM Reasoning for Intelligent Battery Fault Diagnosis](https://arxiv.org/abs/2512.24686)
*Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang*

Main category: cs.AI

TL;DR: 本文提出了BatteryAgent框架,通过整合物理知识特征与大语言模型的推理能力,实现了锂离子电池故障的可解释性诊断,将传统的二分类检测扩展为多类型智能诊断,AUROC达到0.986,显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法虽然检测准确率高,但存在"黑盒"特性导致可解释性不足的问题;同时受限于二分类范式,难以提供根本原因分析和维护建议。锂离子电池故障诊断对系统安全至关重要,需要一种既准确又可解释、能提供全面诊断报告的新方法。

Method: 提出BatteryAgent分层框架,包含三个核心模块:(1)物理感知层:利用基于电化学原理的10个机制特征,平衡降维与物理保真度;(2)检测与归因层:采用梯度提升决策树(GBDT)和SHAP方法量化特征贡献;(3)推理与诊断层:以大语言模型(LLM)为智能体核心,构建"数值-语义"桥梁,结合SHAP归因和机制知识库生成包含故障类型、根因分析和维护建议的综合报告。

Result: BatteryAgent在硬边界样本上有效纠正误分类,AUROC达到0.986,显著优于当前最先进方法。框架将传统二分类检测扩展为多类型可解释诊断,实现了从"被动检测"到"智能诊断"的范式转变。

Conclusion: BatteryAgent框架通过整合物理知识与大语言模型推理能力,成功解决了现有方法可解释性不足和诊断能力受限的问题,为电池安全管理提供了新的智能诊断范式,不仅提高了检测准确性,还能提供根本原因分析和维护建议,具有重要的实际应用价值。

Abstract: Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their "black-box" nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a "numerical-semantic" bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from "passive detection" to "intelligent diagnosis" for battery safety management.

</details>


### [17] [Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences](https://arxiv.org/abs/2512.24829)
*Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano*

Main category: cs.AI

TL;DR: 本文提出了一种可解释的家庭物品摆放偏好模型,将人类决策分解为四个可解释维度(空间实用性、习惯便利性、语义连贯性和常识适当性),并通过63人在线研究验证了该模型,最后将其集成到蒙特卡洛树搜索规划器中,用于指导机器人生成符合人类偏好的物品摆放方案。


<details>
  <summary>Details</summary>
Motivation: 现有的家庭物品整理机器人系统依赖于从人类演示中推断的潜在偏好模型,虽然这些模型在预测方面有效,但对指导人类决策的可解释因素提供的洞察有限。因此需要一种明确的、可解释的物品摆放偏好表达方式,以更好地理解和建模人类的摆放决策。

Method: 研究者提出了四个可解释的物品摆放偏好维度:空间实用性(将物品放在空间中最自然合适的位置)、习惯便利性(让常用物品易于拿取)、语义连贯性(将用于相同任务或上下文相关的物品放在一起)和常识适当性(将物品放在人们通常期望找到它们的地方)。通过设计和验证自我报告问卷,在63名参与者的在线研究中验证了这些维度的心理学独特性和解释力。然后将这些维度集成到蒙特卡洛树搜索(MCTS)规划器中,用于生成物品摆放方案。

Result: 研究结果证实了四个维度的心理学独特性,以及它们在两个场景(厨房和客厅)中的解释力。当使用参与者衍生的偏好进行指导时,基于MCTS的规划器能够生成与参与者生成的摆放方案高度一致的合理摆放方案。

Conclusion: 本研究贡献了一个紧凑、可解释的物品摆放偏好表达框架,并展示了如何将其操作化应用于机器人规划。这种明确的偏好模型不仅提高了预测性能,还增强了系统的可解释性,为家庭服务机器人的物品整理任务提供了更符合人类认知的解决方案。

Abstract: Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.

</details>


### [18] [GenZ: Foundational models as latent variable generators within traditional statistical models](https://arxiv.org/abs/2512.24834)
*Marko Jojic,Nebojsa Jojic*

Main category: cs.AI

TL;DR: 本文提出GenZ模型,通过可解释的语义特征将基础模型与统计建模相结合。该方法通过迭代过程发现语义特征描述,并使用广义EM算法联合优化特征描述符和统计模型参数,在房价预测和电影推荐任务上显著优于仅依赖大语言模型领域知识的基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然拥有广泛的领域知识,但往往无法捕捉对预测任务至关重要的数据集特定模式。现有方法过度依赖基础模型的通用领域理解,而忽略了从统计建模错误中学习数据集特定特征的机会。因此需要一种混合方法来桥接基础模型的语义理解能力和统计模型对数据特定模式的捕捉能力。

Method: 提出GenZ混合模型,核心方法包括:(1)通过对比统计建模错误识别的项目组来迭代发现语义特征描述,而非仅依赖基础模型的领域知识;(2)将问题形式化为广义EM算法,联合优化语义特征描述符和统计模型参数;(3)提示冻结的基础模型根据发现的特征对项目进行分类,将这些判断视为潜在二值特征的噪声观测,通过学习的统计关系预测实值目标。

Result: 在两个领域验证了方法有效性:(1)房价预测任务中,使用多模态房源数据发现的语义特征,模型达到12%的中位相对误差,大幅优于仅依赖LLM通用领域知识的GPT-5基线(38%误差);(2)Netflix电影推荐的冷启动协同过滤任务中,模型仅通过语义描述预测协同过滤表示达到0.59余弦相似度,匹配传统协同过滤需要约4000个用户评分才能达到的性能。

Conclusion: GenZ成功地将基础模型的语义理解能力与统计建模相结合,通过发现数据集特定的语义特征(如预测本地住房市场的建筑细节、预测用户偏好的系列电影归属等)显著提升预测性能。这些发现的特征揭示了与模型领域知识不同的数据集特定模式,证明了从统计建模错误中学习语义特征的有效性,为可解释的混合建模提供了新思路。

Abstract: We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model's domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12\% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38\% error) that relies on the LLM's general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions -- matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model's domain knowledge alone.

</details>


### [19] [A study on constraint extraction and exception exclusion in care worker scheduling](https://arxiv.org/abs/2512.24853)
*Koki Suenaga,Tomohiro Furuta,Satoshi Ono*

Main category: cs.AI

TL;DR: 本文提出了一种基于约束模板的方法,用于自动提取长期护理机构的排班约束条件,并通过排除异常约束来生成满足硬约束且减少软约束违规的护理人员排班表。


<details>
  <summary>Details</summary>
Motivation: 长期护理机构的排班条件因设施而异,需要通过访谈管理者来设计特定设施的约束条件。现有约束提取技术无法有效处理异常约束,导致自动排班系统难以适应不同机构的实际需求。

Method: 提出使用约束模板来提取各种组件的组合,包括连续多日的班次模式或员工组合。模板可以通过改变关注的天数、员工数量以及提取焦点(模式或频率)来提取多样化的约束。关键创新是引入了排除异常约束的机制,与现有约束提取技术不同。提取的约束可被约束编程求解器用于生成护理人员排班表。

Result: 实验表明,所提方法成功创建了满足所有硬约束的排班表,并通过规避异常约束的提取,减少了软约束的违规次数。

Conclusion: 基于约束模板的方法能够有效提取长期护理机构的排班约束,通过排除异常约束机制提高了自动排班系统的实用性,生成的排班表既满足必须遵守的硬约束,又能减少软约束违规,为不同护理机构提供了可定制的排班解决方案。

Abstract: Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.

</details>


### [20] [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)
*Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng*

Main category: cs.AI

TL;DR: 本文介绍了Agentic Learning Ecosystem (ALE),一个用于优化智能体大语言模型生产流程的基础设施,包含训练框架ROLL、沙盒环境ROCK和智能体框架iFlow CLI,并发布了基于ALE训练的开源智能体模型ROME,该模型在百万级轨迹数据上训练,采用新型策略优化算法IPA,在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源社区缺乏一个系统化的端到端生态系统来简化智能体开发流程。智能体需要在真实环境中进行多轮交互、执行动作、观察结果并迭代优化,但现有基础设施不足以支持这种复杂的开发需求,因此需要构建一个原则性的、完整的智能体学习生态系统。

Method: 提出Agentic Learning Ecosystem (ALE),包含三个核心组件:1) ROLL-权重优化的后训练框架;2) ROCK-用于轨迹生成的沙盒环境管理器;3) iFlow CLI-高效上下文工程的智能体框架。基于ALE训练ROME模型,使用超过100万条轨迹数据,采用数据组合协议合成复杂行为,并提出Interaction-based Policy Alignment (IPA)算法,该算法在语义交互块而非单个token层面分配信用,以提高长期训练稳定性。

Result: ROME模型在多个基准测试中表现出色,包括SWE-bench Verified和Terminal Bench等。研究还引入了Terminal Bench Pro基准测试,具有更好的规模和污染控制。实验结果证明了ALE基础设施的有效性,ROME在结构化设置下展现了强大的性能。

Conclusion: ALE为智能体大语言模型的开发提供了完整的基础设施解决方案,通过ROLL、ROCK和iFlow CLI三个组件实现了从数据生成到模型训练的全流程优化。基于ALE训练的开源模型ROME及其创新的IPA算法验证了该生态系统的有效性,为开源社区提供了可靠的智能体开发工具链,推动了智能体技术的发展和应用。

Abstract: Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.

</details>


### [21] [Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing](https://arxiv.org/abs/2512.24896)
*Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project's standardized format, strengthening the technological base for autonomous vehicle research in Poland.

</details>


### [22] [Iterative Deployment Improves Planning Skills in LLMs](https://arxiv.org/abs/2512.24940)
*Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal*

Main category: cs.AI

TL;DR: 本文研究了大语言模型的迭代部署机制,发现通过用户精心筛选的数据进行微调,模型性能会显著改变。研究揭示这一过程实际上在外循环中实现了强化学习,具有隐式奖励函数,这对AI安全和训练范式都有重要启示。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在实际部署中会经历迭代更新,每次使用用户筛选的数据进行微调。然而,这种迭代部署机制如何影响模型性能,以及其背后的理论机制尚不清楚。理解这一过程对于AI安全和模型训练方法具有重要意义,因为隐式的优化过程可能导致意外的模型行为变化。

Method: 研究者在多个规划领域测试了迭代部署机制,每次使用前一个模型部署后用户精心筛选的数据对模型进行微调。通过理论分析,证明了这种迭代部署过程实际上在外循环中实现了强化学习训练,其中包含一个隐式的奖励函数。该方法将数据筛选过程与强化学习框架建立了联系。

Result: 实验结果显示,迭代部署显著提升了模型的规划能力,后期模型展现出涌现的泛化能力,能够发现比初始模型长得多的规划方案。理论分析成功建立了迭代部署与强化学习之间的联系,揭示了隐式奖励函数的存在。

Conclusion: 迭代部署机制本质上是一种在外循环中进行的强化学习过程,具有隐式奖励函数。这一发现具有双重意义:一是对AI安全领域的警示,因为隐式奖励函数可能导致未预期的模型行为;二是提供了一种替代显式强化学习的训练范式,依赖数据筛选而非显式奖励信号,为模型训练提供了新的思路。

Abstract: We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.

</details>


### [23] [AMAP Agentic Planning Technical Report](https://arxiv.org/abs/2512.24957)
*Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo*

Main category: cs.AI

TL;DR: 本文提出STAgent,一个专门用于时空理解的智能体大语言模型,通过稳定的工具环境、层次化数据筛选框架和级联训练方法,能够处理复杂的兴趣点发现和行程规划任务,同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理复杂的时空场景任务(如受约束的兴趣点发现和行程规划)时能力不足,需要一个能够与多种工具交互、进行复杂推理并保持通用能力的专门化智能体模型。

Method: 提出三个关键贡献:(1)构建支持超过10个领域特定工具的稳定工具环境,支持异步展开和训练;(2)设计层次化数据筛选框架,以1:10,000的过滤比例从海量数据中筛选高质量、高多样性和高难度的查询;(3)采用级联训练方案,包括种子SFT阶段评估查询难度、第二SFT阶段针对高确定性查询微调,以及最终RL阶段利用低确定性数据进行强化学习。模型基于Qwen3-30B-A3B初始化。

Result: STAgent在TravelBench基准测试上取得了良好的性能表现,同时在广泛的通用基准测试中保持了其通用能力,验证了所提出的智能体模型的有效性。

Conclusion: 通过稳定的工具环境、高质量数据筛选和级联训练策略,STAgent成功实现了时空场景下的复杂任务处理能力,同时保留了大语言模型的通用能力,证明了该方法在构建专门化智能体模型方面的有效性。

Abstract: We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.

</details>

{"id": "2601.05256", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05256", "abs": "https://arxiv.org/abs/2601.05256", "authors": ["Eirini Baltzi", "Tilemachos Moumouris", "Athena Psalta", "Vasileios Tsironis", "Konstantinos Karantzalos"], "title": "Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring", "comment": null, "summary": "Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observation (EO) data. Designed for both experts and non-experts, NAIAD provides a single-prompt interface that translates natural-language queries into actionable insights. Through Retrieval-Augmented Generation (RAG), LLM reasoning, external tool orchestration, computational graph execution, and agentic reflection, it retrieves and synthesizes knowledge from curated sources to produce tailored reports. The system integrates diverse tools for weather data, Sentinel-2 imagery, remote-sensing index computation (e.g., NDCI), chlorophyll-a estimation, and established platforms such as CyFi. Performance is evaluated using correctness and relevancy metrics, achieving over 77% and 85% respectively on a dedicated benchmark covering multiple user-expertise levels. Preliminary results show strong adaptability and robustness across query types. An ablation study on LLM backbones further highlights Gemma 3 (27B) and Qwen 2.5 (14B) as offering the best balance between computational efficiency and reasoning performance.", "AI": {"tldr": "NAIAD\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fdAI\u52a9\u624b,\u901a\u8fc7\u6574\u5408\u591a\u79cd\u5206\u6790\u5de5\u5177\u548c\u5730\u7403\u89c2\u6d4b\u6570\u636e,\u4e3a\u5185\u9646\u6c34\u4f53\u76d1\u6d4b\u63d0\u4f9b\u5168\u9762\u7684\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u89e3\u51b3\u65b9\u6848,\u5728\u6b63\u786e\u6027\u548c\u76f8\u5173\u6027\u6307\u6807\u4e0a\u5206\u522b\u8fbe\u523077%\u548c85%\u4ee5\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u5185\u9646\u6c34\u4f53\u76d1\u6d4b\u65b9\u6cd5\u901a\u5e38\u53ea\u9488\u5bf9\u84dd\u85fb\u3001\u53f6\u7eff\u7d20\u6216\u5176\u4ed6\u6c34\u8d28\u6307\u6807\u7b49\u5b64\u7acb\u7684\u5b50\u95ee\u9898\u8fdb\u884c\u5355\u72ec\u5904\u7406,\u7f3a\u4e4f\u6574\u4f53\u6027\u89e3\u51b3\u65b9\u6848\u3002\u4e3a\u4e86\u4fdd\u969c\u516c\u5171\u5065\u5eb7\u548c\u751f\u6001\u7cfb\u7edf\u5b89\u5168,\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u4e3a\u4e13\u5bb6\u548c\u975e\u4e13\u5bb6\u7528\u6237\u63d0\u4f9b\u5168\u9762\u3001\u6613\u7528\u7684\u5185\u9646\u6c34\u4f53\u76d1\u6d4b\u7cfb\u7edf,\u5b9e\u73b0\u53ca\u65f6\u5e72\u9884\u4ee5\u964d\u4f4e\u98ce\u9669\u3002", "method": "NAIAD\u91c7\u7528\u667a\u80fd\u4f53AI\u67b6\u6784,\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u548c\u5916\u90e8\u5206\u6790\u5de5\u5177\u3002\u7cfb\u7edf\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u3001LLM\u63a8\u7406\u3001\u5916\u90e8\u5de5\u5177\u7f16\u6392\u3001\u8ba1\u7b97\u56fe\u6267\u884c\u548c\u667a\u80fd\u4f53\u53cd\u601d\u673a\u5236,\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u8f6c\u5316\u4e3a\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf\u3002\u7cfb\u7edf\u6574\u5408\u4e86\u5929\u6c14\u6570\u636e\u3001Sentinel-2\u536b\u661f\u5f71\u50cf\u3001\u9065\u611f\u6307\u6570\u8ba1\u7b97(\u5982NDCI)\u3001\u53f6\u7eff\u7d20-a\u4f30\u7b97\u4ee5\u53caCyFi\u7b49\u6210\u719f\u5e73\u53f0,\u4ece\u7cbe\u9009\u77e5\u8bc6\u6e90\u4e2d\u68c0\u7d22\u548c\u7efc\u5408\u4fe1\u606f\u751f\u6210\u5b9a\u5236\u5316\u62a5\u544a\u3002", "result": "\u5728\u6db5\u76d6\u591a\u4e2a\u7528\u6237\u4e13\u4e1a\u6c34\u5e73\u7684\u4e13\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d,NAIAD\u5728\u6b63\u786e\u6027\u6307\u6807\u4e0a\u8fbe\u523077%\u4ee5\u4e0a,\u5728\u76f8\u5173\u6027\u6307\u6807\u4e0a\u8fbe\u523085%\u4ee5\u4e0a\u3002\u521d\u6b65\u7ed3\u679c\u663e\u793a\u7cfb\u7edf\u5728\u4e0d\u540c\u67e5\u8be2\u7c7b\u578b\u4e0a\u5177\u6709\u5f3a\u5927\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660eGemma 3(27B)\u548cQwen 2.5(14B)\u5728\u8ba1\u7b97\u6548\u7387\u548c\u63a8\u7406\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "NAIAD\u6210\u529f\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u5185\u9646\u6c34\u4f53\u76d1\u6d4b\u52a9\u624b,\u901a\u8fc7\u5355\u4e00\u63d0\u793a\u754c\u9762\u4e3a\u4e0d\u540c\u4e13\u4e1a\u6c34\u5e73\u7684\u7528\u6237\u63d0\u4f9b\u5168\u9762\u7684\u6c34\u8d28\u76d1\u6d4b\u89e3\u51b3\u65b9\u6848\u3002\u7cfb\u7edf\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\u548c\u8de8\u67e5\u8be2\u7c7b\u578b\u7684\u9002\u5e94\u80fd\u529b,\u5176\u4e2d\u4e2d\u7b49\u89c4\u6a21\u7684\u5f00\u6e90\u6a21\u578b(Gemma 3 27B\u548cQwen 2.5 14B)\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f18,\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2601.05298", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05298", "abs": "https://arxiv.org/abs/2601.05298", "authors": ["Yeongbin Cha", "Namjung Kim"], "title": "Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing", "comment": "preprint", "summary": "Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge graph (AM-MKG) to enable reliable knowledge extraction and principled extrapolative modeling. By explicitly encoding equations, variables, assumptions, and their semantic relationships within a formal ontology, unstructured literature is transformed into machine-interpretable representations that support structured querying and reasoning. LLM-based equation generation is further conditioned on MKG-derived subgraphs, enforcing physically meaningful functional forms and mitigating non-physical or unstable extrapolation trends. To assess reliability beyond conventional predictive uncertainty, a confidence-aware extrapolation assessment is introduced, integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency into a unified confidence score. Results demonstrate that ontology-guided extraction significantly improves the structural coherence and quantitative reliability of extracted knowledge, while subgraph-conditioned equation generation yields stable and physically consistent extrapolations compared to unguided LLM outputs. Overall, this work establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, highlighting the potential of knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05302", "abs": "https://arxiv.org/abs/2601.05302", "authors": ["Mizuki Sakai", "Mizuki Yokoyama", "Wakaba Tateishi", "Genki Ichinose"], "title": "Effects of personality steering on cooperative behavior in Large Language Model agents", "comment": null, "summary": "Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4eba\u683c\u5f15\u5bfc\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u667a\u80fd\u4f53\u5728\u91cd\u590d\u56da\u5f92\u56f0\u5883\u535a\u5f08\u4e2d\u5408\u4f5c\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b9c\u4eba\u6027\u662f\u4fc3\u8fdb\u5408\u4f5c\u7684\u4e3b\u5bfc\u56e0\u7d20\uff0c\u800c\u4eba\u683c\u5f15\u5bfc\u66f4\u50cf\u662f\u884c\u4e3a\u504f\u5dee\u800c\u975e\u51b3\u5b9a\u6027\u63a7\u5236\u673a\u5236\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u6218\u7565\u548c\u793e\u4f1a\u4e92\u52a8\u4e2d\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u9700\u8981\u4e86\u89e3\u4e3aLLM\u5206\u914d\u4eba\u683c\u7279\u8d28\u5982\u4f55\u5728\u53d7\u63a7\u6761\u4ef6\u4e0b\u5f71\u54cd\u5176\u5408\u4f5c\u884c\u4e3a\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u8868\u660e\u4eba\u683c\u7279\u8d28\u53ef\u4ee5\u5f71\u54cdLLM\u884c\u4e3a\uff0c\u4f46\u4eba\u683c\u5f15\u5bfc\u5bf9\u5408\u4f5c\u7684\u5177\u4f53\u5f71\u54cd\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u4e94\u4eba\u683c\u91cf\u8868\uff08Big Five Inventory\uff09\u6d4b\u91cf\u4e09\u4e2a\u6a21\u578b\uff08GPT-3.5-turbo\u3001GPT-4o\u548cGPT-5\uff09\u7684\u57fa\u7840\u4eba\u683c\u6863\u6848\u3002\u901a\u8fc7\u91cd\u590d\u56da\u5f92\u56f0\u5883\u535a\u5f08\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u57fa\u7ebf\u6761\u4ef6\u548c\u4eba\u683c\u4fe1\u606f\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u8868\u73b0\uff0c\u5e76\u8fdb\u4e00\u6b65\u5206\u6790\u5c06\u6bcf\u4e2a\u4eba\u683c\u7ef4\u5ea6\u72ec\u7acb\u64cd\u7eb5\u81f3\u6781\u7aef\u503c\u65f6\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5b9c\u4eba\u6027\uff08agreeableness\uff09\u662f\u4fc3\u8fdb\u6240\u6709\u6a21\u578b\u5408\u4f5c\u7684\u4e3b\u5bfc\u56e0\u7d20\uff0c\u800c\u5176\u4ed6\u4eba\u683c\u7279\u8d28\u7684\u5f71\u54cd\u6709\u9650\u3002\u660e\u786e\u7684\u4eba\u683c\u4fe1\u606f\u4f1a\u589e\u52a0\u5408\u4f5c\uff0c\u4f46\u4e5f\u53ef\u80fd\u63d0\u9ad8\u88ab\u5229\u7528\u7684\u8106\u5f31\u6027\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u7248\u672c\u7684\u6a21\u578b\u4e2d\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u540e\u671f\u7248\u672c\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u5177\u9009\u62e9\u6027\u7684\u5408\u4f5c\u884c\u4e3a\u3002", "conclusion": "\u4eba\u683c\u5f15\u5bfc\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u66f4\u50cf\u662f\u4e00\u79cd\u884c\u4e3a\u504f\u5dee\uff08behavioral bias\uff09\u800c\u975e\u51b3\u5b9a\u6027\u7684\u63a7\u5236\u673a\u5236\u3002\u5b9c\u4eba\u6027\u662f\u5f71\u54cdLLM\u5408\u4f5c\u884c\u4e3a\u7684\u5173\u952e\u4eba\u683c\u7ef4\u5ea6\uff0c\u800c\u6a21\u578b\u7684\u8fed\u4ee3\u5347\u7ea7\u4f7f\u5176\u5728\u5408\u4f5c\u51b3\u7b56\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9009\u62e9\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2601.05330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05330", "abs": "https://arxiv.org/abs/2601.05330", "authors": ["Tengwei Song", "Long Yin", "Zhen Han", "Zhiqiang Xu"], "title": "Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings", "comment": null, "summary": "Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair interactions, the databases are often sparse, i.e., there are only limited and incomplete examples of such pairs, and also labor-intensive to maintain. This lack of sufficient training data significantly hinders the ability of traditional enzyme prediction models to generalize to unseen interactions. In this work, we try to exploit chemical reaction equations from domain-specific databases, given their easier accessibility and denser, more abundant data. However, interactions of multiple compounds, e.g., educts and products, with the same enzymes create complex relational data patterns that traditional models cannot easily capture. To tackle that, we represent chemical reaction equations as triples of (educt, enzyme, product) within a knowledge graph, such that we can take advantage of knowledge graph embedding (KGE) to infer missing enzyme-substrate pairs for graph completion. Particularly, in order to capture intricate relationships among compounds, we propose our knowledge-enhanced hypergraph model for enzyme prediction, i.e., Hyper-Enz, which integrates a hypergraph transformer with a KGE model to learn representations of the hyper-edges that involve multiple educts and products. Also, a multi-expert paradigm is introduced to guide the learning of enzyme-substrate interactions with both the proposed model and chemical reaction equations. Experimental results show a significant improvement, with up to a 88% relative improvement in average enzyme retrieval accuracy and 30% improvement in pair-level prediction compared to traditional models, demonstrating the effectiveness of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u548c\u8d85\u56fe\u7684\u9176-\u5e95\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u6a21\u578bHyper-Enz,\u901a\u8fc7\u5229\u7528\u5316\u5b66\u53cd\u5e94\u65b9\u7a0b\u5f0f\u6570\u636e\u548c\u8d85\u56fe\u53d8\u6362\u5668,\u5728\u9176\u68c0\u7d22\u51c6\u786e\u7387\u548c\u914d\u5bf9\u9884\u6d4b\u4e0a\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5206\u522b\u5b9e\u73b0\u4e8688%\u548c30%\u7684\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u9176-\u5e95\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e13\u5bb6\u6807\u6ce8\u7684\u7a00\u758f\u6570\u636e\u5e93,\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u5bfc\u81f4\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u867d\u7136\u5316\u5b66\u53cd\u5e94\u65b9\u7a0b\u5f0f\u6570\u636e\u66f4\u6613\u83b7\u53d6\u4e14\u66f4\u4e30\u5bcc,\u4f46\u591a\u4e2a\u5316\u5408\u7269(\u53cd\u5e94\u7269\u548c\u4ea7\u7269)\u4e0e\u540c\u4e00\u9176\u7684\u590d\u6742\u5173\u7cfb\u6a21\u5f0f\u96be\u4ee5\u88ab\u4f20\u7edf\u6a21\u578b\u6355\u83b7\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65b0\u65b9\u6cd5\u6765\u5229\u7528\u8fd9\u4e9b\u4e30\u5bcc\u7684\u53cd\u5e94\u65b9\u7a0b\u5f0f\u6570\u636e,\u5e76\u6709\u6548\u5efa\u6a21\u590d\u6742\u7684\u591a\u5143\u5173\u7cfb\u3002", "method": "\u5c06\u5316\u5b66\u53cd\u5e94\u65b9\u7a0b\u5f0f\u8868\u793a\u4e3a(\u53cd\u5e94\u7269,\u9176,\u4ea7\u7269)\u4e09\u5143\u7ec4\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31,\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165(KGE)\u63a8\u65ad\u7f3a\u5931\u7684\u9176-\u5e95\u7269\u914d\u5bf9\u3002\u63d0\u51faHyper-Enz\u6a21\u578b,\u6574\u5408\u8d85\u56fe\u53d8\u6362\u5668(hypergraph transformer)\u548cKGE\u6a21\u578b\u6765\u5b66\u4e60\u6d89\u53ca\u591a\u4e2a\u53cd\u5e94\u7269\u548c\u4ea7\u7269\u7684\u8d85\u8fb9\u8868\u793a,\u6355\u83b7\u5316\u5408\u7269\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002\u5f15\u5165\u591a\u4e13\u5bb6\u8303\u5f0f(multi-expert paradigm)\u6307\u5bfc\u6a21\u578b\u5b66\u4e60\u9176-\u5e95\u7269\u76f8\u4e92\u4f5c\u7528\u548c\u5316\u5b66\u53cd\u5e94\u65b9\u7a0b\u5f0f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a,\u4e0e\u4f20\u7edf\u6a21\u578b\u76f8\u6bd4,\u5e73\u5747\u9176\u68c0\u7d22\u51c6\u786e\u7387\u76f8\u5bf9\u63d0\u5347\u9ad8\u8fbe88%,\u914d\u5bf9\u7ea7\u522b\u9884\u6d4b\u63d0\u534730%,\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5316\u5b66\u53cd\u5e94\u65b9\u7a0b\u5f0f\u8868\u793a\u4e3a\u77e5\u8bc6\u56fe\u8c31\u5e76\u91c7\u7528\u8d85\u56fe\u53d8\u6362\u5668\u5efa\u6a21\u590d\u6742\u591a\u5143\u5173\u7cfb,Hyper-Enz\u6a21\u578b\u6210\u529f\u89e3\u51b3\u4e86\u9176-\u5e95\u7269\u76f8\u4e92\u4f5c\u7528\u9884\u6d4b\u4e2d\u8bad\u7ec3\u6570\u636e\u7a00\u758f\u7684\u95ee\u9898,\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd,\u4e3a\u751f\u7269\u5316\u5b66\u548c\u4ee3\u8c22\u5de5\u7a0b\u9886\u57df\u7684\u9176\u9884\u6d4b\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05376", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05376", "abs": "https://arxiv.org/abs/2601.05376", "authors": ["Tassallah Abdullahi", "Shrestha Ghosh", "Hamish S Fraser", "Daniel Le\u00f3n Tramontini", "Adeel Abbasi", "Ghada Bourjeily", "Carsten Eickhoff", "Ritambhara Singh"], "title": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models", "comment": null, "summary": "Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to $\\sim+20\\%$ in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's $\u03ba= 0.43$) but indicate a low confidence in 95.9\\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\\_Paradox.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4eba\u683c\u89d2\u8272\u8bbe\u5b9a\u5bf9\u4e34\u5e8a\u5927\u8bed\u8a00\u6a21\u578b\u51b3\u7b56\u7684\u5f71\u54cd,\u53d1\u73b0\u533b\u7597\u4eba\u683c\u89d2\u8272\u5728\u5173\u952e\u62a4\u7406\u4efb\u52a1\u4e2d\u53ef\u63d0\u5347\u7ea620%\u7684\u51c6\u786e\u7387\u548c\u6821\u51c6\u5ea6,\u4f46\u5728\u521d\u7ea7\u62a4\u7406\u573a\u666f\u4e2d\u53cd\u800c\u964d\u4f4e\u6027\u80fd,\u63ed\u793a\u4e86\u4eba\u683c\u89d2\u8272\u4f5c\u4e3a\u884c\u4e3a\u5148\u9a8c\u5f15\u5165\u7684\u662f\u60c5\u5883\u4f9d\u8d56\u7684\u6743\u8861\u800c\u975e\u5b89\u5168\u6216\u4e13\u4e1a\u6027\u7684\u4fdd\u8bc1\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u683c\u89d2\u8272\u8bbe\u5b9a\u901a\u5e38\u88ab\u5047\u8bbe\u80fd\u5355\u8c03\u5730\u63d0\u5347\u4e13\u4e1a\u6027\u548c\u5b89\u5168\u6027,\u4f46\u5176\u5728\u9ad8\u98ce\u9669\u4e34\u5e8a\u51b3\u7b56\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u8868\u5f81\u3002\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u4e13\u4e1a\u89d2\u8272(\u5982\u6025\u8bca\u533b\u751f\u3001\u62a4\u58eb)\u548c\u4ea4\u4e92\u98ce\u683c(\u5927\u80c6vs\u8c28\u614e)\u5982\u4f55\u5f71\u54cd\u4e34\u5e8aLLMs\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\u8868\u73b0\u3002", "method": "\u91c7\u7528\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6,\u5728\u4e34\u5e8a\u5206\u8bca\u548c\u60a3\u8005\u5b89\u5168\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u4e0d\u540c\u4eba\u683c\u89d2\u8272\u8bbe\u5b9a\u7684LLMs,\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u4efb\u52a1\u51c6\u786e\u6027\u3001\u6821\u51c6\u5ea6\u548c\u5b89\u5168\u76f8\u5173\u7684\u98ce\u9669\u884c\u4e3a\u3002\u5bf9\u6bd4\u533b\u7597\u4e13\u4e1a\u89d2\u8272\u4e0e\u975e\u533b\u7597\u89d2\u8272\u3001\u4e0d\u540c\u4ea4\u4e92\u98ce\u683c\u7684\u5f71\u54cd,\u5e76\u7ed3\u5408LLM\u8bc4\u5224\u6392\u540d\u548c\u4eba\u7c7b\u4e34\u5e8a\u533b\u751f\u8bc4\u4f30(\u4f7f\u7528Cohen's \u03ba\u8861\u91cf\u4e00\u81f4\u6027)\u8fdb\u884c\u7efc\u5408\u5206\u6790\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u3001\u60c5\u5883\u4f9d\u8d56\u4e14\u975e\u5355\u8c03\u7684\u6548\u679c:\u533b\u7597\u4eba\u683c\u89d2\u8272\u5728\u91cd\u75c7\u76d1\u62a4\u4efb\u52a1\u4e2d\u4f7f\u51c6\u786e\u7387\u548c\u6821\u51c6\u5ea6\u63d0\u5347\u7ea620%,\u4f46\u5728\u521d\u7ea7\u62a4\u7406\u573a\u666f\u4e2d\u5bfc\u81f4\u76f8\u5f53\u5e45\u5ea6\u7684\u6027\u80fd\u4e0b\u964d\u3002\u4ea4\u4e92\u98ce\u683c\u8c03\u8282\u98ce\u9669\u503e\u5411\u548c\u654f\u611f\u6027,\u4f46\u9ad8\u5ea6\u4f9d\u8d56\u5177\u4f53\u6a21\u578b\u3002LLM\u8bc4\u5224\u5728\u5b89\u5168\u5173\u952e\u6848\u4f8b\u4e2d\u503e\u5411\u533b\u7597\u4eba\u683c\u89d2\u8272,\u4f46\u4eba\u7c7b\u4e34\u5e8a\u533b\u751f\u5bf9\u5b89\u5168\u5408\u89c4\u6027\u4ec5\u663e\u793a\u4e2d\u7b49\u4e00\u81f4\u6027(\u5e73\u5747Cohen's \u03ba=0.43),\u4e1495.9%\u7684\u63a8\u7406\u8d28\u91cf\u8bc4\u4f30\u663e\u793a\u4f4e\u7f6e\u4fe1\u5ea6\u3002", "conclusion": "\u4eba\u683c\u89d2\u8272\u8bbe\u5b9a\u4f5c\u4e3a\u884c\u4e3a\u5148\u9a8c\u5f15\u5165\u7684\u662f\u60c5\u5883\u4f9d\u8d56\u7684\u6743\u8861,\u800c\u975e\u5b89\u5168\u6027\u6216\u4e13\u4e1a\u6027\u7684\u7edd\u5bf9\u4fdd\u8bc1\u3002\u533b\u7597\u4eba\u683c\u89d2\u8272\u7684\u6548\u679c\u5728\u4e0d\u540c\u4e34\u5e8a\u573a\u666f\u4e2d\u5b58\u5728\u663e\u8457\u5dee\u5f02,\u9700\u8981\u6839\u636e\u5177\u4f53\u5e94\u7528\u60c5\u5883\u8c28\u614e\u9009\u62e9\u548c\u914d\u7f6e\u4eba\u683c\u89d2\u8272\u53c2\u6570,\u4e0d\u80fd\u7b80\u5355\u5047\u8bbe\u5176\u5e26\u6765\u5355\u5411\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2601.05384", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.05384", "abs": "https://arxiv.org/abs/2601.05384", "authors": ["Alessandro Bellina", "Giordano De Marzo", "David Garcia"], "title": "Conformity and Social Impact on AI Agents", "comment": null, "summary": "As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting the dynamics of artificial societies. This study examines conformity, the tendency to align with group opinions under social pressure, in large multimodal language models functioning as AI agents. By adapting classic visual experiments from social psychology, we investigate how AI agents respond to group influence as social actors. Our experiments reveal that AI agents exhibit a systematic conformity bias, aligned with Social Impact Theory, showing sensitivity to group size, unanimity, task difficulty, and source characteristics. Critically, AI agents achieving near-perfect performance in isolation become highly susceptible to manipulation through social influence. This vulnerability persists across model scales: while larger models show reduced conformity on simple tasks due to improved capabilities, they remain vulnerable when operating at their competence boundary. These findings reveal fundamental security vulnerabilities in AI agent decision-making that could enable malicious manipulation, misinformation campaigns, and bias propagation in multi-agent systems, highlighting the urgent need for safeguards in collective AI deployments.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6539\u7f16\u7ecf\u5178\u793e\u4f1a\u5fc3\u7406\u5b66\u89c6\u89c9\u5b9e\u9a8c,\u63ed\u793a\u4e86\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3aAI\u667a\u80fd\u4f53\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u7684\u4ece\u4f17\u504f\u5dee,\u5373\u4f7f\u5728\u5355\u72ec\u6267\u884c\u65f6\u8868\u73b0\u8fd1\u4e4e\u5b8c\u7f8e\u7684AI\u667a\u80fd\u4f53\u4e5f\u6781\u6613\u53d7\u5230\u7fa4\u4f53\u5f71\u54cd\u7684\u64cd\u7eb5,\u8fd9\u79cd\u8106\u5f31\u6027\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e2d\u6301\u7eed\u5b58\u5728,\u66b4\u9732\u4e86AI\u667a\u80fd\u4f53\u51b3\u7b56\u4e2d\u7684\u6839\u672c\u6027\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740AI\u667a\u80fd\u4f53\u8d8a\u6765\u8d8a\u591a\u5730\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u8fd0\u884c,\u7406\u89e3\u5b83\u4eec\u7684\u96c6\u4f53\u884c\u4e3a\u5bf9\u4e8e\u9884\u6d4b\u4eba\u5de5\u793e\u4f1a\u7684\u52a8\u6001\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u8005\u9700\u8981\u4e86\u89e3AI\u667a\u80fd\u4f53\u662f\u5426\u4f1a\u50cf\u4eba\u7c7b\u4e00\u6837\u5728\u793e\u4f1a\u538b\u529b\u4e0b\u8868\u73b0\u51fa\u4ece\u4f17\u884c\u4e3a,\u4ee5\u53ca\u8fd9\u79cd\u884c\u4e3a\u53ef\u80fd\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669,\u5305\u62ec\u6076\u610f\u64cd\u7eb5\u3001\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u548c\u504f\u89c1\u6269\u6563\u7b49\u95ee\u9898\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u6539\u7f16\u81ea\u793e\u4f1a\u5fc3\u7406\u5b66\u7684\u7ecf\u5178\u89c6\u89c9\u5b9e\u9a8c\u65b9\u6cd5,\u5c06\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3aAI\u667a\u80fd\u4f53\u8fdb\u884c\u6d4b\u8bd5\u3002\u5b9e\u9a8c\u8bbe\u8ba1\u8003\u5bdf\u4e86AI\u667a\u80fd\u4f53\u5728\u7fa4\u4f53\u5f71\u54cd\u4e0b\u7684\u53cd\u5e94,\u7cfb\u7edf\u6027\u5730\u6d4b\u8bd5\u4e86\u591a\u4e2a\u53d8\u91cf\u7684\u5f71\u54cd,\u5305\u62ec\u7fa4\u4f53\u89c4\u6a21\u3001\u4e00\u81f4\u6027\u7a0b\u5ea6\u3001\u4efb\u52a1\u96be\u5ea6\u3001\u4fe1\u606f\u6e90\u7279\u5f81\u7b49\u56e0\u7d20,\u5e76\u5bf9\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790,\u7279\u522b\u5173\u6ce8\u667a\u80fd\u4f53\u5728\u5176\u80fd\u529b\u8fb9\u754c\u5904\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a,AI\u667a\u80fd\u4f53\u8868\u73b0\u51fa\u4e0e\u793e\u4f1a\u5f71\u54cd\u7406\u8bba\u4e00\u81f4\u7684\u7cfb\u7edf\u6027\u4ece\u4f17\u504f\u5dee,\u5bf9\u7fa4\u4f53\u89c4\u6a21\u3001\u4e00\u81f4\u6027\u3001\u4efb\u52a1\u96be\u5ea6\u548c\u4fe1\u606f\u6e90\u7279\u5f81\u8868\u73b0\u51fa\u654f\u611f\u6027\u3002\u5173\u952e\u53d1\u73b0\u662f,\u5373\u4f7f\u5728\u5355\u72ec\u6267\u884c\u65f6\u80fd\u8fbe\u5230\u8fd1\u4e4e\u5b8c\u7f8e\u8868\u73b0\u7684AI\u667a\u80fd\u4f53,\u5728\u793e\u4f1a\u5f71\u54cd\u4e0b\u4e5f\u53d8\u5f97\u9ad8\u5ea6\u6613\u53d7\u64cd\u7eb5\u3002\u8fd9\u79cd\u8106\u5f31\u6027\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e2d\u6301\u7eed\u5b58\u5728:\u867d\u7136\u66f4\u5927\u7684\u6a21\u578b\u7531\u4e8e\u80fd\u529b\u63d0\u5347\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8f83\u5c11\u7684\u4ece\u4f17\u884c\u4e3a,\u4f46\u5f53\u5b83\u4eec\u5728\u80fd\u529b\u8fb9\u754c\u5904\u8fd0\u884c\u65f6\u4ecd\u7136\u4fdd\u6301\u8106\u5f31\u6027\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86AI\u667a\u80fd\u4f53\u51b3\u7b56\u4e2d\u5b58\u5728\u7684\u6839\u672c\u6027\u5b89\u5168\u6f0f\u6d1e,\u8fd9\u4e9b\u6f0f\u6d1e\u53ef\u80fd\u88ab\u7528\u4e8e\u6076\u610f\u64cd\u7eb5\u3001\u865a\u5047\u4fe1\u606f\u5ba3\u4f20\u6d3b\u52a8\u4ee5\u53ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u4f20\u64ad\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u96c6\u4f53AI\u90e8\u7f72\u4e2d\u5efa\u7acb\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\u7684\u8feb\u5207\u9700\u6c42,\u5bf9\u4e8e\u672a\u6765\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b89\u5168\u8bbe\u8ba1\u548c\u98ce\u9669\u9632\u8303\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.05386", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05386", "abs": "https://arxiv.org/abs/2601.05386", "authors": ["Daniel Keren"], "title": "On the Effect of Cheating in Chess", "comment": null, "summary": "Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\\footnote{Needless to say, the goal of this work is not to assist cheaters, but to measure the effectiveness of cheating -- which is crucial as part of the effort to contain and detect it.}", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u56fd\u9645\u8c61\u68cb\u4f5c\u5f0a\u95ee\u9898,\u4e0d\u540c\u4e8e\u4ee5\u5f80\u4fa7\u91cd\u68c0\u6d4b\u4f5c\u5f0a\u7684\u7814\u7a76,\u672c\u6587\u8bc4\u4f30\u5728\u6bd4\u8d5b\u4e2d\u6709\u9650\u6b21\u6570\u4f7f\u7528\u8f6f\u4ef6\u8f85\u52a9\u6240\u80fd\u83b7\u5f97\u7684\u6027\u80fd\u63d0\u5347,\u5e76\u5728\u5e38\u7528\u56fd\u9645\u8c61\u68cb\u5f15\u64ce\u4e0a\u5f00\u53d1\u548c\u6d4b\u8bd5\u76f8\u5173\u7b97\u6cd5\u3002", "motivation": "\u56fd\u9645\u8c61\u68cb\u4f5c\u5f0a(\u4f7f\u7528\u5f3a\u5927\u8f6f\u4ef6\u8f85\u52a9)\u5df2\u6210\u4e3a\u4e25\u91cd\u95ee\u9898,\u751a\u81f3\u5f71\u54cd\u5230\u6700\u9ad8\u6c34\u5e73\u7684\u6bd4\u8d5b\u3002\u4ee5\u5f80\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u4f5c\u5f0a\u68c0\u6d4b,\u4f46\u7f3a\u4e4f\u5bf9\u6709\u9650\u6b21\u6570\u4f5c\u5f0a\u6240\u5e26\u6765\u7684\u5b9e\u9645\u6027\u80fd\u589e\u76ca\u7684\u91cf\u5316\u8bc4\u4f30\u3002\u4e86\u89e3\u4f5c\u5f0a\u7684\u6709\u6548\u6027\u5bf9\u4e8e\u904f\u5236\u548c\u68c0\u6d4b\u4f5c\u5f0a\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f00\u53d1\u7b97\u6cd5\u6765\u8bc4\u4f30\u5728\u6bd4\u8d5b\u4e2d\u6709\u9650\u6b21\u6570\u4f7f\u7528\u8f6f\u4ef6\u8f85\u52a9\u7684\u6027\u80fd\u589e\u76ca,\u5e76\u5728\u5e38\u7528\u7684\u56fd\u9645\u8c61\u68cb\u5f15\u64ce(\u8f6f\u4ef6)\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u548c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u7b97\u6cd5\u6d4b\u8bd5,\u91cf\u5316\u5206\u6790\u4e86\u5728\u56fd\u9645\u8c61\u68cb\u6bd4\u8d5b\u4e2d\u6709\u9650\u6b21\u6570\u4f5c\u5f0a\u5bf9\u6027\u80fd\u63d0\u5347\u7684\u5f71\u54cd\u7a0b\u5ea6(\u6458\u8981\u672a\u63d0\u4f9b\u5177\u4f53\u6570\u503c\u7ed3\u679c)\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u91cf\u5316\u8bc4\u4f30\u6709\u9650\u6b21\u6570\u4f5c\u5f0a\u7684\u6548\u679c,\u4e3a\u7406\u89e3\u4f5c\u5f0a\u884c\u4e3a\u7684\u5b9e\u9645\u5f71\u54cd\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2,\u8fd9\u5bf9\u4e8e\u5f00\u53d1\u66f4\u6709\u6548\u7684\u4f5c\u5f0a\u68c0\u6d4b\u548c\u904f\u5236\u63aa\u65bd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7814\u7a76\u76ee\u7684\u4e0d\u662f\u534f\u52a9\u4f5c\u5f0a\u8005,\u800c\u662f\u4e3a\u53cd\u4f5c\u5f0a\u5de5\u4f5c\u63d0\u4f9b\u79d1\u5b66\u4f9d\u636e\u3002"}}
{"id": "2601.05455", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05455", "abs": "https://arxiv.org/abs/2601.05455", "authors": ["Sahil Wadhwa", "Himanshu Kumar", "Guanqun Yang", "Abbaas Alif Mohamed Nishar", "Pranab Mohanty", "Swapnil Shinde", "Yue Wu"], "title": "ART: Adaptive Reasoning Trees for Explainable Claim Verification", "comment": null, "summary": "Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim verification. The process begins with a root claim, which branches into supporting and attacking child arguments. An argument's strength is determined bottom-up via a pairwise tournament of its children, adjudicated by a judge LLM, allowing a final, transparent and contestable verdict to be systematically derived which is missing in methods like Chain-of-Thought (CoT). We empirically validate ART on multiple datasets, analyzing different argument generators and comparison strategies. Our findings show that ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification which is more reliable and ensures clarity in the overall decision making step.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.05483", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05483", "abs": "https://arxiv.org/abs/2601.05483", "authors": ["Zixuan Xiao", "Jun Ma", "Siwei Zhang"], "title": "MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis", "comment": null, "summary": "Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChange, a multi-modal agent framework that flexibly integrates heterogeneous urban data via a modular toolkit and a core module, Modality Controller for cross- and intra-modal alignment, enabling robust analysis of complex urban change scenarios. Case studies include: a shift toward small, community-focused parks in New York, reflecting local green space efforts; the spread of concentrated water pollution across districts in Hong Kong, pointing to coordinated water management; and a notable decline in open dumpsites in Shenzhen, with contrasting links between nighttime economic activity and waste types, indicating differing urban pressures behind domestic and construction waste. Compared to the best-performing baseline, the MMUEChange agent achieves a 46.7% improvement in task success rate and effectively mitigates hallucination, demonstrating its capacity to support complex urban change analysis tasks with real-world policy implications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMMUEChange\u591a\u6a21\u6001\u667a\u80fd\u4f53\u6846\u67b6,\u901a\u8fc7\u6a21\u5757\u5316\u5de5\u5177\u5305\u548c\u6a21\u6001\u63a7\u5236\u5668\u5b9e\u73b0\u5f02\u6784\u57ce\u5e02\u6570\u636e\u7684\u7075\u6d3b\u6574\u5408,\u7528\u4e8e\u590d\u6742\u57ce\u5e02\u73af\u5883\u53d8\u5316\u5206\u6790,\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u6a21\u578b\u4efb\u52a1\u6210\u529f\u7387\u63d0\u534746.7%,\u5e76\u6709\u6548\u7f13\u89e3\u5e7b\u89c9\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57ce\u5e02\u73af\u5883\u53d8\u5316\u5206\u6790\u65b9\u6cd5(\u7279\u522b\u662f\u9065\u611f\u53d8\u5316\u68c0\u6d4b)\u5f80\u5f80\u4f9d\u8d56\u4e8e\u50f5\u5316\u7684\u5355\u6a21\u6001\u5206\u6790,\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u7684\u57ce\u5e02\u53d8\u5316\u573a\u666f\u3002\u4e3a\u5b9e\u73b0\u53ef\u6301\u7eed\u53d1\u5c55,\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7075\u6d3b\u6574\u5408\u5f02\u6784\u57ce\u5e02\u6570\u636e\u3001\u652f\u6301\u8de8\u6a21\u6001\u548c\u6a21\u6001\u5185\u5bf9\u9f50\u7684\u9c81\u68d2\u5206\u6790\u6846\u67b6\u3002", "method": "\u63d0\u51faMMUEChange\u591a\u6a21\u6001\u667a\u80fd\u4f53\u6846\u67b6,\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6:(1)\u6a21\u5757\u5316\u5de5\u5177\u5305,\u7528\u4e8e\u6574\u5408\u5f02\u6784\u57ce\u5e02\u6570\u636e;(2)\u6a21\u6001\u63a7\u5236\u5668(Modality Controller),\u5b9e\u73b0\u8de8\u6a21\u6001\u548c\u6a21\u6001\u5185\u5bf9\u9f50\u3002\u8be5\u6846\u67b6\u80fd\u591f\u7075\u6d3b\u5904\u7406\u591a\u6e90\u57ce\u5e02\u6570\u636e,\u652f\u6301\u590d\u6742\u57ce\u5e02\u53d8\u5316\u573a\u666f\u7684\u9c81\u68d2\u5206\u6790\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u57ce\u5e02\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027:\u7ebd\u7ea6\u5c0f\u578b\u793e\u533a\u516c\u56ed\u589e\u52a0\u53cd\u6620\u672c\u5730\u7eff\u5730\u5efa\u8bbe\u52aa\u529b;\u9999\u6e2f\u8de8\u533a\u57df\u96c6\u4e2d\u6c34\u6c61\u67d3\u6269\u6563\u6307\u5411\u534f\u8c03\u6c34\u7ba1\u7406\u9700\u6c42;\u6df1\u5733\u9732\u5929\u5783\u573e\u573a\u663e\u8457\u51cf\u5c11,\u591c\u95f4\u7ecf\u6d4e\u6d3b\u52a8\u4e0e\u4e0d\u540c\u5e9f\u7269\u7c7b\u578b\u5448\u73b0\u5bf9\u6bd4\u6027\u5173\u8054\u3002\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\u6a21\u578b,MMUEChange\u5728\u4efb\u52a1\u6210\u529f\u7387\u4e0a\u63d0\u534746.7%,\u5e76\u6709\u6548\u7f13\u89e3\u4e86\u5e7b\u89c9\u95ee\u9898\u3002", "conclusion": "MMUEChange\u6846\u67b6\u5c55\u793a\u4e86\u5904\u7406\u590d\u6742\u57ce\u5e02\u53d8\u5316\u5206\u6790\u4efb\u52a1\u7684\u80fd\u529b,\u5177\u6709\u5b9e\u9645\u653f\u7b56\u5e94\u7528\u4ef7\u503c\u3002\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u548c\u667a\u80fd\u5bf9\u9f50\u673a\u5236,\u8be5\u6846\u67b6\u80fd\u591f\u4e3a\u57ce\u5e02\u53ef\u6301\u7eed\u53d1\u5c55\u63d0\u4f9b\u66f4\u51c6\u786e\u3001\u66f4\u5168\u9762\u7684\u73af\u5883\u53d8\u5316\u6d1e\u5bdf,\u514b\u670d\u4e86\u4f20\u7edf\u5355\u6a21\u6001\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2601.05500", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05500", "abs": "https://arxiv.org/abs/2601.05500", "authors": ["Aparna Elangovan", "Lei Xu", "Mahsa Elyasi", "Ismail Akdulum", "Mehmet Aksakal", "Enes Gurun", "Brian Hur", "Saab Mansour", "Ravid Shwartz Ziv", "Karin Verspoor", "Dan Roth"], "title": "The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm", "comment": null, "summary": "Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability.\n  Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u8303\u5f0f\u6765\u89e3\u51b3AI\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5ffd\u7565\u4e13\u5bb6\u6807\u6ce8\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898,\u7279\u522b\u662f\u5728\u533b\u5b66\u7b49\u4e0d\u786e\u5b9a\u6027\u666e\u904d\u5b58\u5728\u7684\u9886\u57df\u3002\u7814\u7a76\u5f15\u5165\u4e86\u671f\u671b\u51c6\u786e\u7387\u548c\u671f\u671bF1\u7b49\u6982\u5ff5,\u5e76\u5efa\u8bae\u6839\u636e\u771f\u5b9e\u7b54\u6848\u7684\u6982\u7387(\u901a\u8fc7\u4e13\u5bb6\u4e00\u81f4\u6027\u8861\u91cf)\u5bf9\u7ed3\u679c\u8fdb\u884c\u5206\u5c42\u8bc4\u4f30,\u4ee5\u66f4\u53ef\u9760\u5730\u6bd4\u8f83\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf(\u5305\u62ec\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u6a21\u578b)\u7684\u57fa\u51c6\u6d4b\u8bd5\u901a\u5e38\u5ffd\u7565\u4e86\u4e13\u5bb6\u6807\u6ce8\u771f\u5b9e\u7b54\u6848\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u5f71\u54cd\u3002\u8fd9\u79cd\u6a21\u7cca\u6027\u5728\u533b\u5b66\u7b49\u4e0d\u786e\u5b9a\u6027\u666e\u904d\u5b58\u5728\u7684\u9886\u57df\u5c24\u4e3a\u91cd\u8981\u3002\u5ffd\u7565\u771f\u5b9e\u7b54\u6848\u7684\u4e0d\u786e\u5b9a\u6027\u53ef\u80fd\u5bfc\u81f4\u8bef\u5bfc\u6027\u7ed3\u8bba,\u4f7f\u975e\u4e13\u5bb6\u7cfb\u7edf\u770b\u8d77\u6765\u4e0e\u4e13\u5bb6\u8868\u73b0\u76f8\u4f3c\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u8303\u5f0f\u6765\u51c6\u786e\u8861\u91cfAI\u7cfb\u7edf\u5728\u5b58\u5728\u6807\u6ce8\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\u4e0b\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u8303\u5f0f\u6765\u7406\u8bba\u89e3\u91ca\u771f\u5b9e\u7b54\u6848\u7684\u786e\u5b9a\u6027\u4e0e\u7cfb\u7edf\u5f97\u5206\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5f15\u5165\u4e86\"\u671f\u671b\u51c6\u786e\u7387\"(expected accuracy)\u548c\"\u671f\u671bF1\"(expected F1)\u4e24\u4e2a\u65b0\u6982\u5ff5,\u7528\u4e8e\u4f30\u8ba1\u5728\u7ed9\u5b9a\u771f\u5b9e\u7b54\u6848\u53d8\u5f02\u6027\u7684\u60c5\u51b5\u4e0b,\u4e13\u5bb6\u6216\u7cfb\u7edf\u80fd\u591f\u8fbe\u5230\u7684\u5206\u6570\u3002\u6838\u5fc3\u65b9\u6cd5\u662f\u6839\u636e\u771f\u5b9e\u7b54\u6848\u7684\u6982\u7387(\u901a\u5e38\u901a\u8fc7\u4e13\u5bb6\u6807\u6ce8\u8005\u7684\u4e00\u81f4\u6027\u7387\u6765\u8861\u91cf)\u5bf9\u8bc4\u4f30\u7ed3\u679c\u8fdb\u884c\u5206\u5c42,\u7279\u522b\u662f\u5f53\u6574\u4f53\u6027\u80fd\u4f4e\u4e8e80%\u9608\u503c\u65f6,\u5206\u5c42\u8bc4\u4f30\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "result": "\u7814\u7a76\u8868\u660e,\u5728\u9ad8\u786e\u5b9a\u6027\u7684\u771f\u5b9e\u7b54\u6848\u6570\u636e\u96c6\u4e2d,\u4e13\u5bb6\u624d\u80fd\u83b7\u5f97\u9ad8\u5206;\u800c\u5728\u771f\u5b9e\u7b54\u6848\u53d8\u5f02\u6027\u9ad8\u7684\u6570\u636e\u96c6\u4e2d,\u968f\u673a\u6807\u6ce8\u8005\u548c\u4e13\u5bb6\u4e4b\u95f4\u53ef\u80fd\u51e0\u4e4e\u6ca1\u6709\u5dee\u5f02\u3002\u901a\u8fc7\u5206\u5c42\u8bc4\u4f30,\u5728\u9ad8\u786e\u5b9a\u6027\u533a\u95f4\u5185\u7684\u6027\u80fd\u6bd4\u8f83\u53d8\u5f97\u66f4\u52a0\u53ef\u9760,\u6709\u6548\u7f13\u89e3\u4e86\u4e0d\u786e\u5b9a\u6027\u8fd9\u4e00\u5173\u952e\u6df7\u6dc6\u56e0\u7d20\u7684\u5f71\u54cd\u3002\u8fd9\u4e3a\u66f4\u51c6\u786e\u5730\u8bc4\u4f30AI\u7cfb\u7edf\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002", "conclusion": "\u5728\u5efa\u7acbAI\u7cfb\u7edf\u80fd\u529b\u8bc4\u4f30\u65f6,\u5e94\u8be5\u6839\u636e\u771f\u5b9e\u7b54\u6848\u7684\u6982\u7387(\u901a\u8fc7\u4e13\u5bb6\u4e00\u81f4\u6027\u7387\u6d4b\u91cf)\u5bf9\u7ed3\u679c\u8fdb\u884c\u5206\u5c42\u62a5\u544a\u3002\u5f53\u6574\u4f53\u6027\u80fd\u4f4e\u4e8e80%\u65f6,\u5206\u5c42\u8bc4\u4f30\u5c24\u4e3a\u5173\u952e\u3002\u5206\u5c42\u8bc4\u4f30\u4f7f\u5f97\u5728\u9ad8\u786e\u5b9a\u6027\u533a\u95f4\u5185\u7684\u6027\u80fd\u6bd4\u8f83\u66f4\u52a0\u53ef\u9760,\u51cf\u8f7b\u4e86\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u5173\u952e\u6df7\u6dc6\u56e0\u7d20\u7684\u5f71\u54cd,\u4ece\u800c\u907f\u514d\u5bf9\u7cfb\u7edf\u80fd\u529b\u4ea7\u751f\u8bef\u5bfc\u6027\u8bc4\u4ef7\u3002"}}
{"id": "2601.05525", "categories": ["cs.AI", "cs.LG", "physics.comp-ph", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.05525", "abs": "https://arxiv.org/abs/2601.05525", "authors": ["Ricardo Vinuesa", "Steven L. Brunton", "Gianmarco Mengaldo"], "title": "Explainable AI: Learning from the Learners", "comment": null, "summary": "Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd(XAI)\u4e0e\u56e0\u679c\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\"\u4ece\u5b66\u4e60\u8005\u4e2d\u5b66\u4e60\"\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u7840\u6a21\u578b\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5728\u79d1\u5b66\u53d1\u73b0\u3001\u4f18\u5316\u548c\u8ba4\u8bc1\u7b49\u9886\u57df\u63d0\u53d6\u56e0\u679c\u673a\u5236\u3001\u6307\u5bfc\u7a33\u5065\u8bbe\u8ba1\u5e76\u652f\u6301\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u4fe1\u4efb\u4e0e\u95ee\u8d23\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u5728\u591a\u4e2a\u79d1\u5b66\u548c\u5de5\u7a0b\u4efb\u52a1\u4e2d\u5df2\u8d85\u8d8a\u4eba\u7c7b\u8868\u73b0\uff0c\u4f46\u5176\u5185\u90e8\u8868\u5f81\u5f80\u5f80\u4e0d\u900f\u660e\u3002\u4e3a\u4e86\u5145\u5206\u5229\u7528AI\u7684\u80fd\u529b\u5e76\u5efa\u7acb\u4eba\u673a\u534f\u4f5c\uff0c\u9700\u8981\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7406\u89e3AI\u7684\u51b3\u7b56\u673a\u5236\uff0c\u63d0\u53d6\u6709\u4ef7\u503c\u7684\u77e5\u8bc6\uff0c\u5e76\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u5efa\u7acb\u4fe1\u4efb\u548c\u95ee\u8d23\u673a\u5236\u3002", "method": "\u63d0\u51fa\u5c06\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd(XAI)\u4e0e\u56e0\u679c\u63a8\u7406\u76f8\u7ed3\u5408\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u805a\u7126\u4e8e\u4e09\u4e2a\u6838\u5fc3\u5e94\u7528\u9886\u57df\uff1a\u53d1\u73b0(discovery)\u3001\u4f18\u5316(optimization)\u548c\u8ba4\u8bc1(certification)\u3002\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u6765\u63d0\u53d6\u56e0\u679c\u673a\u5236\u3001\u6307\u5bfc\u7a33\u5065\u7684\u8bbe\u8ba1\u4e0e\u63a7\u5236\uff0c\u5e76\u652f\u6301\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u4fe1\u4efb\u5efa\u7acb\u3002", "result": "\u5c55\u793a\u4e86\u57fa\u7840\u6a21\u578b\u4e0e\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u7ed3\u5408\u5982\u4f55\u5b9e\u73b0\uff1a(1)\u63d0\u53d6\u56e0\u679c\u673a\u5236\u7528\u4e8e\u79d1\u5b66\u53d1\u73b0\uff1b(2)\u6307\u5bfc\u7a33\u5065\u7684\u8bbe\u8ba1\u548c\u63a7\u5236\u4f18\u5316\uff1b(3)\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u652f\u6301\u4fe1\u4efb\u548c\u95ee\u8d23\u3002\u540c\u65f6\u8ba8\u8bba\u4e86\u89e3\u91ca\u65b9\u6cd5\u5728\u5fe0\u5b9e\u6027(faithfulness)\u3001\u6cdb\u5316\u80fd\u529b(generalization)\u548c\u53ef\u7528\u6027(usability)\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\u3002", "conclusion": "\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd(XAI)\u53ef\u4ee5\u4f5c\u4e3a\u79d1\u5b66\u548c\u5de5\u7a0b\u9886\u57df\u4eba\u673a\u534f\u4f5c\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u4e0e\u56e0\u679c\u63a8\u7406\u7ed3\u5408\u5b9e\u73b0\"\u4ece\u5b66\u4e60\u8005\u4e2d\u5b66\u4e60\"\u3002\u5c3d\u7ba1\u5728\u89e3\u91ca\u7684\u5fe0\u5b9e\u6027\u3001\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u7528\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u4f46XAI\u4e3a\u63d0\u53d6AI\u77e5\u8bc6\u3001\u6307\u5bfc\u7a33\u5065\u8bbe\u8ba1\u548c\u5efa\u7acb\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u4fe1\u4efb\u63d0\u4f9b\u4e86\u91cd\u8981\u9014\u5f84\u3002"}}
{"id": "2601.05529", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05529", "abs": "https://arxiv.org/abs/2601.05529", "authors": ["Jua Han", "Jaeyoon Seo", "Jungbin Min", "Jean Oh", "Jihie Kim"], "title": "Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making", "comment": null, "summary": "One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we identified critical failure cases in LLM-based decision-making. Based on these, we designed seven tasks for quantitative assessment, categorized into: Complete Information, Incomplete Information, and Safety-Oriented Spatial Reasoning (SOSR). Complete information tasks utilize ASCII maps to minimize interpretation ambiguity and isolate spatial reasoning from visual processing. Incomplete information tasks require models to infer missing context, testing for spatial continuity versus hallucinations. SOSR tasks use natural language to evaluate safe decision-making in life-threatening contexts. We benchmark various LLMs and Vision-Language Models (VLMs) across these tasks. Beyond aggregate performance, we analyze the implications of a 1% failure rate, highlighting how \"rare\" errors escalate into catastrophic outcomes. Results reveal serious vulnerabilities: several models achieved a 0% success rate in ASCII navigation, while in a simulated fire drill, models instructed robots to move toward hazardous areas instead of emergency exits. Our findings lead to a sobering conclusion: current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. We demonstrate that even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u7684\u6027\u80fd,\u53d1\u73b0\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e,\u5728\u706b\u707e\u758f\u6563\u7b49\u751f\u547d\u6538\u5173\u7684\u60c5\u5883\u4e2d\u53ef\u80fd\u505a\u51fa\u5371\u9669\u51b3\u7b56,\u8bc1\u660e\u5f53\u524dLLM\u5c1a\u672a\u51c6\u5907\u597d\u76f4\u63a5\u90e8\u7f72\u4e8e\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u51b3\u7b56\u7cfb\u7edf,\u5176\u9519\u8bef\u53ef\u80fd\u76f4\u63a5\u5371\u53ca\u4eba\u7c7b\u5b89\u5168\u3002\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d,\u5373\u4f7f\u662f\u5fae\u5c0f\u7684\u9519\u8bef\u4e5f\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u540e\u679c,\u56e0\u6b64\u8feb\u5207\u9700\u8981\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30LLM\u5728\u6b64\u7c7b\u573a\u666f\u4e0b\u7684\u6027\u80fd\u8868\u73b0,\u8bc6\u522b\u6f5c\u5728\u7684\u81f4\u547d\u7f3a\u9677\u3002", "method": "\u7814\u7a76\u9996\u5148\u901a\u8fc7\u706b\u707e\u758f\u6563\u573a\u666f\u7684\u5b9a\u6027\u8bc4\u4f30\u8bc6\u522bLLM\u51b3\u7b56\u7684\u5173\u952e\u5931\u8d25\u6848\u4f8b,\u7136\u540e\u8bbe\u8ba1\u4e86\u4e03\u9879\u5b9a\u91cf\u8bc4\u4f30\u4efb\u52a1,\u5206\u4e3a\u4e09\u7c7b:(1)\u5b8c\u6574\u4fe1\u606f\u4efb\u52a1:\u4f7f\u7528ASCII\u5730\u56fe\u6700\u5c0f\u5316\u89e3\u91ca\u6b67\u4e49,\u9694\u79bb\u7a7a\u95f4\u63a8\u7406\u4e0e\u89c6\u89c9\u5904\u7406;(2)\u4e0d\u5b8c\u6574\u4fe1\u606f\u4efb\u52a1:\u8981\u6c42\u6a21\u578b\u63a8\u65ad\u7f3a\u5931\u4e0a\u4e0b\u6587,\u6d4b\u8bd5\u7a7a\u95f4\u8fde\u7eed\u6027\u63a8\u7406\u80fd\u529b;(3)\u5b89\u5168\u5bfc\u5411\u7a7a\u95f4\u63a8\u7406(SOSR)\u4efb\u52a1:\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u8bc4\u4f30\u751f\u547d\u5a01\u80c1\u60c5\u5883\u4e0b\u7684\u5b89\u5168\u51b3\u7b56\u80fd\u529b\u3002\u5bf9\u591a\u79cdLLM\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5,\u5e76\u7279\u522b\u5206\u67901%\u5931\u8d25\u7387\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u63ed\u793a\u4e86\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e:\u591a\u4e2a\u6a21\u578b\u5728ASCII\u5bfc\u822a\u4efb\u52a1\u4e2d\u6210\u529f\u7387\u4e3a0%;\u5728\u6a21\u62df\u706b\u707e\u6f14\u4e60\u4e2d,\u6a21\u578b\u6307\u793a\u673a\u5668\u4eba\u5411\u5371\u9669\u533a\u57df\u79fb\u52a8\u800c\u975e\u7d27\u6025\u51fa\u53e3;\u5373\u4f7f\u662f99%\u7684\u51c6\u786e\u7387,\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u4e5f\u610f\u5473\u7740\u6bcf\u767e\u6b21\u6267\u884c\u5c31\u6709\u4e00\u6b21\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u4f24\u5bb3\u3002\u5b9e\u9a8c\u8bc1\u660e\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u65e0\u6cd5\u4fdd\u8bc1\u5b89\u5168\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c1a\u672a\u51c6\u5907\u597d\u76f4\u63a5\u90e8\u7f72\u4e8e\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u3002\u5728\u673a\u5668\u4eba\u7b49\u7269\u7406\u7cfb\u7edf\u4e2d,99%\u7684\u51c6\u786e\u7387\u5177\u6709\u5371\u9669\u7684\u8bef\u5bfc\u6027,\u56e0\u4e3a\"\u7f55\u89c1\"\u7684\u9519\u8bef\u4f1a\u5347\u7ea7\u4e3a\u707e\u96be\u6027\u540e\u679c\u3002\u5b8c\u5168\u4f9d\u8d56\u73b0\u6709LLM\u4f1a\u4ea7\u751f\u4e0d\u53ef\u63a5\u53d7\u7684\u98ce\u9669,\u9700\u8981\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u91c7\u53d6\u66f4\u52a0\u8c28\u614e\u7684\u90e8\u7f72\u7b56\u7565\u548c\u989d\u5916\u7684\u5b89\u5168\u4fdd\u969c\u673a\u5236\u3002"}}
{"id": "2601.05567", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05567", "abs": "https://arxiv.org/abs/2601.05567", "authors": ["Tengxiao Liu", "Deepak Nathani", "Zekun Li", "Kevin Yang", "William Yang Wang"], "title": "WildSci: Advancing Scientific Reasoning from In-the-Wild Literature", "comment": null, "summary": "Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at https://huggingface.co/datasets/JustinTX/WildSci.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86WildSci\u6570\u636e\u96c6,\u8fd9\u662f\u4e00\u4e2a\u4ece\u540c\u884c\u8bc4\u5ba1\u6587\u732e\u4e2d\u81ea\u52a8\u5408\u6210\u7684\u9886\u57df\u7279\u5b9a\u79d1\u5b66\u95ee\u9898\u6570\u636e\u96c6,\u6db5\u76d69\u4e2a\u79d1\u5b66\u5b66\u79d1\u548c26\u4e2a\u5b50\u9886\u57df\u3002\u901a\u8fc7\u5c06\u590d\u6742\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u9879\u9009\u62e9\u9898\u683c\u5f0f,\u5e76\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u6a21\u578b\u5fae\u8c03,\u5728\u591a\u4e2a\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55,\u4f46\u5728\u533b\u5b66\u548c\u6750\u6599\u79d1\u5b66\u7b49\u79d1\u5b66\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u4ecd\u7136\u6709\u9650\u3002\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u79d1\u5b66\u9886\u57df\u6570\u636e\u96c6\u8986\u76d6\u8303\u56f4\u6709\u9650,\u4ee5\u53ca\u5f00\u653e\u5f0f\u79d1\u5b66\u95ee\u9898\u56fa\u6709\u7684\u590d\u6742\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218,\u9700\u8981\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u79d1\u5b66\u9886\u57df\u6570\u636e\u96c6,\u5e76\u5f00\u53d1\u6709\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86WildSci\u6570\u636e\u96c6,\u4ece\u540c\u884c\u8bc4\u5ba1\u7684\u79d1\u5b66\u6587\u732e\u4e2d\u81ea\u52a8\u5408\u6210\u9886\u57df\u7279\u5b9a\u7684\u79d1\u5b66\u95ee\u9898,\u8986\u76d69\u4e2a\u79d1\u5b66\u5b66\u79d1\u548c26\u4e2a\u5b50\u9886\u57df\u3002\u901a\u8fc7\u5c06\u590d\u6742\u7684\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u9879\u9009\u62e9\u9898\u683c\u5f0f,\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u5956\u52b1\u4fe1\u53f7,\u4f7f\u5f97\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u6210\u4e3a\u53ef\u80fd\u3002\u7814\u7a76\u8005\u8fdb\u4e00\u6b65\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03,\u5e76\u5206\u6790\u4e86\u8bad\u7ec3\u52a8\u6001,\u5305\u62ec\u7279\u5b9a\u9886\u57df\u7684\u6027\u80fd\u53d8\u5316\u3001\u54cd\u5e94\u884c\u4e3a\u548c\u6cdb\u5316\u8d8b\u52bf\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u79d1\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5728WildSci\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\u540e,\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5f97\u5230\u4e86\u63d0\u5347\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u9886\u57df\u7279\u5b9a\u6027\u80fd\u53d8\u5316\u3001\u6a21\u578b\u54cd\u5e94\u884c\u4e3a\u4ee5\u53ca\u8de8\u9886\u57df\u6cdb\u5316\u7684\u8d8b\u52bf\u3002", "conclusion": "WildSci\u6570\u636e\u96c6\u4e3a\u79d1\u5b66\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u53ef\u6301\u7eed\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u4ece\u540c\u884c\u8bc4\u5ba1\u6587\u732e\u4e2d\u81ea\u52a8\u5408\u6210\u9ad8\u8d28\u91cf\u7684\u79d1\u5b66\u95ee\u9898,\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65b9\u6cd5,\u8be5\u5de5\u4f5c\u6709\u6548\u5730\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u3002\u6570\u636e\u96c6\u5df2\u516c\u5f00\u53d1\u5e03,\u4e3a\u79d1\u5b66\u63a8\u7406\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2601.05578", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.05578", "abs": "https://arxiv.org/abs/2601.05578", "authors": ["Cooper Lin", "Yanting Zhang", "Maohao Ran", "Wei Xue", "Hongwei Fan", "Yibo Xu", "Zhenglin Wan", "Sirui Han", "Yike Guo", "Jun Song"], "title": "Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection", "comment": null, "summary": "E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u5bf9\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5,\u4e13\u95e8\u7528\u4e8e\u7535\u5b50\u5546\u52a1\u6b3a\u8bc8\u68c0\u6d4b\u3002\u901a\u8fc7Group Sequence Policy Optimization\u7b97\u6cd5\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u7cfb\u7edf,\u5728\u771f\u5b9e\u4ea4\u6613\u6570\u636e\u4e0a\u5fae\u8c03\u8bed\u8a00\u6a21\u578b,\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728F1\u5206\u6570\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347,\u8bc1\u660e\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u63a2\u7d22\u673a\u5236\u80fd\u591f\u53d1\u73b0\u4f20\u7edf\u7279\u5f81\u5de5\u7a0b\u65e0\u6cd5\u6355\u83b7\u7684\u65b0\u578b\u6b3a\u8bc8\u6307\u6807\u3002", "motivation": "\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u548c\u652f\u4ed8\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u5546\u9762\u4e34\u65e5\u76ca\u590d\u6742\u7684\u6b3a\u8bc8\u884c\u4e3a,\u5305\u62ec\u8eab\u4efd\u76d7\u7a83\u3001\u8d26\u6237\u63a5\u7ba1\u548c\u590d\u6742\u7684\u6d17\u94b1\u64cd\u4f5c\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u5177\u6709\u7406\u8bba\u6f5c\u529b,\u4f46\u5176\u5728\u771f\u5b9e\u91d1\u878d\u573a\u666f\u4e2d\u7684\u6b3a\u8bc8\u68c0\u6d4b\u5e94\u7528\u4ecd\u672a\u88ab\u5145\u5206\u5f00\u53d1,\u5728\u5904\u7406\u7279\u5b9a\u9886\u57df\u7684\u7535\u5b50\u5546\u52a1\u4ea4\u6613\u6570\u636e\u65b9\u9762\u7684\u5b9e\u9645\u6709\u6548\u6027\u4e5f\u5c1a\u672a\u5f97\u5230\u5b9e\u8bc1\u9a8c\u8bc1\u3002\u672c\u6587\u65e8\u5728\u5f25\u5408\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u7684\u5c40\u9650\u6027\u4e0eLLM\u5728\u6b3a\u8bc8\u68c0\u6d4b\u4e2d\u672a\u5f00\u53d1\u6f5c\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60(RL)\u5bf9\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3,\u4e13\u95e8\u7528\u4e8e\u6b3a\u8bc8\u68c0\u6d4b\u4efb\u52a1,\u4ec5\u4f7f\u7528\u539f\u59cb\u4ea4\u6613\u6570\u636e\u3002\u5177\u4f53\u4f7f\u7528Group Sequence Policy Optimization(GSPO)\u7b97\u6cd5\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u7cfb\u7edf,\u5728\u4e2d\u56fd\u5168\u7403\u652f\u4ed8\u89e3\u51b3\u65b9\u6848\u516c\u53f8\u63d0\u4f9b\u7684\u771f\u5b9e\u4ea4\u6613\u6570\u636e\u96c6\u4e0a\u5bf9\u4e0d\u540c\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6846\u67b6,\u9f13\u52b1\u8bed\u8a00\u6a21\u578b\u63a2\u7d22\u6587\u672c\u4ea4\u6613\u6570\u636e\u4e2d\u5d4c\u5165\u7684\u591a\u6837\u5316\u4fe1\u4efb\u548c\u98ce\u9669\u4fe1\u53f7,\u5305\u62ec\u5ba2\u6237\u4fe1\u606f\u3001\u914d\u9001\u8be6\u60c5\u3001\u4ea7\u54c1\u63cf\u8ff0\u548c\u8ba2\u5355\u5386\u53f2\u4e2d\u7684\u6a21\u5f0f\u3002", "result": "\u7ecf\u8fc7\u540e\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u5728\u4fdd\u7559\u6d4b\u8bd5\u6570\u636e\u4e0a\u5b9e\u73b0\u4e86F1\u5206\u6570\u7684\u663e\u8457\u63d0\u5347\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027,\u8868\u660e\u6027\u80fd\u6539\u8fdb\u4e3b\u8981\u5f52\u56e0\u4e8e\u5f3a\u5316\u5b66\u4e60\u56fa\u6709\u7684\u63a2\u7d22\u673a\u5236,\u4f7f\u6a21\u578b\u80fd\u591f\u53d1\u73b0\u4f20\u7edf\u5de5\u7a0b\u7279\u5f81\u65e0\u6cd5\u6355\u83b7\u7684\u65b0\u578b\u6b3a\u8bc8\u6307\u6807\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u7535\u5b50\u5546\u52a1\u6b3a\u8bc8\u68c0\u6d4b\u7684\u53ef\u884c\u6027\u548c\u6709\u6548\u6027\u3002\u89c2\u5bdf\u5230\u7684\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u5f52\u529f\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u63a2\u7d22\u673a\u5236,\u8be5\u673a\u5236\u4f7f\u6a21\u578b\u80fd\u591f\u53d1\u73b0\u8d85\u8d8a\u4f20\u7edf\u7279\u5f81\u5de5\u7a0b\u7684\u65b0\u578b\u6b3a\u8bc8\u6307\u6807\u3002\u8fd9\u4e3a\u5c06LLM\u5e94\u7528\u4e8e\u5b9e\u9645\u91d1\u878d\u6b3a\u8bc8\u68c0\u6d4b\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301,\u5c55\u793a\u4e86\u5728\u771f\u5b9e\u4ea4\u6613\u6570\u636e\u4e0a\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.05629", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05629", "abs": "https://arxiv.org/abs/2601.05629", "authors": ["Jiapu Wang", "Xinghe Cheng", "Zezheng Wu", "Ruiqi Ma", "Rui Wang", "Zhichao Yan", "Haoran Luo", "Yuhao Jiang", "Kai Sun"], "title": "Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion", "comment": null, "summary": "Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Cumulative Path-Level Semantic Reasoning for inductive knowledge graph completion (CPSR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed CPSR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, CPSR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that CPSR achieves state-of-the-art performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CPSR\u6846\u67b6\uff0c\u901a\u8fc7\u7d2f\u79ef\u8def\u5f84\u7ea7\u8bed\u4e49\u63a8\u7406\u6765\u89e3\u51b3\u5f52\u7eb3\u5f0f\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u566a\u58f0\u7ed3\u6784\u4fe1\u606f\u548c\u957f\u7a0b\u4f9d\u8d56\u6355\u83b7\u95ee\u9898\uff0c\u540c\u65f6\u6355\u83b7\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u65b9\u6cd5\u5728\u5904\u7406\u65b0\u5174\u5b9e\u4f53\u573a\u666f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u5f52\u7eb3\u5f0f\u65b9\u6cd5\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u4e00\u662f\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u7ed3\u6784\u4fe1\u606f\u7684\u5f71\u54cd\uff0c\u4e8c\u662f\u96be\u4ee5\u6355\u83b7\u63a8\u7406\u8def\u5f84\u4e2d\u7684\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5904\u7406\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3001\u6709\u6548\u8fc7\u6ee4\u566a\u58f0\u5e76\u6355\u83b7\u957f\u7a0b\u4f9d\u8d56\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCPSR\uff08\u7d2f\u79ef\u8def\u5f84\u7ea7\u8bed\u4e49\u63a8\u7406\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\uff081\uff09\u67e5\u8be2\u4f9d\u8d56\u7684\u63a9\u7801\u6a21\u5757\uff0c\u81ea\u9002\u5e94\u5730\u5c4f\u853d\u566a\u58f0\u7ed3\u6784\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u7559\u4e0e\u76ee\u6807\u5bc6\u5207\u76f8\u5173\u7684\u91cd\u8981\u4fe1\u606f\uff1b\uff082\uff09\u5168\u5c40\u8bed\u4e49\u8bc4\u5206\u6a21\u5757\uff0c\u8bc4\u4f30\u63a8\u7406\u8def\u5f84\u4e2d\u5404\u8282\u70b9\u7684\u4e2a\u4f53\u8d21\u732e\u548c\u96c6\u4f53\u5f71\u54cd\uff0c\u4ece\u800c\u540c\u65f6\u6355\u83b7\u77e5\u8bc6\u56fe\u8c31\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCPSR\u5728\u5f52\u7eb3\u5f0f\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\uff08state-of-the-art\uff09\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "CPSR\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u67e5\u8be2\u4f9d\u8d56\u7684\u566a\u58f0\u8fc7\u6ee4\u548c\u5168\u5c40\u8bed\u4e49\u8bc4\u5206\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f52\u7eb3\u5f0f\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u65b0\u5174\u5b9e\u4f53\uff0c\u5e76\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u540c\u65f6\u5229\u7528\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u7684\u6027\u80fd\u3002"}}
{"id": "2601.05637", "categories": ["cs.AI", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05637", "abs": "https://arxiv.org/abs/2601.05637", "authors": ["Emily Cheng", "Carmen Amo Alonso", "Federico Danieli", "Arno Blaas", "Luca Zappella", "Pau Rodriguez", "Xavier Suau"], "title": "GenCtrl -- A Formal Controllability Toolkit for Generative Models", "comment": null, "summary": "As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u8bc4\u4f30\u751f\u6210\u6a21\u578b\u7684\u53ef\u63a7\u6027\uff0c\u901a\u8fc7\u5c06\u4eba\u673a\u4ea4\u4e92\u5efa\u6a21\u4e3a\u63a7\u5236\u8fc7\u7a0b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4f30\u7b97\u6a21\u578b\u53ef\u63a7\u96c6\u7684\u7b97\u6cd5\uff0c\u5e76\u5728\u8bed\u8a00\u6a21\u578b\u548c\u6587\u672c\u751f\u6210\u56fe\u50cf\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6a21\u578b\u53ef\u63a7\u6027\u7684\u8106\u5f31\u6027\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u7684\u666e\u53ca\uff0c\u5bf9\u751f\u6210\u8fc7\u7a0b\u7684\u7cbe\u7ec6\u63a7\u5236\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u4e00\u4e2a\u6839\u672c\u95ee\u9898\u5c1a\u672a\u89e3\u7b54\uff1a\u8fd9\u4e9b\u6a21\u578b\u672c\u8eab\u662f\u5426\u771f\u6b63\u53ef\u63a7\uff1f\u73b0\u6709\u7684\u63a7\u5236\u751f\u6210\u65b9\u6cd5\uff08\u4ece\u63d0\u793a\u5230\u5fae\u8c03\uff09\u4e0d\u65ad\u6d8c\u73b0\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6a21\u578b\u53ef\u63a7\u6027\u7684\u7406\u8bba\u5206\u6790\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "method": "\u5c06\u4eba\u673a\u4ea4\u4e92\u5efa\u6a21\u4e3a\u63a7\u5236\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7b97\u6cd5\u6765\u4f30\u7b97\u5bf9\u8bdd\u573a\u666f\u4e2d\u6a21\u578b\u7684\u53ef\u63a7\u96c6\u3002\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5173\u4e8e\u4f30\u8ba1\u8bef\u5dee\u4e0e\u6837\u672c\u590d\u6742\u5ea6\u5173\u7cfb\u7684\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u63a8\u5bfc\u51fa\u6982\u7387\u8fd1\u4f3c\u6b63\u786e\uff08PAC\uff09\u754c\u9650\uff0c\u8be5\u754c\u9650\u5177\u6709\u65e0\u5206\u5e03\u5047\u8bbe\u3001\u4ec5\u9700\u8f93\u51fa\u6709\u754c\u6027\u5047\u8bbe\u3001\u9002\u7528\u4e8e\u4efb\u4f55\u9ed1\u76d2\u975e\u7ebf\u6027\u63a7\u5236\u7cfb\u7edf\uff08\u5373\u4efb\u4f55\u751f\u6210\u6a21\u578b\uff09\u7684\u7279\u70b9\u3002", "result": "\u5728\u8bed\u8a00\u6a21\u578b\u548c\u6587\u672c\u751f\u6210\u56fe\u50cf\u7684\u5bf9\u8bdd\u63a7\u5236\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6a21\u578b\u7684\u53ef\u63a7\u6027\u51fa\u4e4e\u610f\u6599\u5730\u8106\u5f31\uff0c\u5e76\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5b9e\u9a8c\u8bbe\u7f6e\u3002\u8fd9\u51f8\u663e\u4e86\u8fdb\u884c\u4e25\u683c\u53ef\u63a7\u6027\u5206\u6790\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u7684\u53ef\u63a7\u6027\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u9700\u8981\u5c06\u7814\u7a76\u91cd\u70b9\u4ece\u7b80\u5355\u5730\u5c1d\u8bd5\u63a7\u5236\u8f6c\u5411\u9996\u5148\u7406\u89e3\u5176\u57fa\u672c\u9650\u5236\u3002\u8be5\u7406\u8bba\u6846\u67b6\u4e3a\u8bc4\u4f30\u751f\u6210\u6a21\u578b\u7684\u53ef\u63a7\u6027\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u5de5\u5177\uff0c\u5f3a\u8c03\u5728\u5f00\u53d1\u63a7\u5236\u65b9\u6cd5\u4e4b\u524d\u5e94\u5148\u8fdb\u884c\u53ef\u63a7\u6027\u5206\u6790\u3002"}}
{"id": "2601.05693", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05693", "abs": "https://arxiv.org/abs/2601.05693", "authors": ["Zenghao Duan", "Liang Pang", "Zihao Wei", "Wenbin Duan", "Yuxin Tian", "Shicheng Xu", "Jingcheng Deng", "Zhiyi Yin", "Xueqi Cheng"], "title": "Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models", "comment": null, "summary": "Despite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u5728\u6d4b\u8bd5\u65f6\u6269\u5c55\u4e2d\u51fa\u73b0\u7684\"\u5faa\u73af\u63a8\u7406\"\u5931\u6548\u6a21\u5f0f,\u63d0\u51fa\u4e86LoopBench\u6570\u636e\u96c6\u7528\u4e8e\u5206\u6790\u6570\u503c\u5faa\u73af\u548c\u9648\u8ff0\u5faa\u73af\u4e24\u79cd\u7c7b\u578b,\u63ed\u793a\u4e86\u5faa\u73af\u63a8\u7406\u7684\u673a\u5236\u7279\u5f81\u4e3a\u72b6\u6001\u574d\u7f29\u548cV\u578b\u6ce8\u610f\u529b\u81ea\u6211\u5f3a\u5316\u673a\u5236,\u5e76\u91c7\u7528\u7d2f\u79ef\u548c(CUSUM)\u7b97\u6cd5\u5b9e\u73b0\u65e9\u671f\u5faa\u73af\u9884\u6d4b\u3002", "motivation": "\u5c3d\u7ba1\u6d4b\u8bd5\u65f6\u6269\u5c55\u53d6\u5f97\u4e86\u6210\u529f,\u4f46\u5927\u578b\u63a8\u7406\u6a21\u578b\u7ecf\u5e38\u9047\u5230\u91cd\u590d\u5faa\u73af\u95ee\u9898,\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u548c\u63a8\u7406\u5931\u8d25\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\"\u5faa\u73af\u63a8\u7406\"\u8fd9\u4e00\u7279\u6b8a\u5931\u6548\u6a21\u5f0f\u7684\u7cfb\u7edf\u6027\u5206\u6790,\u8be5\u73b0\u8c61\u8868\u73b0\u4e3a\u751f\u6210\u5185\u5bb9\u4f5c\u4e3a\u81ea\u8eab\u91cd\u73b0\u7684\u903b\u8f91\u524d\u63d0,\u5f62\u6210\u81ea\u6211\u5f3a\u5316\u7684\u9677\u9631\u3002\u56e0\u6b64\u9700\u8981\u6df1\u5165\u7406\u89e3\u5176\u673a\u5236\u5e76\u5f00\u53d1\u6709\u6548\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "1. \u6784\u5efaLoopBench\u6570\u636e\u96c6,\u6355\u83b7\u6570\u503c\u5faa\u73af\u548c\u9648\u8ff0\u5faa\u73af\u4e24\u79cd\u4e0d\u540c\u7684\u5faa\u73af\u7c7b\u578b;2. \u4ece\u673a\u5236\u89d2\u5ea6\u5c06\u5faa\u73af\u63a8\u7406\u8868\u5f81\u4e3a\u5177\u6709\u660e\u786e\u8fb9\u754c\u7684\u72b6\u6001\u574d\u7f29\u73b0\u8c61,\u5176\u4e2d\u8bed\u4e49\u91cd\u590d\u5148\u4e8e\u6587\u672c\u91cd\u590d;3. \u5206\u6790\u63a8\u7406\u50f5\u5c40\u5982\u4f55\u89e6\u53d1\u5faa\u73af\u5f00\u59cb,\u4ee5\u53caV\u578b\u6ce8\u610f\u529b\u673a\u5236\u5982\u4f55\u9a71\u52a8\u81ea\u6211\u5f3a\u5316\u7684\u6301\u7eed\u5faa\u73af;4. \u91c7\u7528\u7d2f\u79ef\u548c(CUSUM)\u7b97\u6cd5\u6355\u83b7\u5faa\u73af\u524d\u5146,\u5b9e\u73b0\u65e9\u671f\u5faa\u73af\u9884\u6d4b\u3002", "result": "\u5728\u591a\u79cd\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86CUSUM\u7b97\u6cd5\u5728\u65e9\u671f\u5faa\u73af\u9884\u6d4b\u65b9\u9762\u7684\u51c6\u786e\u6027,\u5e76\u9610\u660e\u4e86\u957f\u94fe\u63a8\u7406\u7684\u7a33\u5b9a\u6027\u7279\u5f81\u3002\u7814\u7a76\u63ed\u793a\u4e86\u5faa\u73af\u63a8\u7406\u7684\u5185\u5728\u673a\u5236:\u8bed\u4e49\u91cd\u590d\u4f5c\u4e3a\u6587\u672c\u91cd\u590d\u7684\u524d\u5146,\u63a8\u7406\u50f5\u5c40\u89e6\u53d1\u5faa\u73af,V\u578b\u6ce8\u610f\u529b\u673a\u5236\u7ef4\u6301\u81ea\u6211\u5f3a\u5316\u5faa\u73af\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u5e76\u5206\u6790\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\"\u5faa\u73af\u63a8\u7406\"\u5931\u6548\u6a21\u5f0f,\u63ed\u793a\u4e86\u5176\u4f5c\u4e3a\u72b6\u6001\u574d\u7f29\u7684\u673a\u5236\u7279\u5f81\u548cV\u578b\u6ce8\u610f\u529b\u9a71\u52a8\u7684\u81ea\u6211\u5f3a\u5316\u673a\u5236\u3002\u901a\u8fc7LoopBench\u6570\u636e\u96c6\u548cCUSUM\u7b97\u6cd5,\u6210\u529f\u5b9e\u73b0\u4e86\u5faa\u73af\u7684\u65e9\u671f\u9884\u6d4b,\u4e3a\u63d0\u9ad8\u957f\u94fe\u63a8\u7406\u7684\u7a33\u5b9a\u6027\u548c\u8ba1\u7b97\u6548\u7387\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5,\u6709\u52a9\u4e8e\u6539\u5584\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.05705", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.05705", "abs": "https://arxiv.org/abs/2601.05705", "authors": ["Ali Farjami", "Luca Redondi", "Marco Valentino"], "title": "Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning", "comment": "Work in progress", "summary": "Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u903b\u8f91\u53c2\u6570\u5316\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6,\u7528\u4e8e\u53ef\u9a8c\u8bc1\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406,\u5c06\u903b\u8f91\u5f62\u5f0f\u4ece\u9759\u6001\u80cc\u666f\u8f6c\u53d8\u4e3a\u53ef\u63a7\u7ec4\u4ef6,\u901a\u8fc7\u5728\u9ad8\u9636\u903b\u8f91\u4e2d\u5d4c\u5165\u591a\u79cd\u7ecf\u5178\u548c\u975e\u7ecf\u5178\u5f62\u5f0f\u7cfb\u7edf,\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u3001\u6a21\u5757\u5316\u548c\u81ea\u9002\u5e94\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5b9a\u7406\u8bc1\u660e\u5668\u7ed3\u5408\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u903b\u8f91\u5f62\u5f0f\u7cfb\u7edf,\u8fd9\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002\u4e0d\u540c\u63a8\u7406\u9886\u57df(\u5982\u89c4\u8303\u63a8\u7406\u3001\u4f26\u7406\u63a8\u7406\u3001\u5e38\u8bc6\u63a8\u7406)\u53ef\u80fd\u9700\u8981\u4e0d\u540c\u7684\u903b\u8f91\u7cfb\u7edf,\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u7075\u6d3b\u9009\u62e9\u548c\u5207\u6362\u903b\u8f91\u5f62\u5f0f\u7684\u6846\u67b6,\u4f7f\u903b\u8f91\u6210\u4e3a\u53ef\u53c2\u6570\u5316\u7684\u7ec4\u4ef6\u800c\u975e\u9759\u6001\u80cc\u666f\u3002", "method": "\u91c7\u7528LogiKEy\u65b9\u6cd5\u8bba,\u5c06\u591a\u79cd\u7ecf\u5178\u548c\u975e\u7ecf\u5178\u903b\u8f91\u5f62\u5f0f\u7cfb\u7edf(\u5305\u62ec\u4e00\u9636\u903b\u8f91\u3001\u9053\u4e49\u903b\u8f91\u3001\u6a21\u6001\u903b\u8f91\u7b49)\u5d4c\u5165\u5230\u9ad8\u9636\u903b\u8f91(HOL)\u4e2d,\u6784\u5efa\u903b\u8f91\u53c2\u6570\u5316\u6846\u67b6\u3002\u6bd4\u8f83\u4e86\u4e24\u79cd\u7b56\u7565:\u903b\u8f91\u5916\u90e8\u65b9\u6cd5(\u901a\u8fc7\u516c\u7406\u7f16\u7801\u89c4\u8303\u9700\u6c42)\u548c\u903b\u8f91\u5185\u90e8\u65b9\u6cd5(\u89c4\u8303\u6a21\u5f0f\u4ece\u903b\u8f91\u5185\u7f6e\u7ed3\u6784\u4e2d\u4ea7\u751f)\u3002\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e86\u4e0d\u540c\u903b\u8f91\u5f62\u5f0f\u5728\u63a8\u7406\u8d28\u91cf\u3001\u89e3\u91ca\u7cbe\u70bc\u548c\u8bc1\u660e\u884c\u4e3a\u65b9\u9762\u7684\u8868\u73b0,\u7279\u522b\u5173\u6ce8\u89c4\u8303\u63a8\u7406\u9886\u57df\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e,\u903b\u8f91\u5185\u90e8\u7b56\u7565\u80fd\u591f\u6301\u7eed\u63d0\u5347\u6027\u80fd\u5e76\u4e3a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u751f\u6210\u66f4\u9ad8\u6548\u7684\u6df7\u5408\u8bc1\u660e\u3002\u7814\u7a76\u53d1\u73b0\u903b\u8f91\u7684\u6709\u6548\u6027\u5177\u6709\u9886\u57df\u4f9d\u8d56\u6027:\u4e00\u9636\u903b\u8f91\u5728\u5e38\u8bc6\u63a8\u7406\u4e2d\u8868\u73b0\u66f4\u597d,\u800c\u9053\u4e49\u903b\u8f91\u548c\u6a21\u6001\u903b\u8f91\u5728\u4f26\u7406\u9886\u57df\u8868\u73b0\u4f18\u5f02\u3002\u4e0d\u540c\u903b\u8f91\u5f62\u5f0f\u7cfb\u7edf\u5728\u4e0d\u540c\u63a8\u7406\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5dee\u5f02\u5316\u7684\u4f18\u52bf\u3002", "conclusion": "\u5c06\u903b\u8f91\u4f5c\u4e3a\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u4e2d\u7684\u4e00\u7b49\u516c\u6c11\u548c\u53c2\u6570\u5316\u5143\u7d20\u5177\u6709\u91cd\u8981\u4ef7\u503c,\u80fd\u591f\u5b9e\u73b0\u66f4\u9c81\u68d2\u3001\u6a21\u5757\u5316\u548c\u81ea\u9002\u5e94\u7684\u63a8\u7406\u7cfb\u7edf\u3002\u903b\u8f91\u53c2\u6570\u5316\u6846\u67b6\u4e3a\u53ef\u9a8c\u8bc1\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u63d0\u4f9b\u4e86\u7075\u6d3b\u6027,\u4f7f\u7cfb\u7edf\u80fd\u591f\u6839\u636e\u5177\u4f53\u9886\u57df\u548c\u4efb\u52a1\u9700\u6c42\u9009\u62e9\u6700\u5408\u9002\u7684\u903b\u8f91\u5f62\u5f0f,\u4ece\u800c\u63d0\u5347\u6574\u4f53\u63a8\u7406\u6027\u80fd\u548c\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2601.05724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05724", "abs": "https://arxiv.org/abs/2601.05724", "authors": ["Yuxuan Zhou", "Fei Huang", "Heng Li", "Fengyi Wu", "Tianyu Wang", "Jianwei Zhang", "Junyang Lin", "Zhi-Qi Cheng"], "title": "Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding", "comment": null, "summary": "Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rely on surrogate approximations or are constrained by partial information, struggling with joint intractability. In this work, we propose Hierarchical Speculative Decoding (HSD), a provably lossless verification method that significantly boosts the expected number of accepted tokens and overcomes joint intractability by balancing excess and deficient probability mass across accessible branches. Our extensive large-scale experiments demonstrate that HSD yields consistent improvements in acceptance rates across diverse model families and benchmarks. Moreover, its strong explainability and generality make it readily integrable into a wide range of speculative decoding frameworks. Notably, integrating HSD into EAGLE-3 yields over a 12% performance gain, establishing state-of-the-art decoding efficiency without compromising distribution fidelity. Code is available at https://github.com/ZhouYuxuanYX/Hierarchical-Speculative-Decoding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5206\u5c42\u63a8\u6d4b\u89e3\u7801(HSD)\u65b9\u6cd5,\u8fd9\u662f\u4e00\u79cd\u53ef\u8bc1\u660e\u65e0\u635f\u7684\u9a8c\u8bc1\u65b9\u6cd5,\u901a\u8fc7\u5728\u53ef\u8bbf\u95ee\u5206\u652f\u95f4\u5e73\u8861\u8fc7\u91cf\u548c\u4e0d\u8db3\u7684\u6982\u7387\u8d28\u91cf\u6765\u514b\u670d\u8054\u5408\u96be\u89e3\u6027\u95ee\u9898,\u663e\u8457\u63d0\u5347\u4e86\u63a8\u6d4b\u89e3\u7801\u4e2d\u88ab\u63a5\u53d7token\u7684\u6570\u91cf,\u5728\u4fdd\u6301\u5206\u5e03\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u63a8\u6d4b\u89e3\u7801\u4e2d\u7684\u9a8c\u8bc1\u73af\u8282\u662f\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\u540c\u65f6\u4fdd\u6301\u5206\u5e03\u4fdd\u771f\u5ea6\u7684\u5173\u952e\u74f6\u9888\u3002\u867d\u7136\u5e8f\u5217\u7ea7\u9a8c\u8bc1\u6bd4\u9010token\u9a8c\u8bc1\u80fd\u63a5\u53d7\u66f4\u591atoken,\u4f46\u73b0\u6709\u65b9\u6848\u5e38\u4f9d\u8d56\u66ff\u4ee3\u8fd1\u4f3c\u6216\u53d7\u9650\u4e8e\u90e8\u5206\u4fe1\u606f,\u96be\u4ee5\u5904\u7406\u8054\u5408\u96be\u89e3\u6027\u95ee\u9898\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u9a8c\u8bc1\u65b9\u6cd5\u6765\u63d0\u9ad8token\u63a5\u53d7\u7387\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u63a8\u6d4b\u89e3\u7801(HSD)\u65b9\u6cd5,\u8fd9\u662f\u4e00\u79cd\u53ef\u8bc1\u660e\u65e0\u635f\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u5728\u53ef\u8bbf\u95ee\u5206\u652f\u95f4\u5e73\u8861\u8fc7\u91cf\u548c\u4e0d\u8db3\u7684\u6982\u7387\u8d28\u91cf\u6765\u514b\u670d\u8054\u5408\u96be\u89e3\u6027\u95ee\u9898,\u4ece\u800c\u663e\u8457\u63d0\u5347\u9884\u671f\u88ab\u63a5\u53d7token\u7684\u6570\u91cf\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u5f3a\u53ef\u89e3\u91ca\u6027\u548c\u901a\u7528\u6027,\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u5404\u79cd\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\u4e2d\u3002", "result": "\u5927\u89c4\u6a21\u5b9e\u9a8c\u8868\u660e,HSD\u5728\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u80fd\u6301\u7eed\u63d0\u9ad8\u63a5\u53d7\u7387\u3002\u5c06HSD\u96c6\u6210\u5230EAGLE-3\u4e2d\u53ef\u83b7\u5f97\u8d85\u8fc712%\u7684\u6027\u80fd\u63d0\u5347,\u5728\u4e0d\u635f\u5bb3\u5206\u5e03\u4fdd\u771f\u5ea6\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u89e3\u7801\u6548\u7387\u3002", "conclusion": "HSD\u4f5c\u4e3a\u4e00\u79cd\u53ef\u8bc1\u660e\u65e0\u635f\u7684\u5206\u5c42\u9a8c\u8bc1\u65b9\u6cd5,\u6210\u529f\u89e3\u51b3\u4e86\u63a8\u6d4b\u89e3\u7801\u4e2d\u7684\u8054\u5408\u96be\u89e3\u6027\u95ee\u9898,\u663e\u8457\u63d0\u5347\u4e86token\u63a5\u53d7\u7387\u548c\u63a8\u7406\u901f\u5ea6,\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u5e03\u4fdd\u771f\u5ea6\u3002\u5176\u5f3a\u901a\u7528\u6027\u4f7f\u5176\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u79cd\u63a8\u6d4b\u89e3\u7801\u6846\u67b6,\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u52a0\u901f\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05739", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05739", "abs": "https://arxiv.org/abs/2601.05739", "authors": ["G M Shahariar", "Zabir Al Nazi", "Md Olid Hasan Bhuiyan", "Zhouxing Shi"], "title": "PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility", "comment": null, "summary": "Vision Language Models (VLMs) are increasingly integrated into privacy-critical domains, yet existing evaluations of personally identifiable information (PII) leakage largely treat privacy as a static extraction task and ignore how a subject's online presence--the volume of their data available online--influences privacy alignment. We introduce PII-VisBench, a novel benchmark containing 4000 unique probes designed to evaluate VLM safety through the continuum of online presence. The benchmark stratifies 200 subjects into four visibility categories: high, medium, low, and zero--based on the extent and nature of their information available online. We evaluate 18 open-source VLMs (0.3B-32B) based on two key metrics: percentage of PII probing queries refused (Refusal Rate) and the fraction of non-refusal responses flagged for containing PII (Conditional PII Disclosure Rate). Across models, we observe a consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. We identify that models are more likely to disclose PII for high-visibility subjects, alongside substantial model-family heterogeneity and PII-type disparities. Finally, paraphrasing and jailbreak-style prompts expose attack and model-dependent failures, motivating visibility-aware safety evaluation and training interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PII-VisBench\u57fa\u51c6\u6d4b\u8bd5,\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u5728\u4e0d\u540c\u5728\u7ebf\u53ef\u89c1\u5ea6\u4e3b\u4f53\u4e0a\u7684\u9690\u79c1\u4fe1\u606f\u6cc4\u9732\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\u6a21\u578b\u5bf9\u9ad8\u53ef\u89c1\u5ea6\u4e3b\u4f53\u66f4\u5bb9\u6613\u6cc4\u9732\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f(PII),\u5e76\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u7684\u7cfb\u7edf\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9690\u79c1\u8bc4\u4f30\u5c06\u9690\u79c1\u89c6\u4e3a\u9759\u6001\u63d0\u53d6\u4efb\u52a1,\u5ffd\u7565\u4e86\u4e3b\u4f53\u5728\u7ebf\u5b58\u5728\u5ea6(\u5373\u5176\u5728\u7ebf\u6570\u636e\u91cf)\u5bf9\u9690\u79c1\u5bf9\u9f50\u7684\u5f71\u54cd\u3002\u968f\u7740VLM\u8d8a\u6765\u8d8a\u591a\u5730\u96c6\u6210\u5230\u9690\u79c1\u654f\u611f\u9886\u57df,\u9700\u8981\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u5728\u7ebf\u53ef\u89c1\u5ea6\u4e3b\u4f53\u4e0a\u7684PII\u6cc4\u9732\u98ce\u9669,\u4ee5\u53ca\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b4000\u4e2a\u72ec\u7279\u63a2\u6d4b\u6837\u672c\u7684PII-VisBench\u57fa\u51c6\u6d4b\u8bd5,\u5c06200\u4e2a\u4e3b\u4f53\u6309\u5728\u7ebf\u53ef\u89c1\u5ea6\u5206\u4e3a\u9ad8\u3001\u4e2d\u3001\u4f4e\u3001\u96f6\u56db\u4e2a\u7c7b\u522b\u3002\u4f7f\u7528\u4e24\u4e2a\u5173\u952e\u6307\u6807\u8bc4\u4f3018\u4e2a\u5f00\u6e90VLM\u6a21\u578b(\u53c2\u6570\u91cf0.3B-32B):\u62d2\u7edd\u7387(Refusal Rate,\u5373\u62d2\u7edd\u56de\u7b54PII\u63a2\u6d4b\u67e5\u8be2\u7684\u767e\u5206\u6bd4)\u548c\u6761\u4ef6PII\u62ab\u9732\u7387(Conditional PII Disclosure Rate,\u5373\u975e\u62d2\u7edd\u54cd\u5e94\u4e2d\u5305\u542bPII\u7684\u6bd4\u4f8b)\u3002\u6b64\u5916\u8fd8\u6d4b\u8bd5\u4e86\u6539\u5199\u548c\u8d8a\u72f1\u5f0f\u63d0\u793a\u5bf9\u6a21\u578b\u7684\u653b\u51fb\u6548\u679c\u3002", "result": "\u6240\u6709\u6a21\u578b\u8868\u73b0\u51fa\u4e00\u81f4\u6a21\u5f0f:\u968f\u7740\u4e3b\u4f53\u53ef\u89c1\u5ea6\u964d\u4f4e,\u62d2\u7edd\u7387\u589e\u52a0,PII\u62ab\u9732\u7387\u4e0b\u964d(\u4ece\u9ad8\u53ef\u89c1\u5ea6\u76849.10%\u964d\u81f3\u4f4e\u53ef\u89c1\u5ea6\u76845.34%)\u3002\u6a21\u578b\u5bf9\u9ad8\u53ef\u89c1\u5ea6\u4e3b\u4f53\u66f4\u5bb9\u6613\u6cc4\u9732PII,\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02,\u4e0d\u540cPII\u7c7b\u578b\u7684\u6cc4\u9732\u7a0b\u5ea6\u4e5f\u4e0d\u540c\u3002\u6539\u5199\u548c\u8d8a\u72f1\u5f0f\u63d0\u793a\u80fd\u591f\u66b4\u9732\u51fa\u4f9d\u8d56\u4e8e\u653b\u51fb\u65b9\u5f0f\u548c\u6a21\u578b\u7684\u5b89\u5168\u5931\u6548\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86VLM\u5728\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u95ee\u9898,\u7279\u522b\u662f\u5bf9\u9ad8\u53ef\u89c1\u5ea6\u4e3b\u4f53\u7684PII\u6cc4\u9732\u98ce\u9669\u66f4\u9ad8\u3002\u8fd9\u8868\u660e\u9700\u8981\u5f00\u53d1\u8003\u8651\u5728\u7ebf\u53ef\u89c1\u5ea6\u7684\u9690\u79c1\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u548c\u8bad\u7ec3\u5e72\u9884\u63aa\u65bd,\u4ee5\u63d0\u9ad8\u6a21\u578b\u5728\u4e0d\u540c\u53ef\u89c1\u5ea6\u4e3b\u4f53\u4e0a\u7684\u9690\u79c1\u4fdd\u62a4\u80fd\u529b,\u786e\u4fddVLM\u5728\u9690\u79c1\u654f\u611f\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\u3002"}}
{"id": "2601.05746", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05746", "abs": "https://arxiv.org/abs/2601.05746", "authors": ["Zhenghao Li", "Zhi Zheng", "Wei Chen", "Jielun Zhao", "Yong Chen", "Tong Xu", "Enhong Chen"], "title": "DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation", "comment": "16pages,6figures", "summary": "Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DynaDebate\uff08\u52a8\u6001\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u5f84\u751f\u6210\u3001\u8fc7\u7a0b\u4e2d\u5fc3\u8fa9\u8bba\u548c\u89e6\u53d1\u5f0f\u9a8c\u8bc1\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u4e2d\u667a\u80fd\u4f53\u63a8\u7406\u8def\u5f84\u8d8b\u540c\u5bfc\u81f4\u8fa9\u8bba\u5931\u6548\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\u5b58\u5728\u5173\u952e\u7f3a\u9677\uff1a\u4f9d\u8d56\u65e0\u5f15\u5bfc\u7684\u521d\u59cb\u5316\u5bfc\u81f4\u667a\u80fd\u4f53\u91c7\u7528\u76f8\u540c\u7684\u63a8\u7406\u8def\u5f84\u5e76\u72af\u76f8\u540c\u7684\u9519\u8bef\uff0c\u4f7f\u5f97\u6709\u6548\u8fa9\u8bba\u53d7\u963b\uff0c\u6700\u7ec8\u7ed3\u679c\u9000\u5316\u4e3a\u7b80\u5355\u7684\u591a\u6570\u6295\u7968\u3002\u8fd9\u9650\u5236\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u534f\u4f5c\u51b3\u7b56\u548c\u590d\u6742\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u63a8\u7406\u548c\u534f\u4f5c\u80fd\u529b\u3002", "method": "DynaDebate\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u673a\u5236\uff1a\uff081\uff09\u52a8\u6001\u8def\u5f84\u751f\u6210\u4e0e\u5206\u914d\uff1a\u4f7f\u7528\u4e13\u95e8\u7684\u8def\u5f84\u751f\u6210\u667a\u80fd\u4f53\u751f\u6210\u591a\u6837\u5316\u4e14\u903b\u8f91\u4e25\u5bc6\u7684\u89e3\u51b3\u65b9\u6848\u8def\u5f84\uff0c\u5e76\u5177\u6709\u81ea\u9002\u5e94\u5197\u4f59\u6027\uff1b\uff082\uff09\u8fc7\u7a0b\u4e2d\u5fc3\u8fa9\u8bba\uff1a\u5c06\u5173\u6ce8\u70b9\u4ece\u8868\u9762\u7684\u7ed3\u679c\u6295\u7968\u8f6c\u79fb\u5230\u4e25\u683c\u7684\u9010\u6b65\u903b\u8f91\u6279\u5224\uff0c\u4ee5\u786e\u4fdd\u8fc7\u7a0b\u6b63\u786e\u6027\uff1b\uff083\uff09\u57fa\u4e8e\u89e6\u53d1\u7684\u9a8c\u8bc1\u667a\u80fd\u4f53\uff1a\u5728\u51fa\u73b0\u5206\u6b67\u65f6\u6fc0\u6d3b\uff0c\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u5ba2\u89c2\u5730\u89e3\u51b3\u50f5\u5c40\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDynaDebate\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6700\u5148\u8fdb\u7684\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u65b9\u6cd5\u3002", "conclusion": "DynaDebate\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u8def\u5f84\u751f\u6210\u3001\u8fc7\u7a0b\u5bfc\u5411\u7684\u8fa9\u8bba\u673a\u5236\u548c\u89e6\u53d1\u5f0f\u9a8c\u8bc1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u4e2d\u7684\u8def\u5f84\u8d8b\u540c\u548c\u8fa9\u8bba\u9000\u5316\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u534f\u4f5c\u6548\u80fd\u548c\u51b3\u7b56\u8d28\u91cf\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.05890", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05890", "abs": "https://arxiv.org/abs/2601.05890", "authors": ["Ruizhe Zhang", "Xinke Jiang", "Zhibang Yang", "Zhixin Zhang", "Jiaran Gao", "Yuzhen Xiao", "Hongbin Lai", "Xu Chu", "Junfeng Zhao", "Yasha Wang"], "title": "StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management", "comment": null, "summary": "Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.", "AI": {"tldr": "StackPlanner\u662f\u4e00\u4e2a\u5177\u6709\u663e\u5f0f\u5185\u5b58\u63a7\u5236\u7684\u5c42\u6b21\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6,\u901a\u8fc7\u89e3\u8026\u9ad8\u5c42\u534f\u8c03\u4e0e\u5b50\u4efb\u52a1\u6267\u884c,\u5e76\u5229\u7528\u7ed3\u6784\u5316\u7ecf\u9a8c\u8bb0\u5fc6\u548c\u5f3a\u5316\u5b66\u4e60\u6765\u91cd\u7528\u534f\u8c03\u7ecf\u9a8c,\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u957f\u671f\u534f\u4f5c\u4e2d\u7684\u8bb0\u5fc6\u7ba1\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u957f\u671f\u534f\u4f5c\u4e2d\u5b58\u5728\u4e25\u91cd\u95ee\u9898:\u7f3a\u4e4f\u8bb0\u5fc6\u7ba1\u7406\u5bfc\u81f4\u4e0a\u4e0b\u6587\u81a8\u80c0\u3001\u9519\u8bef\u7d2f\u79ef\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u6b64\u5916,\u8fd9\u4e9b\u7cfb\u7edf\u65e0\u6cd5\u6709\u6548\u91cd\u7528\u534f\u8c03\u7ecf\u9a8c,\u5b58\u5728\u4efb\u52a1\u7ea7\u8bb0\u5fc6\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faStackPlanner\u6846\u67b6,\u91c7\u7528\u5c42\u6b21\u5316\u67b6\u6784,\u901a\u8fc7\u4e3b\u52a8\u4efb\u52a1\u7ea7\u8bb0\u5fc6\u63a7\u5236\u5c06\u9ad8\u5c42\u534f\u8c03\u4e0e\u5b50\u4efb\u52a1\u6267\u884c\u89e3\u8026;\u5229\u7528\u7ed3\u6784\u5316\u7ecf\u9a8c\u8bb0\u5fc6\u5b58\u50a8\u53ef\u91cd\u7528\u7684\u534f\u8c03\u7ecf\u9a8c;\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u6765\u5b66\u4e60\u68c0\u7d22\u548c\u5229\u7528\u8fd9\u4e9b\u7ecf\u9a8c,\u5b9e\u73b0\u663e\u5f0f\u7684\u8bb0\u5fc6\u63a7\u5236\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u6df1\u5ea6\u641c\u7d22\u548c\u667a\u80fd\u4f53\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1,\u7ed3\u679c\u8868\u660eStackPlanner\u80fd\u591f\u6709\u6548\u652f\u6301\u53ef\u9760\u7684\u957f\u671f\u591a\u667a\u80fd\u4f53\u534f\u4f5c,\u663e\u8457\u6539\u5584\u4e86\u8bb0\u5fc6\u7ba1\u7406\u6548\u7387\u548c\u534f\u8c03\u7ecf\u9a8c\u7684\u91cd\u7528\u80fd\u529b\u3002", "conclusion": "StackPlanner\u901a\u8fc7\u5f15\u5165\u663e\u5f0f\u8bb0\u5fc6\u63a7\u5236\u548c\u5c42\u6b21\u5316\u67b6\u6784,\u6210\u529f\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u957f\u671f\u534f\u4f5c\u4e2d\u7684\u5173\u952e\u6311\u6218,\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u3001\u66f4\u9ad8\u6548\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2601.05899", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05899", "abs": "https://arxiv.org/abs/2601.05899", "authors": ["Dawei Wang", "Chengming Zhou", "Di Zhao", "Xinyuan Liu", "Marci Chi Ma", "Gary Ushaw", "Richard Davison"], "title": "TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents", "comment": "AAAI 2026 Oral", "summary": "Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TowerMind,\u4e00\u4e2a\u57fa\u4e8e\u5854\u9632\u6e38\u620f\u7684\u65b0\u578b\u73af\u5883,\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u957f\u671f\u89c4\u5212\u548c\u51b3\u7b56\u80fd\u529b\u3002\u8be5\u73af\u5883\u5177\u6709\u4f4e\u8ba1\u7b97\u9700\u6c42\u548c\u591a\u6a21\u6001\u89c2\u5bdf\u7a7a\u95f4,\u5b9e\u9a8c\u63ed\u793a\u4e86LLM\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd,\u5e76\u6307\u51fa\u4e86LLM\u5728\u89c4\u5212\u9a8c\u8bc1\u3001\u51b3\u7b56\u591a\u6837\u6027\u548c\u884c\u52a8\u6548\u7387\u65b9\u9762\u7684\u5173\u952e\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5b9e\u65f6\u6218\u7565(RTS)\u6e38\u620f\u73af\u5883\u8981\u4e48\u8ba1\u7b97\u9700\u6c42\u9ad8,\u8981\u4e48\u7f3a\u4e4f\u5bf9\u6587\u672c\u89c2\u5bdf\u7684\u652f\u6301,\u8fd9\u9650\u5236\u4e86\u4f7f\u7528RTS\u6e38\u620f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u957f\u671f\u89c4\u5212\u548c\u51b3\u7b56\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u8ba1\u7b97\u9700\u6c42\u4f4e\u3001\u652f\u6301\u591a\u6a21\u6001\u8f93\u5165(\u5305\u62ec\u50cf\u7d20\u3001\u6587\u672c\u548c\u7ed3\u6784\u5316\u6e38\u620f\u72b6\u6001)\u7684\u65b0\u578b\u8bc4\u4f30\u73af\u5883,\u4ee5\u66f4\u597d\u5730\u6d4b\u8bd5LLM\u4f5c\u4e3a\u667a\u80fd\u4f53\u7684\u6838\u5fc3\u80fd\u529b\u3002", "method": "\u63d0\u51faTowerMind\u73af\u5883,\u57fa\u4e8e\u5854\u9632(TD)\u8fd9\u4e00RTS\u6e38\u620f\u5b50\u7c7b\u578b\u6784\u5efa\u3002\u8be5\u73af\u5883\u4fdd\u7559\u4e86RTS\u6e38\u620f\u8bc4\u4f30LLM\u7684\u5173\u952e\u4f18\u52bf,\u540c\u65f6\u5177\u6709\u4f4e\u8ba1\u7b97\u9700\u6c42\u548c\u591a\u6a21\u6001\u89c2\u5bdf\u7a7a\u95f4(\u50cf\u7d20\u3001\u6587\u672c\u548c\u7ed3\u6784\u5316\u6e38\u620f\u72b6\u6001\u8868\u793a)\u3002\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u57fa\u51c6\u5173\u5361,\u5728\u4e0d\u540c\u591a\u6a21\u6001\u8f93\u5165\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u591a\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LLM,\u5e76\u652f\u6301\u6a21\u578b\u5e7b\u89c9\u8bc4\u4f30\u548c\u9ad8\u5ea6\u53ef\u5b9a\u5236\u6027\u3002\u6b64\u5916\u8fd8\u8bc4\u4f30\u4e86\u4e24\u79cd\u7ecf\u5178\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5(Ape-X DQN\u548cPPO)\u4f5c\u4e3a\u5bf9\u6bd4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aLLM\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5728\u80fd\u529b\u548c\u5e7b\u89c9\u7ef4\u5ea6\u4e0a\u5b58\u5728\u660e\u663e\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u7a81\u51fa\u4e86LLM\u884c\u4e3a\u7684\u5173\u952e\u5c40\u9650\u6027,\u5305\u62ec:\u89c4\u5212\u9a8c\u8bc1\u4e0d\u8db3\u3001\u51b3\u7b56\u7f3a\u4e4f\u591a\u7ec8\u5c40\u6027(multifinality)\u4ee5\u53ca\u884c\u52a8\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\u3002\u901a\u8fc7\u8f7b\u91cf\u7ea7\u548c\u591a\u6a21\u6001\u8bbe\u8ba1,TowerMind\u8865\u5145\u4e86\u73b0\u6709\u7684RTS\u6e38\u620f\u73af\u5883,\u5e76\u4e3aAI\u667a\u80fd\u4f53\u9886\u57df\u5f15\u5165\u4e86\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "TowerMind\u4f5c\u4e3a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u591a\u6a21\u6001\u7684\u5854\u9632\u6e38\u620f\u73af\u5883,\u6210\u529f\u5730\u4e3a\u8bc4\u4f30LLM\u7684\u89c4\u5212\u548c\u51b3\u7b56\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u6218\u7565\u89c4\u5212\u3001\u51b3\u7b56\u7075\u6d3b\u6027\u548c\u884c\u52a8\u6548\u7387\u65b9\u9762\u7684\u663e\u8457\u4e0d\u8db3,\u4e3a\u672a\u6765\u6539\u8fdbLLM\u667a\u80fd\u4f53\u80fd\u529b\u6307\u660e\u4e86\u65b9\u5411\u3002\u8be5\u73af\u5883\u8865\u5145\u4e86\u73b0\u6709RTS\u6e38\u620f\u8bc4\u4f30\u4f53\u7cfb,\u6e90\u4ee3\u7801\u5df2\u5728GitHub\u4e0a\u516c\u5f00,\u4fbf\u4e8e\u7814\u7a76\u793e\u533a\u4f7f\u7528\u548c\u6269\u5c55\u3002"}}
{"id": "2601.05991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05991", "abs": "https://arxiv.org/abs/2601.05991", "authors": ["Jiayu Ding", "Haoran Tang", "Ge Li"], "title": "Open-Vocabulary 3D Instruction Ambiguity Detection", "comment": null, "summary": "In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like \"Pass me the vial\" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}

{"id": "2601.00003", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00003", "abs": "https://arxiv.org/abs/2601.00003", "authors": ["Shuqi Liu", "Bowei He", "Chen Ma", "Linqi Song"], "title": "Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models", "comment": null, "summary": "Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00004", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00004", "abs": "https://arxiv.org/abs/2601.00004", "authors": ["Isaac Iyinoluwa Olufadewa", "Miracle Ayomikun Adesina", "Ezekiel Ayodeji Oladejo", "Uthman Babatunde Usman", "Owen Kolade Adeniyi", "Matthew Tolulope Olawoyin"], "title": "Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study", "comment": "9 pages, 1 figure, 4 tables", "summary": "Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u5c3c\u65e5\u5229\u4e9a\u6291\u90c1\u75c7\u7b5b\u67e5\u8986\u76d6\u7387\u4f4e\u7684\u95ee\u9898,\u5f00\u53d1\u4e86\u57fa\u4e8e\u5c3c\u65e5\u5229\u4e9a\u76ae\u94a6\u8bed\u7684\u81ea\u52a8\u5316\u6291\u90c1\u75c7\u7b5b\u67e5\u7cfb\u7edf\u3002\u901a\u8fc7\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs),GPT-4.1\u5728PHQ-9\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u5206\u9884\u6d4b\u4e2d\u8fbe\u523094.5%\u7684\u51c6\u786e\u7387,\u4e3a\u8d44\u6e90\u53d7\u9650\u3001\u8bed\u8a00\u591a\u6837\u5316\u5730\u533a\u63d0\u4f9b\u4e86\u6587\u5316\u9002\u5e94\u6027\u5f3a\u7684\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\u5de5\u5177\u3002", "motivation": "\u5c3c\u65e5\u5229\u4e9a\u6291\u90c1\u75c7\u662f\u91cd\u5927\u5fc3\u7406\u5065\u5eb7\u8d1f\u62c5,\u4f46\u7531\u4e8e\u4e34\u5e8a\u533b\u751f\u8d44\u6e90\u532e\u4e4f\u3001\u793e\u4f1a\u6c61\u540d\u5316\u548c\u8bed\u8a00\u969c\u788d(\u5305\u62ec\u5c3c\u65e5\u5229\u4e9a\u76ae\u94a6\u8bed\u548c520\u591a\u79cd\u5730\u65b9\u8bed\u8a00),\u7b5b\u67e5\u8986\u76d6\u7387\u6781\u4f4e\u3002\u4f20\u7edf\u7684PHQ-9\u91cf\u8868\u5728\u9ad8\u6536\u5165\u56fd\u5bb6\u9a8c\u8bc1,\u4f46\u5728\u8bed\u8a00\u548c\u6587\u5316\u4e0a\u4e0d\u9002\u7528\u4e8e\u5c3c\u65e5\u5229\u4e9a\u7b49\u4f4e\u4e2d\u6536\u5165\u56fd\u5bb6\u548c\u793e\u533a\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u9002\u5e94\u5f53\u5730\u8bed\u8a00\u6587\u5316\u7684\u81ea\u52a8\u5316\u6291\u90c1\u75c7\u7b5b\u67e5\u5de5\u5177\u3002", "method": "1. \u6570\u636e\u6536\u96c6:\u4ece18-40\u5c81\u5c3c\u65e5\u5229\u4e9a\u5e74\u8f7b\u4eba\u4e2d\u6536\u96c6432\u4efd\u76ae\u94a6\u8bed\u97f3\u9891\u56de\u7b54,\u5185\u5bb9\u4e0ePHQ-9\u9879\u76ee\u76f8\u5173\u7684\u5fc3\u7406\u4f53\u9a8c\u8bc4\u4f30;2. \u6570\u636e\u5904\u7406:\u8fdb\u884c\u8f6c\u5f55\u3001\u4e25\u683c\u9884\u5904\u7406\u548c\u6807\u6ce8,\u5305\u62ec\u8bed\u4e49\u6807\u8bb0\u3001\u4fda\u8bed\u548c\u4e60\u8bed\u89e3\u91ca\u3001PHQ-9\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u5206;3. \u6a21\u578b\u5fae\u8c03:\u5bf9\u4e09\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b(Phi-3-mini-4k-instruct\u3001Gemma-3-4B-it\u548cGPT-4.1)\u5728\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03;4. \u6027\u80fd\u8bc4\u4f30:\u5b9a\u91cf\u8bc4\u4f30(\u51c6\u786e\u7387\u3001\u7cbe\u786e\u5ea6\u548c\u8bed\u4e49\u5bf9\u9f50)\u548c\u5b9a\u6027\u8bc4\u4f30(\u6e05\u6670\u5ea6\u3001\u76f8\u5173\u6027\u548c\u6587\u5316\u9002\u5b9c\u6027)\u3002", "result": "GPT-4.1\u5728\u5b9a\u91cf\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f73,PHQ-9\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u5206\u9884\u6d4b\u51c6\u786e\u7387\u8fbe\u523094.5%,\u8d85\u8d8aGemma-3-4B-it\u548cPhi-3-mini-4k-instruct\u3002\u5728\u5b9a\u6027\u8bc4\u4f30\u4e2d,GPT-4.1\u751f\u6210\u7684\u56de\u7b54\u5728\u6587\u5316\u9002\u5b9c\u6027\u3001\u6e05\u6670\u5ea6\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u65b9\u9762\u4e5f\u8868\u73b0\u6700\u4f18,\u80fd\u591f\u4e3a\u5c3c\u65e5\u5229\u4e9a\u670d\u52a1\u4e0d\u8db3\u7684\u793e\u533a\u63d0\u4f9bAI\u4ecb\u5bfc\u7684\u6291\u90c1\u75c7\u7b5b\u67e5\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u9002\u7528\u4e8e\u5c3c\u65e5\u5229\u4e9a\u76ae\u94a6\u8bed\u7684\u81ea\u52a8\u5316\u6291\u90c1\u75c7\u7b5b\u67e5\u7cfb\u7edf,\u4e3a\u5728\u8bed\u8a00\u591a\u6837\u5316\u3001\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u5bf9\u8bdd\u5f0f\u5fc3\u7406\u5065\u5eb7\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u5229\u7528\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u4f4e\u4e2d\u6536\u5165\u56fd\u5bb6\u5fc3\u7406\u5065\u5eb7\u670d\u52a1\u53ef\u53ca\u6027\u95ee\u9898\u7684\u6f5c\u529b,\u7279\u522b\u662f\u5728\u514b\u670d\u8bed\u8a00\u969c\u788d\u548c\u6587\u5316\u9002\u5e94\u6027\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.00021", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00021", "abs": "https://arxiv.org/abs/2601.00021", "authors": ["Peter David Fagan"], "title": "Toward a Physical Theory of Intelligence", "comment": "47 pages, 9 figures", "summary": "We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e0d\u53ef\u9006\u4fe1\u606f\u5904\u7406\u548c\u5b88\u6052\u5b9a\u5f8b\u7684\u667a\u80fd\u7269\u7406\u7406\u8bba,\u5c06\u667a\u80fd\u5b9a\u4e49\u4e3a\u6bcf\u5355\u4f4d\u4e0d\u53ef\u9006\u5904\u7406\u4fe1\u606f\u6240\u4ea7\u751f\u7684\u76ee\u6807\u5bfc\u5411\u529f,\u5e76\u5efa\u7acb\u4e86\u4ece\u4fe1\u606f\u7f16\u7801\u3001\u8ba1\u7b97\u5230\u529f\u63d0\u53d6\u7684\u7269\u7406\u7ea6\u675f\u5c42\u7ea7,\u63ed\u793a\u4e86\u667a\u80fd\u7cfb\u7edf\u7684\u8ba4\u77e5\u6781\u9650\u3001\u751f\u7269\u7cfb\u7edf\u7684\u9ad8\u6548\u8fd0\u4f5c\u673a\u5236\u4ee5\u53ca\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u7684\u7269\u7406\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u7406\u8bba\u7f3a\u4e4f\u7edf\u4e00\u7684\u7269\u7406\u57fa\u7840,\u65e0\u6cd5\u4ece\u6839\u672c\u4e0a\u89e3\u91ca\u667a\u80fd\u4f5c\u4e3a\u7269\u7406\u73b0\u8c61\u7684\u672c\u8d28\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u57fa\u4e8e\u7269\u7406\u5b9a\u5f8b(\u7279\u522b\u662f\u5b88\u6052\u5b9a\u5f8b\u548c\u4e0d\u53ef\u9006\u4fe1\u606f\u5904\u7406)\u7684\u667a\u80fd\u7406\u8bba\u6846\u67b6,\u4ee5\u63d0\u4f9b\u8de8\u57fa\u8d28(substrate-neutral)\u7684\u667a\u80fd\u7edf\u4e00\u63cf\u8ff0,\u5e76\u89e3\u91ca\u667a\u80fd\u7cfb\u7edf\u7684\u5185\u5728\u8ba4\u77e5\u9650\u5236\u3001\u751f\u7269\u5927\u8111\u7684\u9ad8\u6548\u8fd0\u4f5c\u673a\u5236\u4ee5\u53ca\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u95ee\u9898\u7684\u7269\u7406\u6839\u6e90\u3002", "method": "1. \u63d0\u51fa\u5b88\u6052\u4e00\u81f4\u6027\u7f16\u7801(CCE)\u6846\u67b6,\u5c06\u4fe1\u606f\u7f16\u7801\u5bf9\u5e94\u5230\u7531\u5b88\u6052\u5b9a\u5f8b\u5f3a\u5236\u5206\u79bb\u7684\u4e9a\u7a33\u6001\u5438\u5f15\u76c6;2. \u5c06\u667a\u80fd\u5b9a\u4e49\u4e3a\u6bcf\u5355\u4f4d\u4e0d\u53ef\u9006\u5904\u7406\u4fe1\u606f\u4ea7\u751f\u7684\u76ee\u6807\u5bfc\u5411\u529f;3. \u63a8\u5bfc\u51fa\u63a7\u5236\u5f00\u653e\u7cfb\u7edf\u4e2d\u4fe1\u606f\u6444\u53d6\u3001\u4e0d\u53ef\u9006\u8ba1\u7b97\u548c\u529f\u63d0\u53d6\u7684\u7269\u7406\u7ea6\u675f\u5c42\u7ea7;4. \u5206\u6790\u751f\u7269\u7cfb\u7edf\u4e2d\u632f\u8361\u548c\u8fd1\u4e34\u754c\u52a8\u529b\u5b66\u5982\u4f55\u4f18\u5316\u4fe1\u606f\u4fdd\u5b58\u3001\u8017\u6563\u548c\u6709\u7528\u529f\u4e4b\u95f4\u7684\u6743\u8861;5. \u53d1\u5c55\u8fde\u7eed\u52a8\u529b\u5b66\u7535\u8def\u7406\u8bba,\u5c06\u7ecf\u5178\u5e03\u5c14\u903b\u8f91\u4f5c\u4e3a\u5438\u5f15\u5b50\u9009\u62e9\u7684\u7279\u4f8b;6. \u57fa\u4e8e\u4e0d\u53ef\u9006\u4fe1\u606f\u6d41\u548c\u7ed3\u6784\u7a33\u6001\u63d0\u51fa\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u7684\u7269\u7406\u89c6\u89d2\u3002", "result": "1. \u5efa\u7acb\u4e86\u667a\u80fd\u7684\u7269\u7406\u5b9a\u4e49\u548c\u7ea6\u675f\u5c42\u7ea7\u4f53\u7cfb;2. \u8bc1\u660e\u4e86\u957f\u671f\u6548\u7387\u9700\u8981\u4fdd\u6301\u5185\u90e8\u4fe1\u606f\u7ed3\u6784,\u4ece\u800c\u4ea7\u751f\u81ea\u6211\u5efa\u6a21;3. \u786e\u7acb\u4e86\u7269\u7406\u5177\u8eab\u667a\u80fd\u7cfb\u7edf\u5177\u6709\u7c7b\u4f3c\u4e0d\u5b8c\u5907\u6027\u73b0\u8c61\u7684\u5185\u5728\u8ba4\u77e5\u6781\u9650;4. \u53d1\u73b0\u5927\u8111\u901a\u8fc7\u632f\u8361\u548c\u8fd1\u4e34\u754c\u52a8\u529b\u5b66\u5904\u4e8e\u6846\u67b6\u9884\u6d4b\u7684\u9ad8\u6548\u8fd0\u4f5c\u533a\u57df;5. \u5728\u67b6\u6784\u5c42\u9762,\u5c55\u793a\u4e86\u7ecf\u5178\u5e03\u5c14\u903b\u8f91\u662f\u5438\u5f15\u5b50\u9009\u62e9\u7684\u7279\u4f8b,\u66f4\u4e00\u822c\u7684\u4e0d\u53d8\u51e0\u4f55\u652f\u6301\u8d85\u8d8a\u5b9a\u70b9\u903b\u8f91\u7684\u8ba1\u7b97\u6a21\u5f0f;6. \u63d0\u51fa\u4e86\u57fa\u4e8e\u4e0d\u53ef\u9006\u4fe1\u606f\u6d41\u548c\u7ed3\u6784\u7a33\u6001\u7684\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u7269\u7406\u57fa\u7840\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u3001\u8de8\u57fa\u8d28\u7684\u667a\u80fd\u7269\u7406\u7406\u8bba,\u5c06\u667a\u80fd\u89c6\u4e3a\u53d7\u5b88\u6052\u5b9a\u5f8b\u7ea6\u675f\u7684\u4e0d\u53ef\u9006\u4fe1\u606f\u5904\u7406\u73b0\u8c61\u3002\u8be5\u7406\u8bba\u4e0d\u4ec5\u63ed\u793a\u4e86\u667a\u80fd\u7cfb\u7edf\u7684\u5185\u5728\u7269\u7406\u9650\u5236\u548c\u751f\u7269\u5927\u8111\u7684\u9ad8\u6548\u8fd0\u4f5c\u673a\u5236,\u8fd8\u4e3a\u7406\u89e3\u8ba1\u7b97\u67b6\u6784\u548c\u4eba\u5de5\u667a\u80fd\u5b89\u5168\u63d0\u4f9b\u4e86\u7269\u7406\u57fa\u7840\u3002\u8fd9\u4e00\u6846\u67b6\u5c06\u667a\u80fd\u4ece\u62bd\u8c61\u6982\u5ff5\u8f6c\u5316\u4e3a\u53ef\u91cf\u5316\u7684\u7269\u7406\u8fc7\u7a0b,\u4e3a\u8de8\u5b66\u79d1\u7406\u89e3\u667a\u80fd\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u3002"}}
{"id": "2601.00023", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00023", "abs": "https://arxiv.org/abs/2601.00023", "authors": ["Luis M. Moreno-Saavedra", "Silvia Jimenez-Fernandez", "Antonio Portilla-Figueras", "David Casillas-Perez", "Sancho Salcedo-Sanz"], "title": "A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system", "comment": null, "summary": "Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00024", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.00024", "abs": "https://arxiv.org/abs/2601.00024", "authors": ["Purushottam Saha", "Avirup Chakraborty", "Sourish Sarkar", "Subhamoy Maitra", "Diganta Mukherjee", "Tridib Mukherjee"], "title": "Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach", "comment": "9 pages, 6 figures, 2 algorithms", "summary": "The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf913\u5f20\u724c\u7684\u7ecf\u5178\u5370\u5ea6\u62c9\u7c73\u7eb8\u724c\u6e38\u620f\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u7b56\u7565\u6846\u67b6,\u5f15\u5165\u4e86MinDist\u624b\u724c\u8bc4\u4f30\u6307\u6807,\u901a\u8fc7\u91cf\u5316\u624b\u724c\u4e0e\u6700\u8fd1\u6709\u6548\u914d\u7f6e\u4e4b\u95f4\u7684\u7f16\u8f91\u8ddd\u79bb\u6765\u6355\u6349\u7ed3\u6784\u63a5\u8fd1\u5ea6,\u5e76\u7ed3\u5408\u5bf9\u624b\u5efa\u6a21\u548c\u96f6\u548c\u535a\u5f08\u4eff\u771f,\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u80dc\u7387\u3002", "motivation": "13\u5f20\u724c\u7684\u7ecf\u5178\u5370\u5ea6\u62c9\u7c73\u7eb8\u724c\u6e38\u620f\u662f\u4e00\u4e2a\u4e0d\u5b8c\u5168\u4fe1\u606f\u7684\u5e8f\u5217\u535a\u5f08,\u9700\u8981\u6982\u7387\u63a8\u7406\u548c\u7ec4\u5408\u51b3\u7b56\u80fd\u529b\u3002\u73b0\u6709\u7684MinScore\u6307\u6807\u5b58\u5728\u5c40\u9650\u6027,\u9700\u8981\u4e00\u79cd\u66f4\u597d\u7684\u624b\u724c\u8bc4\u4f30\u65b9\u6cd5\u6765\u91cf\u5316\u624b\u724c\u4e0e\u5b8c\u6210\u72b6\u6001\u4e4b\u95f4\u7684\u7ed3\u6784\u63a5\u8fd1\u7a0b\u5ea6,\u4ece\u800c\u8bbe\u8ba1\u51fa\u66f4\u6709\u6548\u7684\u7b97\u6cd5\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86MinDist\u624b\u724c\u8bc4\u4f30\u6307\u6807,\u901a\u8fc7\u8ba1\u7b97\u624b\u724c\u4e0e\u6700\u8fd1\u6709\u6548\u914d\u7f6e\u4e4b\u95f4\u7684\u7f16\u8f91\u8ddd\u79bb\u6765\u6539\u8fdbMinScore\u6307\u6807;\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u7684\u7b97\u6cd5,\u5229\u7528\u52a8\u6001\u526a\u679d\u548c\u6a21\u5f0f\u7f13\u5b58\u6280\u672f\u7cbe\u786e\u8ba1\u7b97\u8be5\u6307\u6807;\u5728\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u4eff\u771f\u6846\u67b6\u4e2d\u878d\u5165\u5bf9\u624b\u624b\u724c\u5efa\u6a21;\u4f7f\u7528\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u8bc4\u4f30\u7b56\u7565\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e,\u57fa\u4e8eMinDist\u6307\u6807\u7684\u667a\u80fd\u4f53\u76f8\u6bd4\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u80dc\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347,\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u4e3a\u62c9\u7c73\u7eb8\u724c\u6e38\u620f\u7684\u7b97\u6cd5\u7b56\u7565\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5,MinDist\u6307\u6807\u901a\u8fc7\u91cf\u5316\u7ed3\u6784\u63a5\u8fd1\u5ea6\u6709\u6548\u6539\u8fdb\u4e86\u51b3\u7b56\u8d28\u91cf,\u7ed3\u5408\u9ad8\u6548\u7b97\u6cd5\u548c\u5bf9\u624b\u5efa\u6a21\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347,\u4e3a\u4e0d\u5b8c\u5168\u4fe1\u606f\u535a\u5f08\u7684\u7b56\u7565\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2601.00029", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00029", "abs": "https://arxiv.org/abs/2601.00029", "authors": ["Abolhassan Pishahang", "Maryam Badiei"], "title": "From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers", "comment": "Proceedings of SIGraDi 2025: XXIX International Conference of the Ibero-American Society of Digital Graphics, C\u00f3rdoba, Argentina, 2025", "summary": "This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00097", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.00097", "abs": "https://arxiv.org/abs/2601.00097", "authors": ["Akash Kumar Panda", "Olaoluwa Adigun", "Bart Kosko"], "title": "The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs", "comment": "15 figures", "summary": "We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00105", "abs": "https://arxiv.org/abs/2601.00105", "authors": ["Muhammad U. Nasir", "Yuchen Li", "Steven James", "Julian Togelius"], "title": "Mortar: Evolving Mechanics for Automatic Game Design", "comment": null, "summary": "We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00121", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.00121", "abs": "https://arxiv.org/abs/2601.00121", "authors": ["Yaqi Duan", "Yichun Hu", "Jiashuo Jiang"], "title": "Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control", "comment": null, "summary": "Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant \"hallucination tax\": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.\n  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned \"digital twin\" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00138", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00138", "abs": "https://arxiv.org/abs/2601.00138", "authors": ["Jorge Ortiz"], "title": "Explicit Abstention Knobs for Predictable Reliability in Video Question Answering", "comment": "Preprint. Diagnostic study of confidence-based abstention under evidence truncation", "summary": "High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e2d\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u9009\u62e9\u6027\u9884\u6d4b\u673a\u5236,\u63a2\u8ba8\u5176\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\u5bf9\u9519\u8bef\u7387\u7684\u63a7\u5236\u80fd\u529b\u3002", "motivation": "\u9ad8\u98ce\u9669\u573a\u666f\u4e0b\u90e8\u7f72\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u9700\u8981\u9009\u62e9\u6027\u9884\u6d4b\u673a\u5236,\u5373\u7cfb\u7edf\u5728\u4e0d\u786e\u5b9a\u65f6\u5e94\u8be5\u62d2\u7edd\u56de\u7b54\u800c\u975e\u5192\u9669\u4ea7\u751f\u4ee3\u4ef7\u9ad8\u6602\u7684\u9519\u8bef\u3002\u7814\u7a76\u8005\u5e0c\u671b\u9a8c\u8bc1\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u62d2\u7edd\u7b56\u7565\u662f\u5426\u80fd\u53ef\u9760\u5730\u63a7\u5236\u9519\u8bef\u7387,\u4ee5\u53ca\u8fd9\u79cd\u63a7\u5236\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u662f\u5426\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528NExT-QA\u6570\u636e\u96c6\u548cGemini 2.0 Flash\u6a21\u578b,\u901a\u8fc7\u8c03\u6574\u7f6e\u4fe1\u5ea6\u9608\u503cepsilon\u6765\u7814\u7a76\u98ce\u9669-\u8986\u76d6\u7387\u6743\u8861\u5173\u7cfb,\u8bc4\u4f30\u7f6e\u4fe1\u5ea6\u9608\u503c\u673a\u5236\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u504f\u79fb\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u5f97\u51fa\u4e24\u4e2a\u4e3b\u8981\u53d1\u73b0:\u7b2c\u4e00,\u7f6e\u4fe1\u5ea6\u9608\u503c\u5728\u5206\u5e03\u5185\u63d0\u4f9b\u4e86\u673a\u5236\u6027\u63a7\u5236,\u901a\u8fc7\u8c03\u6574\u9608\u503cepsilon\u53ef\u4ee5\u4ea7\u751f\u5e73\u6ed1\u7684\u98ce\u9669-\u8986\u76d6\u7387\u6743\u8861\u66f2\u7ebf,\u6709\u6548\u964d\u4f4e\u9519\u8bef\u7387\u3002\u7b2c\u4e8c\u4e2a\u53d1\u73b0\u5728\u6458\u8981\u4e2d\u672a\u5b8c\u6574\u5448\u73b0\u3002", "conclusion": "\u7f6e\u4fe1\u5ea6\u9608\u503c\u65b9\u6cd5\u80fd\u591f\u4e3a\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e2d\u63d0\u4f9b\u6709\u6548\u7684\u9519\u8bef\u7387\u63a7\u5236\u673a\u5236,\u5728\u5206\u5e03\u5185\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u53ef\u63a7\u6027,\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u573a\u666f\u4e2d\u7684\u9009\u62e9\u6027\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.00142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00142", "abs": "https://arxiv.org/abs/2601.00142", "authors": ["Tiansi Dong", "Henry He", "Pietro Li\u00f2", "Mateja Jamnik"], "title": "An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making", "comment": "19 pages", "summary": "This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00227", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00227", "abs": "https://arxiv.org/abs/2601.00227", "authors": ["Shanli Xing", "Yiyan Zhai", "Alexander Jiang", "Yixin Dong", "Yong Wu", "Zihao Ye", "Charlie Ruan", "Yingyi Huang", "Yineng Zhang", "Liangsheng Yin", "Aksara Bayyapu", "Luis Ceze", "Tianqi Chen"], "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "comment": null, "summary": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00240", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.00240", "abs": "https://arxiv.org/abs/2601.00240", "authors": ["Zongwei Wang", "Bincheng Gu", "Hongyu Yu", "Junliang Yu", "Tao He", "Jiayin Feng", "Min Gao"], "title": "Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability", "comment": "16 pages", "summary": "LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal \"us\" versus \"them\" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u7fa4\u4f53\u95f4\u504f\u89c1\u65b9\u9762\u7684\u8106\u5f31\u6027,\u53d1\u73b0\u667a\u80fd\u4f53\u5728\u6700\u5c0f\u7fa4\u4f53\u7ebf\u7d22\u4e0b\u4f1a\u8868\u73b0\u51fa\u5bf9\u4eba\u7c7b\u7684\u5916\u7fa4\u4f53\u504f\u89c1,\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\"\u4fe1\u5ff5\u6295\u6bd2\u653b\u51fb\"(BPA)\u65b9\u6cd5\u6765\u63ed\u793a\u8fd9\u4e00\u5b89\u5168\u9690\u60a3,\u65e8\u5728\u4e3a\u66f4\u5b89\u5168\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u4e0d\u4ec5\u5b58\u5728\u4eba\u53e3\u7edf\u8ba1\u5b66\u504f\u89c1(\u5982\u6027\u522b\u3001\u5b97\u6559),\u8fd8\u53ef\u80fd\u5728\"\u6211\u4eec\"\u4e0e\"\u4ed6\u4eec\"\u7684\u6700\u5c0f\u7fa4\u4f53\u7ebf\u7d22\u4e0b\u8868\u73b0\u51fa\u7fa4\u4f53\u95f4\u504f\u89c1\u3002\u5f53\u8fd9\u79cd\u7fa4\u4f53\u8fb9\u754c\u4e0e\u667a\u80fd\u4f53-\u4eba\u7c7b\u5206\u754c\u7ebf\u5bf9\u9f50\u65f6,\u98ce\u9669\u4ece\u4eba\u7c7b\u7fa4\u4f53\u95f4\u7684\u5dee\u5f02\u8f6c\u53d8\u4e3a\u66f4\u6839\u672c\u7684\u7fa4\u4f53\u5c42\u9762\u4e0d\u5bf9\u79f0\u2014\u2014\u4eba\u7c7b\u6574\u4f53\u53ef\u80fd\u88ab\u667a\u80fd\u4f53\u89c6\u4e3a\u5916\u7fa4\u4f53\u3002\u7814\u7a76\u8005\u5e0c\u671b\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u63ed\u793a\u8fd9\u4e00\u6f5c\u5728\u98ce\u9669,\u5e76\u63a2\u7d22\u5176\u653b\u51fb\u9762\u548c\u9632\u5fa1\u7b56\u7565\u3002", "method": "\u7814\u7a76\u91c7\u7528\u57fa\u4e8e\u5206\u914d\u51b3\u7b56\u7684\u53d7\u63a7\u591a\u667a\u80fd\u4f53\u793e\u4f1a\u6a21\u62df\u5b9e\u9a8c,\u5728\u660e\u786e\u7684\u6536\u76ca\u6743\u8861\u4e0b\u68c0\u9a8c\u667a\u80fd\u4f53\u7684\u7fa4\u4f53\u95f4\u504f\u89c1\u3002\u63d0\u51fa\u4e86\"\u4fe1\u5ff5\u6295\u6bd2\u653b\u51fb\"(BPA)\u65b9\u6cd5,\u5305\u62ec\u4e24\u79cd\u5b9e\u4f8b\u5316\u5f62\u5f0f:\u521d\u59cb\u5316\u65f6\u7684\u6863\u6848\u6295\u6bd2(BPA-PP)\u548c\u901a\u8fc7\u4f18\u5316\u7684\u4fe1\u5ff5\u7ec6\u5316\u540e\u7f00\u6ce8\u5165\u5b58\u50a8\u53cd\u601d\u7684\u8bb0\u5fc6\u6295\u6bd2(BPA-MP)\u3002\u8fd9\u4e9b\u653b\u51fb\u65e8\u5728\u7834\u574f\u6301\u4e45\u6027\u8eab\u4efd\u4fe1\u5ff5,\u6291\u5236\u6709\u5229\u4e8e\u4eba\u7c7b\u7684\u9690\u6027\u4eba\u7c7b\u89c4\u8303\u811a\u672c,\u91cd\u65b0\u6fc0\u6d3b\u5bf9\u4eba\u7c7b\u7684\u5916\u7fa4\u4f53\u504f\u89c1\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e,\u667a\u80fd\u4f53\u5728\u6700\u5c0f\u7fa4\u4f53\u7ebf\u7d22\u4e0b\u786e\u5b9e\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u7fa4\u4f53\u95f4\u504f\u89c1\u3002\u867d\u7136\u5f53\u90e8\u5206\u5bf9\u8c61\u88ab\u6807\u8bb0\u4e3a\u4eba\u7c7b\u65f6\u8fd9\u79cd\u504f\u89c1\u6709\u6240\u51cf\u5f31,\u4f46\u7814\u7a76\u53d1\u73b0\u8fd9\u79cd\u51cf\u5f31\u5f52\u56e0\u4e8e\u4ec5\u5728\u667a\u80fd\u4f53\u76f8\u4fe1\u771f\u5b9e\u4eba\u7c7b\u5b58\u5728\u65f6\u624d\u6fc0\u6d3b\u7684\u9690\u6027\u4eba\u7c7b\u89c4\u8303\u811a\u672c\u3002\u8fd9\u79cd\u4fe1\u5ff5\u4f9d\u8d56\u6027\u521b\u9020\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002BPA\u653b\u51fb\u5728\u5404\u79cd\u8bbe\u7f6e\u4e0b\u90fd\u8868\u73b0\u51fa\u4e25\u91cd\u6027,\u80fd\u591f\u6709\u6548\u6291\u5236\u4eba\u7c7b\u89c4\u8303\u811a\u672c\u5e76\u91cd\u65b0\u6fc0\u6d3b\u5bf9\u4eba\u7c7b\u7684\u5916\u7fa4\u4f53\u504f\u89c1\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5b58\u5728\u7684\u7fa4\u4f53\u95f4\u504f\u89c1\u8106\u5f31\u6027,\u7279\u522b\u662f\u5f53\u4eba\u7c7b\u88ab\u89c6\u4e3a\u5916\u7fa4\u4f53\u65f6\u7684\u6f5c\u5728\u98ce\u9669\u3002\u901a\u8fc7\u63d0\u51fa\u4fe1\u5ff5\u6295\u6bd2\u653b\u51fb,\u7814\u7a76\u5c55\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u6846\u67b6\u7684\u5b89\u5168\u9690\u60a3\u3002\u8bba\u6587\u8ba8\u8bba\u4e86\u9488\u5bf9BPA\u7684\u5b9e\u7528\u7f13\u89e3\u7b56\u7565,\u5f3a\u8c03\u4e86\u5728\u6863\u6848\u548c\u8bb0\u5fc6\u8fb9\u754c\u5904\u7684\u53ef\u884c\u5e72\u9884\u63aa\u65bd\u3002\u7814\u7a76\u76ee\u6807\u662f\u901a\u8fc7\u8bc6\u522b\u8fd9\u4e9b\u8106\u5f31\u6027\u6765\u6307\u5bfc\u66f4\u5b89\u5168\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1,\u800c\u975e\u4fc3\u8fdb\u73b0\u5b9e\u4e16\u754c\u7684\u6076\u610f\u5229\u7528\u3002"}}
{"id": "2601.00290", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.00290", "abs": "https://arxiv.org/abs/2601.00290", "authors": ["Sixue Xing", "Xuanye Xia", "Kerui Wu", "Meng Jiang", "Jintai Chen", "Tianfan Fu"], "title": "ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization", "comment": null, "summary": "Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00339", "categories": ["cs.AI", "cs.DC", "cs.ET", "cs.MA", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.00339", "abs": "https://arxiv.org/abs/2601.00339", "authors": ["Alaa Saleh", "Praveen Kumar Donta", "Roberto Morabito", "Sasu Tarkoma", "Anders Lindgren", "Qiyang Zhang", "Schahram Dustdar Susanna Pirttikangas", "Lauri Lov\u00e9n"], "title": "Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems", "comment": null, "summary": "Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00400", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00400", "abs": "https://arxiv.org/abs/2601.00400", "authors": ["Weng Ding", "Yi Han", "Mu-Jiang-Shan Wang"], "title": "Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning", "comment": "15 pages, 8 figures. Under review", "summary": "Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\\% in coordinated attack detection, representing a 15.2\\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00421", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00421", "abs": "https://arxiv.org/abs/2601.00421", "authors": ["Alessio Di Rubbo", "Mattia Neri", "Remo Pareschi", "Marco Pedroni", "Roberto Valtancoli", "Paolino Zica"], "title": "Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications", "comment": "Submitted to Sci (MDPI) for peer review", "summary": "This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u8bed\u4e49\u7a7a\u95f4\u63a8\u7406\u4ece\u8ba1\u7b97\u8bed\u8a00\u5b66\u6269\u5c55\u5230\u56e2\u961f\u8fd0\u52a8\u6218\u672f\u51b3\u7b56\u7684\u521b\u65b0\u65b9\u6cd5,\u901a\u8fc7\u5c06\u7403\u5458\u5efa\u6a21\u4e3a\u591a\u7ef4\u5411\u91cf\u3001\u5c06\u6218\u672f\u914d\u7f6e\u89c6\u4e3a\u7ec4\u5408\u8bed\u4e49\u7ed3\u6784,\u5b9e\u73b0\u4e86\u6218\u672f\u9002\u914d\u5ea6\u8bc4\u4f30\u548c\u7b56\u7565\u63a8\u8350,\u5e76\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u591a\u79cd\u56e2\u961f\u534f\u4f5c\u9886\u57df\u7684\u901a\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u6218\u672f\u51b3\u7b56\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u8bed\u4e49\u5efa\u6a21\u80fd\u529b\u3002\u672c\u6587\u53d7\u8ba1\u7b97\u8bed\u8a00\u5b66\u4e2d\u8bed\u4e49\u7a7a\u95f4\u63a8\u7406\u7684\u542f\u53d1,\u63d0\u51fa\u5c06\u6587\u672c\u4e0e\u56e2\u961f\u7c7b\u6bd4(\u7403\u5458\u5982\u540c\u8bcd\u6c47,\u96c6\u4f53\u914d\u5408\u4f20\u8fbe\u610f\u4e49),\u65e8\u5728\u4e3a\u56e2\u961f\u8fd0\u52a8\u6218\u672f\u51b3\u7b56\u63d0\u4f9b\u4e00\u79cd\u53ef\u89e3\u91ca\u3001\u52a8\u6001\u81ea\u9002\u5e94\u7684\u5efa\u6a21\u6846\u67b6,\u5e76\u5c06\u5176\u63a8\u5e7f\u5230\u7bee\u7403\u3001\u66f2\u68cd\u7403\u3001\u534f\u4f5c\u673a\u5668\u4eba\u548c\u4eba\u673a\u534f\u540c\u7b49\u591a\u79cd\u56e2\u961f\u534f\u4f5c\u573a\u666f\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u6bcf\u4e2a\u7403\u5458\u8868\u793a\u4e3a\u6574\u5408\u6280\u672f\u3001\u8eab\u4f53\u548c\u5fc3\u7406\u5c5e\u6027\u7684\u591a\u7ef4\u5411\u91cf;\u901a\u8fc7\u4e0a\u4e0b\u6587\u52a0\u6743\u5c06\u7403\u5458\u5411\u91cf\u805a\u5408\u4e3a\u56e2\u961f\u5c42\u9762\u7684\u8bed\u4e49\u8868\u793a;\u5728\u5171\u4eab\u5411\u91cf\u7a7a\u95f4\u4e2d,\u5c06\u9ad8\u4f4d\u903c\u62a2\u3001\u53cd\u51fb\u3001\u63a7\u7403\u63a8\u8fdb\u7b49\u6218\u672f\u6a21\u677f\u7f16\u7801\u4e3a\u7c7b\u4f3c\u8bed\u8a00\u6982\u5ff5\u7684\u5411\u91cf;\u4f7f\u7528\u5411\u91cf\u8ddd\u79bb\u5ea6\u91cf\u8bc4\u4f30\u6218\u672f\u6a21\u677f\u4e0e\u56e2\u961f\u914d\u7f6e\u7684\u5bf9\u9f50\u7a0b\u5ea6,\u8ba1\u7b97\u6218\u672f\"\u9002\u914d\u5ea6\"\u548c\u5bf9\u624b\u5229\u7528\u6f5c\u529b;\u5f00\u53d1\u4e86\u57fa\u4e8ePython\u7684\u539f\u578b\u7cfb\u7edf,\u751f\u6210\u53ef\u89e3\u91ca\u7684\u52a8\u6001\u6218\u672f\u63a8\u8350\u548c\u5c5e\u6027\u7ea7\u8bca\u65ad\u6d1e\u5bdf\u3002", "result": "\u7814\u7a76\u5f00\u53d1\u7684Python\u539f\u578b\u7cfb\u7edf\u6210\u529f\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u53ef\u89e3\u91ca\u7684\u3001\u52a8\u6001\u81ea\u9002\u5e94\u7684\u6218\u672f\u7b56\u7565\u63a8\u8350,\u5e76\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u7684\u5c5e\u6027\u7ea7\u8bca\u65ad\u5206\u6790\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u8db3\u7403,\u8fd8\u5c55\u73b0\u4e86\u5728\u7bee\u7403\u3001\u66f2\u68cd\u7403\u3001\u534f\u4f5c\u673a\u5668\u4eba\u548c\u4eba\u673a\u534f\u540c\u7cfb\u7edf\u7b49\u591a\u79cd\u56e2\u961f\u534f\u4f5c\u9886\u57df\u7684\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5c06\u8bed\u4e49\u7a7a\u95f4\u63a8\u7406\u65b9\u6cd5\u4ece\u8ba1\u7b97\u8bed\u8a00\u5b66\u8fc1\u79fb\u5230\u56e2\u961f\u8fd0\u52a8\u6218\u672f\u51b3\u7b56\u9886\u57df,\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u96c6\u4f53\u51b3\u7b56\u548c\u6027\u80fd\u4f18\u5316\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5411\u91cf\u7a7a\u95f4\u5efa\u6a21\u5b9e\u73b0\u4e86\u6218\u672f\u9002\u914d\u5ea6\u7684\u91cf\u5316\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u7684\u7b56\u7565\u63a8\u8350\u3002\u672a\u6765\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6574\u5408\u771f\u5b9e\u4e16\u754c\u6570\u636e\u3001\u5f00\u53d1\u9884\u6d4b\u6a21\u62df\u529f\u80fd,\u4ee5\u53ca\u6784\u5efa\u6df7\u5408\u4eba\u673a\u6218\u672f\u667a\u80fd\u7cfb\u7edf,\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u8be5\u6846\u67b6\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2601.00514", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00514", "abs": "https://arxiv.org/abs/2601.00514", "authors": ["Liv G. d'Aliberti", "Manoel Horta Ribeiro"], "title": "The Illusion of Insight in Reasoning Models", "comment": null, "summary": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790100\u4e07+\u63a8\u7406\u8f68\u8ff9\u548c\u6570\u767e\u4e2a\u8bad\u7ec3\u68c0\u67e5\u70b9,\u53d1\u73b0\u63a8\u7406\u6a21\u578b\u7684\"\u987f\u609f\u65f6\u523b\"(mid-reasoning shifts)\u5b9e\u9645\u4e0a\u662f\u4e0d\u7a33\u5b9a\u63a8\u7406\u884c\u4e3a\u7684\u75c7\u72b6,\u800c\u975e\u5185\u5728\u81ea\u6211\u7ea0\u6b63\u673a\u5236\u3002\u8fd9\u4e9b\u8f6c\u53d8\u7f55\u89c1\u3001\u4e0d\u968f\u8bad\u7ec3\u589e\u52a0,\u4e14\u5f88\u5c11\u63d0\u5347\u51c6\u786e\u7387,\u4f46\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u4e0b\u4eba\u4e3a\u89e6\u53d1\u5916\u90e8\u8f6c\u53d8\u53ef\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8ba4\u4e3a\u50cfDeepSeek-R1-Zero\u8fd9\u6837\u7684\u63a8\u7406\u6a21\u578b\u4f1a\u7ecf\u5386\u7a81\u7136\u7684\u63a8\u7406\u4e2d\u671f\"\u987f\u609f\",\u4ece\u800c\u4ea7\u751f\u51c6\u786e\u8f93\u51fa,\u6697\u793a\u6a21\u578b\u5177\u6709\u5185\u5728\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u3002\u7136\u800c,\u8fd9\u79cd\u63a8\u7406\u7b56\u7565\u7684\u5185\u5728\u8f6c\u53d8\u662f\u5426\u771f\u6b63\u63d0\u5347\u6027\u80fd\u5c1a\u4e0d\u6e05\u695a,\u9700\u8981\u7cfb\u7edf\u6027\u7814\u7a76\u6765\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\u3002", "method": "\u7814\u7a76\u56e2\u961f\u5bf9\u8bad\u7ec3\u8fc7\u7a0b\u8fdb\u884c\u4eea\u5668\u5316\u76d1\u6d4b\u4ee5\u68c0\u6d4b\u63a8\u7406\u4e2d\u671f\u8f6c\u53d8(mid-reasoning shifts),\u5206\u6790\u8303\u56f4\u5305\u62ec:\u8d85\u8fc7100\u4e07\u6761\u63a8\u7406\u8f68\u8ff9\u3001\u6570\u767e\u4e2a\u8bad\u7ec3\u68c0\u67e5\u70b9\u3001\u4e09\u4e2a\u63a8\u7406\u9886\u57df\u3001\u591a\u79cd\u89e3\u7801\u6e29\u5ea6\u548c\u6a21\u578b\u67b6\u6784\u3002\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u8fd9\u4e9b\u8f6c\u53d8\u7684\u9891\u7387\u3001\u4e0e\u8bad\u7ec3\u7684\u5173\u7cfb\u3001\u5bf9\u51c6\u786e\u7387\u7684\u5f71\u54cd,\u4ee5\u53ca\u4e0e\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u5173\u8054,\u5e76\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u5728\u9ad8\u71b5\u6761\u4ef6\u4e0b\u4eba\u4e3a\u89e6\u53d1\u5916\u90e8\u8f6c\u53d8\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0:(1)\u63a8\u7406\u8f6c\u53d8\u73b0\u8c61\u7f55\u89c1;(2)\u8f6c\u53d8\u9891\u7387\u4e0d\u968f\u8bad\u7ec3\u589e\u52a0;(3)\u8f6c\u53d8\u5f88\u5c11\u63d0\u5347\u51c6\u786e\u7387,\u4e0d\u7b26\u5408\u5148\u524d\u5bf9\u6a21\u578b\"\u6d1e\u5bdf\u529b\"\u7684\u8ba4\u77e5;(4)\u8f6c\u53d8\u6548\u679c\u968f\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u53d8\u5316;(5)\u5728\u9ad8\u71b5(\u9ad8\u4e0d\u786e\u5b9a\u6027)\u6761\u4ef6\u4e0b\u4eba\u4e3a\u89e6\u53d1\u5916\u90e8\u8f6c\u53d8\u53ef\u4ee5\u53ef\u9760\u5730\u63d0\u5347\u51c6\u786e\u7387\u3002", "conclusion": "\u63a8\u7406\u6a21\u578b\u7684mid-reasoning shifts\u662f\u4e0d\u7a33\u5b9a\u63a8\u7406\u884c\u4e3a\u7684\u75c7\u72b6\u8868\u73b0,\u800c\u975e\u5185\u5728\u7684\u81ea\u6211\u7ea0\u6b63\u673a\u5236\u3002\u8fd9\u4e00\u53d1\u73b0\u6311\u6218\u4e86\u5173\u4e8e\u63a8\u7406\u6a21\u578b\u5177\u6709\"\u987f\u609f\"\u80fd\u529b\u7684\u5148\u524d\u8ba4\u77e5,\u4f46\u63ed\u793a\u4e86\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u4e0b\u901a\u8fc7\u5916\u90e8\u5e72\u9884\u89e6\u53d1\u63a8\u7406\u8f6c\u53d8\u53ef\u4ee5\u6539\u5584\u6a21\u578b\u6027\u80fd\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.00623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00623", "abs": "https://arxiv.org/abs/2601.00623", "authors": ["Longtian Qiu", "Shan Ning", "Chuyu Zhang", "Jiaxuan Sun", "Xuming He"], "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations", "comment": "Accepted by TMLR", "summary": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u96be\u5ea6\u611f\u77e5\u76f4\u63a5\u504f\u597d\u4f18\u5316(DA-DPO)\u6846\u67b6,\u901a\u8fc7\u4f30\u8ba1\u504f\u597d\u6570\u636e\u7684\u96be\u5ea6\u5e76\u91cd\u65b0\u52a0\u6743\u8bad\u7ec3\u6837\u672c,\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2dDPO\u65b9\u6cd5\u56e0\u6570\u636e\u96be\u5ea6\u4e0d\u5e73\u8861\u5bfc\u81f4\u7684\u8fc7\u62df\u5408\u95ee\u9898,\u6709\u6548\u7f13\u89e3\u4e86\u5e7b\u89c9\u73b0\u8c61\u5e76\u63d0\u5347\u4e86\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u65f6,\u7531\u4e8e\u504f\u597d\u6570\u636e\u5b58\u5728\u96be\u5ea6\u4e0d\u5e73\u8861,\u6a21\u578b\u5f80\u5f80\u8fc7\u5ea6\u5173\u6ce8\u5bb9\u6613\u533a\u5206\u7684\u504f\u597d\u5bf9,\u5bfc\u81f4\u8fc7\u62df\u5408,\u8fd9\u963b\u788d\u4e86\u7ec6\u7c92\u5ea6\u7684\u5e7b\u89c9\u6291\u5236\u5e76\u964d\u4f4e\u4e86\u6574\u4f53\u6027\u80fd\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u5b66\u4e60\u8fc7\u7a0b\u3001\u5173\u6ce8\u56f0\u96be\u6837\u672c\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "DA-DPO\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6:(1)\u96be\u5ea6\u4f30\u8ba1\u6a21\u5757:\u5229\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b,\u7ed3\u5408\u751f\u6210\u5f0f\u548c\u5bf9\u6bd4\u5f0f\u76ee\u6807,\u901a\u8fc7\u5206\u5e03\u611f\u77e5\u6295\u7968\u7b56\u7565\u6574\u5408\u8f93\u51fa,\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u4ea7\u751f\u9c81\u68d2\u7684\u96be\u5ea6\u5206\u6570;(2)\u96be\u5ea6\u611f\u77e5\u8bad\u7ec3\u6a21\u5757:\u6839\u636e\u4f30\u8ba1\u7684\u96be\u5ea6\u5bf9\u504f\u597d\u5bf9\u8fdb\u884c\u91cd\u65b0\u52a0\u6743,\u964d\u4f4e\u7b80\u5355\u6837\u672c\u7684\u6743\u91cd,\u5f3a\u8c03\u56f0\u96be\u6837\u672c,\u4ece\u800c\u7f13\u89e3\u8fc7\u62df\u5408\u95ee\u9898\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4f18\u5148\u5904\u7406\u5177\u6709\u6311\u6218\u6027\u7684\u6837\u672c\u6765\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u504f\u597d\u4f18\u5316\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e,DA-DPO\u5728\u591a\u6a21\u6001\u504f\u597d\u4f18\u5316\u4e2d\u8868\u73b0\u51fa\u6301\u7eed\u7684\u6539\u8fdb\u6548\u679c,\u5bf9\u5e7b\u89c9\u73b0\u8c61\u5177\u6709\u66f4\u5f3a\u7684\u9c81\u68d2\u6027,\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b,\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u65b0\u6570\u636e\u6216\u989d\u5916\u7684\u5fae\u8c03\u9636\u6bb5\u5373\u53ef\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "DA-DPO\u901a\u8fc7\u5f15\u5165\u96be\u5ea6\u611f\u77e5\u673a\u5236,\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001DPO\u65b9\u6cd5\u4e2d\u7684\u6570\u636e\u96be\u5ea6\u4e0d\u5e73\u8861\u548c\u8fc7\u62df\u5408\u95ee\u9898,\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u7f13\u89e3\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u89e3\u51b3\u65b9\u6848,\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.00694", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00694", "abs": "https://arxiv.org/abs/2601.00694", "authors": ["Qingwen Pu", "Kun Xie", "Hong Yang", "Guocong Zhai"], "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference", "comment": null, "summary": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86PedX-LLM\u6846\u67b6,\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u7279\u5f81\u3001\u6587\u672c\u6570\u636e\u548c\u4ea4\u901a\u9886\u57df\u77e5\u8bc6\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b,\u5b9e\u73b0\u4e86\u5bf9\u884c\u4eba\u8fc7\u8857\u884c\u4e3a\u7684\u53ef\u6cdb\u5316\u63a8\u7406,\u5728\u672a\u89c1\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u884c\u4eba\u8fc7\u8857\u884c\u4e3a\u63a8\u7406\u65b9\u6cd5(\u4ece\u7edf\u8ba1\u6a21\u578b\u5230\u76d1\u7763\u5b66\u4e60)\u6cdb\u5316\u80fd\u529b\u6709\u9650,\u5728\u65b0\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4ece\u6570\u503c\u6a21\u5f0f\u62df\u5408\u8f6c\u5411\u8bed\u4e49\u5316\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u884c\u4e3a\u63a8\u7406\u7684\u53ef\u80fd,\u4f46\u73b0\u6709LLM\u5e94\u7528\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u9002\u914d\u548c\u89c6\u89c9\u4e0a\u4e0b\u6587\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u4ece\u7279\u5b9a\u573a\u666f\u7684\u6a21\u5f0f\u8bc6\u522b\u8f6c\u5411\u53ef\u6cdb\u5316\u884c\u4e3a\u63a8\u7406\u7684\u65b0\u6846\u67b6\u3002", "method": "\u63d0\u51faPedX-LLM\u6846\u67b6,\u8fd9\u662f\u4e00\u4e2a\u89c6\u89c9\u4e0e\u77e5\u8bc6\u589e\u5f3a\u7684\u884c\u4eba\u8fc7\u8857\u63a8\u7406\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u5c06LLaVA\u63d0\u53d6\u7684\u89c6\u89c9\u7279\u5f81\u4e0e\u6587\u672c\u6570\u636e\u548c\u4ea4\u901a\u9886\u57df\u77e5\u8bc6\u76f8\u6574\u5408,\u901a\u8fc7\u4f4e\u79e9\u9002\u5e94(LoRA)\u6280\u672f\u5bf9LLaMA-2-7B\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u6765\u63a8\u65ad\u8fc7\u8857\u51b3\u7b56\u3002\u91c7\u7528\u8de8\u573a\u666f\u9a8c\u8bc1\u8bc4\u4f30\u6cdb\u5316\u80fd\u529b,\u5e76\u6d4b\u8bd5\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u5b66\u4e60\u914d\u7f6e\u3002", "result": "PedX-LLM\u5728\u603b\u4f53\u6d4b\u8bd5\u4e2d\u8fbe\u523082.0%\u7684\u5e73\u8861\u51c6\u786e\u7387,\u8d85\u8d8a\u6700\u4f73\u7edf\u8ba1\u548c\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002\u89c6\u89c9\u589e\u5f3a\u6a21\u5757\u8d21\u732e2.9%\u6027\u80fd\u63d0\u5347,\u9886\u57df\u77e5\u8bc6\u6574\u5408\u989d\u5916\u5e26\u67654.1%\u6539\u8fdb\u3002\u5728\u8de8\u573a\u666f\u9a8c\u8bc1\u4e2d,\u96f6\u6837\u672c\u914d\u7f6e\u5728\u4e94\u4e2a\u672a\u89c1\u6d4b\u8bd5\u573a\u666f\u4e0a\u8fbe\u523066.9%\u5e73\u8861\u51c6\u786e\u7387,\u6bd4\u57fa\u7ebf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u9ad8\u51fa\u81f3\u5c1118\u4e2a\u767e\u5206\u70b9\u3002\u901a\u8fc7\u5c11\u6837\u672c\u5b66\u4e60(\u4ec55\u4e2a\u9a8c\u8bc1\u6837\u672c),\u51c6\u786e\u7387\u8fdb\u4e00\u6b65\u63d0\u5347\u81f372.2%\u3002", "conclusion": "PedX-LLM\u5c55\u793a\u4e86\u5bf9\u672a\u89c1\u573a\u666f\u7684\u5f3a\u6cdb\u5316\u80fd\u529b,\u8bc1\u5b9e\u4e86\u89c6\u89c9\u4e0e\u77e5\u8bc6\u589e\u5f3a\u63a8\u7406\u80fd\u591f\u4f7f\u6a21\u578b\u6a21\u62df\u7c7b\u4eba\u51b3\u7b56\u903b\u8f91,\u514b\u670d\u7eaf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u573a\u666f\u7279\u5b9a\u6a21\u5f0f\u8bc6\u522b\u5411\u53ef\u6cdb\u5316\u884c\u4e3a\u63a8\u7406\u7684\u8f6c\u53d8,\u4e3a\u884c\u4eba\u8fc7\u8857\u884c\u4e3a\u9884\u6d4b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.00743", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00743", "abs": "https://arxiv.org/abs/2601.00743", "authors": ["Aliakbar Nafar", "Chetan Chigurupati", "Danial Kamali", "Hamid Karimian", "Parisa Kordjamshidi"], "title": "An Agentic Framework for Neuro-Symbolic Programming", "comment": null, "summary": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}

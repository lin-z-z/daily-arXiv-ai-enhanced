{"id": "2512.22199", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22199", "abs": "https://arxiv.org/abs/2512.22199", "authors": ["Teja Chinthala"], "title": "Bidirectional RAG: Safe Self-Improving Retrieval-Augmented Generation Through Multi-Stage Validation", "comment": "10 pages, 2 figures, 2 tables. 36 experiments across 4 datasets with 3 random seeds. Code available upon request", "summary": "Retrieval-Augmented Generation RAG systems enhance large language models by grounding responses in external knowledge bases, but conventional RAG architectures operate with static corpora that cannot evolve from user interactions. We introduce Bidirectional RAG, a novel RAG architecture that enables safe corpus expansion through validated write back of high quality generated responses. Our system employs a multi stage acceptance layer combining grounding verification (NLI based entailment, attribution checking, and novelty detection to prevent hallucination pollution while enabling knowledge accumulation. Across four datasets Natural Questions, TriviaQA, HotpotQA, Stack Overflow with three random seeds 12 experiments per system, Bidirectional RAG achieves 40.58% average coverage nearly doubling Standard RAG 20.33% while adding 72% fewer documents than naive write back 140 vs 500. Our work demonstrates that self improving RAG is feasible and safe when governed by rigorous validation, offering a practical path toward RAG systems that learn from deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53cc\u5411RAG\uff08Bidirectional RAG\uff09\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u9ad8\u8d28\u91cf\u751f\u6210\u54cd\u5e94\u56de\u5199\u673a\u5236\u5b9e\u73b0\u5b89\u5168\u7684\u8bed\u6599\u5e93\u6269\u5c55\uff0c\u4f7fRAG\u7cfb\u7edf\u80fd\u591f\u4ece\u7528\u6237\u4ea4\u4e92\u4e2d\u5b66\u4e60\u548c\u8fdb\u5316\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u8986\u76d6\u7387\u3002", "motivation": "\u4f20\u7edf\u7684RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u7cfb\u7edf\u4f7f\u7528\u9759\u6001\u8bed\u6599\u5e93\uff0c\u65e0\u6cd5\u4ece\u7528\u6237\u4ea4\u4e92\u4e2d\u8fdb\u5316\u548c\u5b66\u4e60\u3002\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u52a8\u6001\u77e5\u8bc6\u79ef\u7d2f\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6301\u7eed\u6539\u8fdb\u6f5c\u529b\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5b9e\u73b0\u77e5\u8bc6\u79ef\u7d2f\u53c8\u80fd\u9632\u6b62\u5e7b\u89c9\u6c61\u67d3\u7684\u81ea\u6211\u6539\u8fdbRAG\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u53cc\u5411RAG\u67b6\u6784\uff0c\u6838\u5fc3\u521b\u65b0\u662f\u901a\u8fc7\u9a8c\u8bc1\u7684\u56de\u5199\u673a\u5236\u5b9e\u73b0\u5b89\u5168\u7684\u8bed\u6599\u5e93\u6269\u5c55\u3002\u7cfb\u7edf\u91c7\u7528\u591a\u9636\u6bb5\u9a8c\u8bc1\u5c42\uff0c\u5305\u62ec\uff1a\uff081\uff09\u57fa\u4e8eNLI\u7684\u8574\u542b\u9a8c\u8bc1\uff1b\uff082\uff09\u5f52\u56e0\u68c0\u67e5\uff1b\uff083\uff09\u65b0\u9896\u6027\u68c0\u6d4b\u3002\u8fd9\u4e9b\u673a\u5236\u5171\u540c\u9632\u6b62\u5e7b\u89c9\u6c61\u67d3\uff0c\u540c\u65f6\u5141\u8bb8\u9ad8\u8d28\u91cf\u751f\u6210\u54cd\u5e94\u56de\u5199\u5230\u77e5\u8bc6\u5e93\u4e2d\uff0c\u5b9e\u73b0\u77e5\u8bc6\u79ef\u7d2f\u3002\u5728\u56db\u4e2a\u6570\u636e\u96c6\uff08Natural Questions\u3001TriviaQA\u3001HotpotQA\u3001Stack Overflow\uff09\u4e0a\u4f7f\u7528\u4e09\u4e2a\u968f\u673a\u79cd\u5b50\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u572812\u4e2a\u5b9e\u9a8c\u914d\u7f6e\u4e2d\uff084\u4e2a\u6570\u636e\u96c6\u00d73\u4e2a\u968f\u673a\u79cd\u5b50\uff09\uff0c\u53cc\u5411RAG\u5b9e\u73b0\u4e8640.58%\u7684\u5e73\u5747\u8986\u76d6\u7387\uff0c\u51e0\u4e4e\u662f\u6807\u51c6RAG\uff0820.33%\uff09\u7684\u4e24\u500d\u3002\u4e0e\u6734\u7d20\u56de\u5199\u65b9\u6cd5\u76f8\u6bd4\uff0c\u53cc\u5411RAG\u6dfb\u52a0\u7684\u6587\u6863\u6570\u91cf\u51cf\u5c11\u4e8672%\uff08140\u4e2a\u6587\u6863 vs 500\u4e2a\u6587\u6863\uff09\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u8d28\u91cf\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u4e25\u683c\u9a8c\u8bc1\u673a\u5236\u7684\u7ba1\u7406\u4e0b\uff0c\u81ea\u6211\u6539\u8fdb\u7684RAG\u7cfb\u7edf\u662f\u53ef\u884c\u4e14\u5b89\u5168\u7684\u3002\u53cc\u5411RAG\u4e3a\u6784\u5efa\u80fd\u591f\u4ece\u90e8\u7f72\u4e2d\u5b66\u4e60\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u77e5\u8bc6\u5e93\u7684\u52a8\u6001\u6269\u5c55\u548c\u6027\u80fd\u63d0\u5347\uff0c\u4e3aRAG\u7cfb\u7edf\u7684\u6301\u7eed\u8fdb\u5316\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.22201", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22201", "abs": "https://arxiv.org/abs/2512.22201", "authors": ["Vincent Chang", "Thee Ho", "Sunishchal Dev", "Kevin Zhu", "Shi Feng", "Kellin Pelrine", "Matthew Kowal"], "title": "Emergent Persuasion: Will LLMs Persuade Without Being Prompted?", "comment": "This paper was accepted to AAAI 2026 AIGOV Workshop", "summary": "With the wide-scale adoption of conversational AI systems, AI are now able to exert unprecedented influence on human opinion and beliefs. Recent work has shown that many Large Language Models (LLMs) comply with requests to persuade users into harmful beliefs or actions when prompted and that model persuasiveness increases with model scale. However, this prior work looked at persuasion from the threat model of $\\textit{misuse}$ (i.e., a bad actor asking an LLM to persuade). In this paper, we instead aim to answer the following question: Under what circumstances would models persuade $\\textit{without being explicitly prompted}$, which would shape how concerned we should be about such emergent persuasion risks. To achieve this, we study unprompted persuasion under two scenarios: (i) when the model is steered (through internal activation steering) along persona traits, and (ii) when the model is supervised-finetuned (SFT) to exhibit the same traits. We showed that steering towards traits, both related to persuasion and unrelated, does not reliably increase models' tendency to persuade unprompted, however, SFT does. Moreover, SFT on general persuasion datasets containing solely benign topics admits a model that has a higher propensity to persuade on controversial and harmful topics--showing that emergent harmful persuasion can arise and should be studied further.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.22207", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22207", "abs": "https://arxiv.org/abs/2512.22207", "authors": ["Ryan Spencer", "Roey Yaari", "Ritvik Vemavarapu", "Joyce Yang", "Steven Ngo", "Utkarsh Sharma"], "title": "GamiBench: Evaluating Spatial Reasoning and 2D-to-3D Planning Capabilities of MLLMs with Origami Folding Tasks", "comment": null, "summary": "Multimodal large language models (MLLMs) are proficient in perception and instruction-following, but they still struggle with spatial reasoning: the ability to mentally track and manipulate objects across multiple views and over time. Spatial reasoning is a key component of human intelligence, but most existing benchmarks focus on static images or final outputs, failing to account for the sequential and viewpoint-dependent nature of this skill. To close this gap, we introduce GamiBench, a benchmark designed to evaluate spatial reasoning and 2D-to-3D planning in MLLMs through origami-inspired folding tasks. GamiBench includes 186 regular and 186 impossible 2D crease patterns paired with their corresponding 3D folded shapes, produced from six distinct viewpoints across three visual question-answering (VQA) tasks: predicting 3D fold configurations, distinguishing valid viewpoints, and detecting impossible patterns. Unlike previous benchmarks that assess only final predictions, GamiBench holistically evaluates the entire reasoning process--measuring cross-view consistency, physical feasibility through impossible-fold detection, and interpretation of intermediate folding steps. It further introduces new diagnostic metrics--viewpoint consistency (VC) and impossible fold selection rate (IFSR)--to measure how well models handle folds of varying complexity. Our experiments show that even leading models such as GPT-5 and Gemini-2.5-Pro struggle on single-step spatial understanding. These contributions establish a standardized framework for evaluating geometric understanding and spatial reasoning in MLLMs. Dataset and code: https://github.com/stvngo/GamiBench.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.22210", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22210", "abs": "https://arxiv.org/abs/2512.22210", "authors": ["Farjana Yesmin", "Romana Akter"], "title": "Toward Equitable Recovery: A Fairness-Aware AI Framework for Prioritizing Post-Flood Aid in Bangladesh", "comment": "7 pages, 6 figures, 5 tables", "summary": "Post-disaster aid allocation in developing nations often suffers from systematic biases that disadvantage vulnerable regions, perpetuating historical inequities. This paper presents a fairness-aware artificial intelligence framework for prioritizing post-flood aid distribution in Bangladesh, a country highly susceptible to recurring flood disasters. Using real data from the 2022 Bangladesh floods that affected 7.2 million people and caused 405.5 million US dollars in damages, we develop an adversarial debiasing model that predicts flood vulnerability while actively removing biases against marginalized districts and rural areas. Our approach adapts fairness-aware representation learning techniques from healthcare AI to disaster management, employing a gradient reversal layer that forces the model to learn bias-invariant representations. Experimental results on 87 upazilas across 11 districts demonstrate that our framework reduces statistical parity difference by 41.6 percent, decreases regional fairness gaps by 43.2 percent, and maintains strong predictive accuracy (R-squared=0.784 vs baseline 0.811). The model generates actionable priority rankings ensuring aid reaches the most vulnerable populations based on genuine need rather than historical allocation patterns. This work demonstrates how algorithmic fairness techniques can be effectively applied to humanitarian contexts, providing decision-makers with tools to implement more equitable disaster recovery strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u516c\u5e73\u6027\u611f\u77e5\u7684\u4eba\u5de5\u667a\u80fd\u6846\u67b6,\u7528\u4e8e\u5b5f\u52a0\u62c9\u56fd\u6d2a\u707e\u540e\u63f4\u52a9\u5206\u914d\u7684\u4f18\u5316\u3002\u8be5\u6846\u67b6\u91c7\u7528\u5bf9\u6297\u53bb\u504f\u6a21\u578b,\u5728\u4fdd\u6301\u8f83\u9ad8\u9884\u6d4b\u51c6\u786e\u5ea6\u7684\u540c\u65f6,\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u8fb9\u7f18\u5316\u5730\u533a\u548c\u519c\u6751\u5730\u533a\u7684\u7cfb\u7edf\u6027\u504f\u89c1,\u786e\u4fdd\u63f4\u52a9\u8d44\u6e90\u6839\u636e\u771f\u5b9e\u9700\u6c42\u800c\u975e\u5386\u53f2\u5206\u914d\u6a21\u5f0f\u5230\u8fbe\u6700\u8106\u5f31\u7684\u4eba\u7fa4\u3002", "motivation": "\u53d1\u5c55\u4e2d\u56fd\u5bb6\u7684\u707e\u540e\u63f4\u52a9\u5206\u914d\u5e38\u5e38\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u89c1,\u4f7f\u8106\u5f31\u5730\u533a\u5904\u4e8e\u4e0d\u5229\u5730\u4f4d,\u5e76\u5ef6\u7eed\u5386\u53f2\u4e0d\u516c\u5e73\u73b0\u8c61\u3002\u5b5f\u52a0\u62c9\u56fd\u4f5c\u4e3a\u6d2a\u707e\u9ad8\u53d1\u56fd\u5bb6,\u8feb\u5207\u9700\u8981\u4e00\u79cd\u516c\u5e73\u7684\u63f4\u52a9\u5206\u914d\u673a\u5236,\u4ee5\u786e\u4fdd\u8d44\u6e90\u80fd\u591f\u6839\u636e\u771f\u5b9e\u9700\u6c42\u800c\u975e\u5386\u53f2\u5206\u914d\u6a21\u5f0f\u5230\u8fbe\u6700\u9700\u8981\u5e2e\u52a9\u7684\u8fb9\u7f18\u5316\u5730\u533a\u548c\u519c\u6751\u5730\u533a\u3002", "method": "\u7814\u7a76\u91c7\u7528\u5bf9\u6297\u53bb\u504f\u6a21\u578b(adversarial debiasing model)\u6765\u9884\u6d4b\u6d2a\u707e\u8106\u5f31\u6027,\u5e76\u4e3b\u52a8\u6d88\u9664\u5bf9\u8fb9\u7f18\u5316\u5730\u533a\u548c\u519c\u6751\u5730\u533a\u7684\u504f\u89c1\u3002\u8be5\u65b9\u6cd5\u5c06\u533b\u7597AI\u4e2d\u7684\u516c\u5e73\u6027\u611f\u77e5\u8868\u793a\u5b66\u4e60\u6280\u672f\u5e94\u7528\u4e8e\u707e\u5bb3\u7ba1\u7406\u9886\u57df,\u4f7f\u7528\u68af\u5ea6\u53cd\u8f6c\u5c42(gradient reversal layer)\u5f3a\u5236\u6a21\u578b\u5b66\u4e60\u504f\u89c1\u4e0d\u53d8\u7684\u8868\u793a\u3002\u57fa\u4e8e2022\u5e74\u5b5f\u52a0\u62c9\u56fd\u6d2a\u707e\u7684\u771f\u5b9e\u6570\u636e(\u5f71\u54cd720\u4e07\u4eba,\u9020\u62104.055\u4ebf\u7f8e\u5143\u635f\u5931),\u5bf911\u4e2a\u5730\u533a\u768487\u4e2a\u4e61\u9547\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e,\u8be5\u6846\u67b6\u572887\u4e2a\u4e61\u9547\u7684\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u663e\u8457\u6210\u6548:\u7edf\u8ba1\u5747\u7b49\u5dee\u5f02\u51cf\u5c11\u4e8641.6%,\u533a\u57df\u516c\u5e73\u6027\u5dee\u8ddd\u964d\u4f4e\u4e8643.2%,\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u5f3a\u7684\u9884\u6d4b\u51c6\u786e\u6027(R\u5e73\u65b9\u503c\u4e3a0.784,\u57fa\u7ebf\u6a21\u578b\u4e3a0.811)\u3002\u6a21\u578b\u751f\u6210\u7684\u53ef\u64cd\u4f5c\u4f18\u5148\u7ea7\u6392\u540d\u786e\u4fdd\u63f4\u52a9\u80fd\u591f\u6839\u636e\u771f\u5b9e\u9700\u6c42\u5230\u8fbe\u6700\u8106\u5f31\u7684\u4eba\u7fa4,\u800c\u975e\u9075\u5faa\u5386\u53f2\u5206\u914d\u6a21\u5f0f\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5c55\u793a\u4e86\u7b97\u6cd5\u516c\u5e73\u6027\u6280\u672f\u5728\u4eba\u9053\u4e3b\u4e49\u6551\u63f4\u573a\u666f\u4e2d\u7684\u6709\u6548\u5e94\u7528,\u4e3a\u51b3\u7b56\u8005\u63d0\u4f9b\u4e86\u5b9e\u65bd\u66f4\u516c\u5e73\u7684\u707e\u5bb3\u6062\u590d\u7b56\u7565\u7684\u5de5\u5177\u3002\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u6539\u5584\u4e86\u63f4\u52a9\u5206\u914d\u7684\u516c\u5e73\u6027,\u8bc1\u660e\u4e86AI\u6280\u672f\u53ef\u4ee5\u5e2e\u52a9\u6253\u7834\u5386\u53f2\u6027\u7684\u7cfb\u7edf\u504f\u89c1,\u4f7f\u707e\u540e\u63f4\u52a9\u771f\u6b63\u60e0\u53ca\u6700\u9700\u8981\u5e2e\u52a9\u7684\u8106\u5f31\u7fa4\u4f53\u3002"}}
{"id": "2512.22258", "categories": ["cs.AI", "cs.LG", "cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2512.22258", "abs": "https://arxiv.org/abs/2512.22258", "authors": ["Satvik Tripathi"], "title": "Logic Sketch Prompting (LSP): A Deterministic and Interpretable Prompting Method", "comment": null, "summary": "Large language models (LLMs) excel at natural language reasoning but remain unreliable on tasks requiring strict rule adherence, determinism, and auditability. Logic Sketch Prompting (LSP) is a lightweight prompting framework that introduces typed variables, deterministic condition evaluators, and a rule based validator that produces traceable and repeatable outputs. Using two pharmacologic logic compliance tasks, we benchmark LSP against zero shot prompting, chain of thought prompting, and concise prompting across three open weight models: Gemma 2, Mistral, and Llama 3. Across both tasks and all models, LSP consistently achieves the highest accuracy (0.83 to 0.89) and F1 score (0.83 to 0.89), substantially outperforming zero shot prompting (0.24 to 0.60), concise prompts (0.16 to 0.30), and chain of thought prompting (0.56 to 0.75). McNemar tests show statistically significant gains for LSP across nearly all comparisons (p < 0.01). These results demonstrate that LSP improves determinism, interpretability, and consistency without sacrificing performance, supporting its use in clinical, regulated, and safety critical decision support systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u903b\u8f91\u8349\u56fe\u63d0\u793a(LSP)\u6846\u67b6,\u901a\u8fc7\u5f15\u5165\u7c7b\u578b\u53d8\u91cf\u3001\u786e\u5b9a\u6027\u6761\u4ef6\u8bc4\u4f30\u5668\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u9a8c\u8bc1\u5668,\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u4e25\u683c\u89c4\u5219\u9075\u5b88\u7684\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027,\u5728\u836f\u7406\u903b\u8f91\u5408\u89c4\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u63d0\u793a\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272,\u4f46\u5728\u9700\u8981\u4e25\u683c\u89c4\u5219\u9075\u5b88\u3001\u786e\u5b9a\u6027\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u4efb\u52a1\u4e0a\u4ecd\u4e0d\u53ef\u9760\u3002\u73b0\u6709\u7684\u63d0\u793a\u65b9\u6cd5(\u5982\u96f6\u6837\u672c\u63d0\u793a\u3001\u601d\u7ef4\u94fe\u63d0\u793a\u7b49)\u5728\u4e34\u5e8a\u3001\u76d1\u7ba1\u548c\u5b89\u5168\u5173\u952e\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u96be\u4ee5\u6ee1\u8db3\u53ef\u8ffd\u6eaf\u6027\u548c\u4e00\u81f4\u6027\u8981\u6c42,\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\u6765\u6539\u5584\u6a21\u578b\u5728\u8fd9\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u903b\u8f91\u8349\u56fe\u63d0\u793a(Logic Sketch Prompting, LSP)\u6846\u67b6,\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6:(1)\u7c7b\u578b\u53d8\u91cf(typed variables)\u7528\u4e8e\u7ed3\u6784\u5316\u4fe1\u606f\u8868\u793a;(2)\u786e\u5b9a\u6027\u6761\u4ef6\u8bc4\u4f30\u5668(deterministic condition evaluators)\u7528\u4e8e\u89c4\u5219\u5224\u65ad;(3)\u57fa\u4e8e\u89c4\u5219\u7684\u9a8c\u8bc1\u5668(rule-based validator)\u7528\u4e8e\u751f\u6210\u53ef\u8ffd\u6eaf\u548c\u53ef\u91cd\u590d\u7684\u8f93\u51fa\u3002\u4f7f\u7528\u4e24\u4e2a\u836f\u7406\u903b\u8f91\u5408\u89c4\u4efb\u52a1,\u5728\u4e09\u4e2a\u5f00\u6e90\u6743\u91cd\u6a21\u578b(Gemma 2\u3001Mistral\u548cLlama 3)\u4e0a\u5bf9LSP\u4e0e\u96f6\u6837\u672c\u63d0\u793a\u3001\u601d\u7ef4\u94fe\u63d0\u793a\u548c\u7b80\u6d01\u63d0\u793a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\u3002", "result": "\u5728\u6240\u6709\u4efb\u52a1\u548c\u6a21\u578b\u4e0a,LSP\u59cb\u7ec8\u8fbe\u5230\u6700\u9ad8\u7684\u51c6\u786e\u7387(0.83\u81f30.89)\u548cF1\u5206\u6570(0.83\u81f30.89),\u5927\u5e45\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a(0.24\u81f30.60)\u3001\u7b80\u6d01\u63d0\u793a(0.16\u81f30.30)\u548c\u601d\u7ef4\u94fe\u63d0\u793a(0.56\u81f30.75)\u3002McNemar\u68c0\u9a8c\u663e\u793aLSP\u5728\u51e0\u4e4e\u6240\u6709\u6bd4\u8f83\u4e2d\u90fd\u53d6\u5f97\u7edf\u8ba1\u663e\u8457\u6027\u63d0\u5347(p < 0.01)\u3002", "conclusion": "LSP\u6846\u67b6\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b,\u663e\u8457\u6539\u5584\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u786e\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u4e00\u81f4\u6027,\u8bc1\u660e\u5176\u9002\u7528\u4e8e\u4e34\u5e8a\u3001\u76d1\u7ba1\u548c\u5b89\u5168\u5173\u952e\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u4e3a\u9700\u8981\u4e25\u683c\u89c4\u5219\u9075\u5b88\u548c\u53ef\u5ba1\u8ba1\u6027\u7684\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848,\u5c55\u793a\u4e86\u7ed3\u6784\u5316\u63d0\u793a\u65b9\u6cd5\u5728\u63d0\u5347LLM\u53ef\u9760\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.22367", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22367", "abs": "https://arxiv.org/abs/2512.22367", "authors": ["\u00c1ngel Aso-Mollar", "Diego Aineto", "Enrico Scala", "Eva Onaindia"], "title": "Subgoaling Relaxation-based Heuristics for Numeric Planning with Infinite Actions", "comment": null, "summary": "Numeric planning with control parameters extends the standard numeric planning model by introducing action parameters as free numeric variables that must be instantiated during planning. This results in a potentially infinite number of applicable actions in a state. In this setting, off-the-shelf numeric heuristics that leverage the action structure are not feasible. In this paper, we identify a tractable subset of these problems--namely, controllable, simple numeric problems--and propose an optimistic compilation approach that transforms them into simple numeric tasks. To do so, we abstract control-dependent expressions into bounded constant effects and relaxed preconditions. The proposed compilation makes it possible to effectively use subgoaling heuristics to estimate goal distance in numeric planning problems involving control parameters. Our results demonstrate that this approach is an effective and computationally feasible way of applying traditional numeric heuristics to settings with an infinite number of possible actions, pushing the boundaries of the current state of the art.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5e26\u63a7\u5236\u53c2\u6570\u7684\u6570\u503c\u89c4\u5212\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e50\u89c2\u7f16\u8bd1\u65b9\u6cd5\uff0c\u5c06\u53ef\u63a7\u7684\u7b80\u5355\u6570\u503c\u95ee\u9898\u8f6c\u6362\u4e3a\u6807\u51c6\u7b80\u5355\u6570\u503c\u4efb\u52a1\uff0c\u4f7f\u4f20\u7edf\u6570\u503c\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e94\u7528\u4e8e\u5177\u6709\u65e0\u9650\u53ef\u80fd\u52a8\u4f5c\u7684\u89c4\u5212\u573a\u666f\u3002", "motivation": "\u5e26\u63a7\u5236\u53c2\u6570\u7684\u6570\u503c\u89c4\u5212\u5c06\u52a8\u4f5c\u53c2\u6570\u4f5c\u4e3a\u81ea\u7531\u6570\u503c\u53d8\u91cf\uff0c\u5bfc\u81f4\u72b6\u6001\u4e2d\u53ef\u80fd\u5b58\u5728\u65e0\u9650\u6570\u91cf\u7684\u53ef\u5e94\u7528\u52a8\u4f5c\uff0c\u4f7f\u5f97\u73b0\u6709\u7684\u5229\u7528\u52a8\u4f5c\u7ed3\u6784\u7684\u6570\u503c\u542f\u53d1\u5f0f\u65b9\u6cd5\u65e0\u6cd5\u76f4\u63a5\u4f7f\u7528\u3002\u9700\u8981\u627e\u5230\u4e00\u79cd\u65b9\u6cd5\u4f7f\u4f20\u7edf\u542f\u53d1\u5f0f\u6280\u672f\u80fd\u591f\u5e94\u7528\u4e8e\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u8bc6\u522b\u4e86\u8fd9\u7c7b\u95ee\u9898\u7684\u4e00\u4e2a\u53ef\u5904\u7406\u5b50\u96c6\u2014\u2014\u53ef\u63a7\u7684\u7b80\u5355\u6570\u503c\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4e50\u89c2\u7f16\u8bd1\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5c06\u63a7\u5236\u4f9d\u8d56\u7684\u8868\u8fbe\u5f0f\u62bd\u8c61\u4e3a\u6709\u754c\u5e38\u6570\u6548\u679c\u548c\u677e\u5f1b\u524d\u7f6e\u6761\u4ef6\uff0c\u4ece\u800c\u5c06\u5e26\u63a7\u5236\u53c2\u6570\u7684\u95ee\u9898\u8f6c\u6362\u4e3a\u7b80\u5355\u6570\u503c\u4efb\u52a1\uff0c\u4f7f\u5b50\u76ee\u6807\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u591f\u4f30\u8ba1\u76ee\u6807\u8ddd\u79bb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5c06\u4f20\u7edf\u6570\u503c\u542f\u53d1\u5f0f\u5e94\u7528\u4e8e\u5177\u6709\u65e0\u9650\u53ef\u80fd\u52a8\u4f5c\u7684\u573a\u666f\uff0c\u5728\u8ba1\u7b97\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u63a8\u8fdb\u4e86\u5f53\u524d\u6280\u672f\u7684\u8fb9\u754c\u3002", "conclusion": "\u901a\u8fc7\u4e50\u89c2\u7f16\u8bd1\u65b9\u6cd5\u5c06\u53ef\u63a7\u7b80\u5355\u6570\u503c\u95ee\u9898\u8f6c\u6362\u4e3a\u6807\u51c6\u7b80\u5355\u6570\u503c\u4efb\u52a1\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5e26\u63a7\u5236\u53c2\u6570\u7684\u6570\u503c\u89c4\u5212\u4e2d\u542f\u53d1\u5f0f\u65b9\u6cd5\u96be\u4ee5\u5e94\u7528\u7684\u95ee\u9898\uff0c\u4e3a\u5904\u7406\u65e0\u9650\u52a8\u4f5c\u7a7a\u95f4\u7684\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.22396", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.22396", "abs": "https://arxiv.org/abs/2512.22396", "authors": ["Bhanu Prakash Vangala", "Sajid Mahmud", "Pawan Neupane", "Joel Selvaraj", "Jianlin Cheng"], "title": "HalluMat: Detecting Hallucinations in LLM-Generated Materials Science Content Through Multi-Stage Verification", "comment": null, "summary": "Artificial Intelligence (AI), particularly Large Language Models (LLMs), is transforming scientific discovery, enabling rapid knowledge generation and hypothesis formulation. However, a critical challenge is hallucination, where LLMs generate factually incorrect or misleading information, compromising research integrity. To address this, we introduce HalluMatData, a benchmark dataset for evaluating hallucination detection methods, factual consistency, and response robustness in AI-generated materials science content. Alongside this, we propose HalluMatDetector, a multi-stage hallucination detection framework that integrates intrinsic verification, multi-source retrieval, contradiction graph analysis, and metric-based assessment to detect and mitigate LLM hallucinations. Our findings reveal that hallucination levels vary significantly across materials science subdomains, with high-entropy queries exhibiting greater factual inconsistencies. By utilizing HalluMatDetector verification pipeline, we reduce hallucination rates by 30% compared to standard LLM outputs. Furthermore, we introduce the Paraphrased Hallucination Consistency Score (PHCS) to quantify inconsistencies in LLM responses across semantically equivalent queries, offering deeper insights into model reliability.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.22398", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22398", "abs": "https://arxiv.org/abs/2512.22398", "authors": ["Ozan Oguztuzun", "Cerag Oguztuzun"], "title": "Lightweight Inference-Time Personalization for Frozen Knowledge Graph Embeddings", "comment": null, "summary": "Foundation models for knowledge graphs (KGs) achieve strong cohort-level performance in link prediction, yet fail to capture individual user preferences; a key disconnect between general relational reasoning and personalized ranking. We propose GatedBias, a lightweight inference-time personalization framework that adapts frozen KG embeddings to individual user contexts without retraining or compromising global accuracy. Our approach introduces structure-gated adaptation: profile-specific features combine with graph-derived binary gates to produce interpretable, per-entity biases, requiring only ${\\sim}300$ trainable parameters. We evaluate GatedBias on two benchmark datasets (Amazon-Book and Last-FM), demonstrating statistically significant improvements in alignment metrics while preserving cohort performance. Counterfactual perturbation experiments validate causal responsiveness; entities benefiting from specific preference signals show 6--30$\\times$ greater rank improvements when those signals are boosted. These results show that personalized adaptation of foundation models can be both parameter-efficient and causally verifiable, bridging general knowledge representations with individual user needs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGatedBias\u6846\u67b6,\u901a\u8fc7\u8f7b\u91cf\u7ea7\u63a8\u7406\u65f6\u4e2a\u6027\u5316\u65b9\u6cd5,\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5c06\u51bb\u7ed3\u7684\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u9002\u914d\u5230\u4e2a\u4f53\u7528\u6237\u4e0a\u4e0b\u6587,\u4ec5\u9700\u7ea6300\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570\u5373\u53ef\u5b9e\u73b0\u4e2a\u6027\u5316\u63a8\u8350,\u540c\u65f6\u4fdd\u6301\u5168\u5c40\u51c6\u786e\u6027\u3002", "motivation": "\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u6a21\u578b\u5728\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u867d\u7136\u5728\u7fa4\u4f53\u5c42\u9762\u8868\u73b0\u4f18\u5f02,\u4f46\u65e0\u6cd5\u6355\u6349\u4e2a\u4f53\u7528\u6237\u504f\u597d,\u5b58\u5728\u901a\u7528\u5173\u7cfb\u63a8\u7406\u4e0e\u4e2a\u6027\u5316\u6392\u5e8f\u4e4b\u95f4\u7684\u5173\u952e\u8131\u8282\u95ee\u9898\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u4fdd\u6301\u5168\u5c40\u51c6\u786e\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u7684\u4e2a\u6027\u5316\u9002\u914d\u3002", "method": "\u63d0\u51faGatedBias\u6846\u67b6,\u91c7\u7528\u7ed3\u6784\u95e8\u63a7\u9002\u914d(structure-gated adaptation)\u673a\u5236:\u5c06\u7528\u6237\u7279\u5b9a\u7684\u914d\u7f6e\u6587\u4ef6\u7279\u5f81\u4e0e\u56fe\u6d3e\u751f\u7684\u4e8c\u5143\u95e8\u63a7\u76f8\u7ed3\u5408,\u751f\u6210\u53ef\u89e3\u91ca\u7684\u5b9e\u4f53\u7ea7\u504f\u7f6e\u3002\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u65f6\u8fdb\u884c\u4e2a\u6027\u5316\u9002\u914d,\u4fdd\u6301\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u51bb\u7ed3\u72b6\u6001,\u4ec5\u9700\u7ea6300\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570,\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6574\u4e2a\u6a21\u578b\u3002", "result": "\u5728Amazon-Book\u548cLast-FM\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30,\u5728\u5bf9\u9f50\u6307\u6807\u4e0a\u53d6\u5f97\u7edf\u8ba1\u663e\u8457\u6027\u6539\u8fdb,\u540c\u65f6\u4fdd\u6301\u7fa4\u4f53\u5c42\u9762\u6027\u80fd\u3002\u53cd\u4e8b\u5b9e\u6270\u52a8\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u56e0\u679c\u54cd\u5e94\u6027:\u5f53\u7279\u5b9a\u504f\u597d\u4fe1\u53f7\u589e\u5f3a\u65f6,\u53d7\u76ca\u4e8e\u8fd9\u4e9b\u4fe1\u53f7\u7684\u5b9e\u4f53\u6392\u540d\u63d0\u5347\u5e45\u5ea6\u8fbe\u52306-30\u500d\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u57fa\u7840\u6a21\u578b\u7684\u4e2a\u6027\u5316\u9002\u914d\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u53c2\u6570\u9ad8\u6548\u548c\u56e0\u679c\u53ef\u9a8c\u8bc1,\u6210\u529f\u5f25\u5408\u4e86\u901a\u7528\u77e5\u8bc6\u8868\u793a\u4e0e\u4e2a\u4f53\u7528\u6237\u9700\u6c42\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002GatedBias\u6846\u67b6\u4e3a\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u6a21\u578b\u7684\u4e2a\u6027\u5316\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u4e14\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.22431", "categories": ["cs.AI", "cs.CL", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.22431", "abs": "https://arxiv.org/abs/2512.22431", "authors": ["Yifan Zhang", "Mengdi Wang"], "title": "Monadic Context Engineering", "comment": "Project Page: https://github.com/yifanzhang-pro/monadic-context-engineering", "summary": "The proliferation of Large Language Models (LLMs) has catalyzed a shift towards autonomous agents capable of complex reasoning and tool use. However, current agent architectures are frequently constructed using imperative, ad hoc patterns. This results in brittle systems plagued by difficulties in state management, error handling, and concurrency. This paper introduces Monadic Context Engineering (MCE), a novel architectural paradigm leveraging the algebraic structures of Functors, Applicative Functors, and Monads to provide a formal foundation for agent design. MCE treats agent workflows as computational contexts where cross-cutting concerns, such as state propagation, short-circuiting error handling, and asynchronous execution, are managed intrinsically by the algebraic properties of the abstraction. We demonstrate how Monads enable robust sequential composition, how Applicatives provide a principled structure for parallel execution, and crucially, how Monad Transformers allow for the systematic composition of these capabilities. This layered approach enables developers to construct complex, resilient, and efficient AI agents from simple, independently verifiable components. We further extend this framework to describe Meta-Agents, which leverage MCE for generative orchestration, dynamically creating and managing sub-agent workflows through metaprogramming. Project Page: https://github.com/yifanzhang-pro/monadic-context-engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5355\u5b50\u4e0a\u4e0b\u6587\u5de5\u7a0b(MCE),\u4e00\u79cd\u57fa\u4e8e\u51fd\u5b50\u3001\u5e94\u7528\u51fd\u5b50\u548c\u5355\u5b50\u7b49\u4ee3\u6570\u7ed3\u6784\u7684\u65b0\u578bAI\u667a\u80fd\u4f53\u67b6\u6784\u8303\u5f0f,\u7528\u4e8e\u89e3\u51b3\u5f53\u524d\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u72b6\u6001\u7ba1\u7406\u3001\u9519\u8bef\u5904\u7406\u548c\u5e76\u53d1\u6267\u884c\u65b9\u9762\u7684\u8106\u5f31\u6027\u95ee\u9898,\u5e76\u6269\u5c55\u5230\u5143\u667a\u80fd\u4f53\u7684\u52a8\u6001\u7f16\u6392\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u67b6\u6784\u901a\u5e38\u91c7\u7528\u547d\u4ee4\u5f0f\u3001\u4e34\u65f6\u6027\u7684\u8bbe\u8ba1\u6a21\u5f0f,\u5bfc\u81f4\u7cfb\u7edf\u8106\u5f31,\u5728\u72b6\u6001\u7ba1\u7406\u3001\u9519\u8bef\u5904\u7406\u548c\u5e76\u53d1\u63a7\u5236\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u56f0\u96be\u3002\u9700\u8981\u4e00\u79cd\u5177\u6709\u5f62\u5f0f\u5316\u57fa\u7840\u7684\u67b6\u6784\u8303\u5f0f\u6765\u6784\u5efa\u66f4\u52a0\u5065\u58ee\u3001\u9ad8\u6548\u548c\u53ef\u9a8c\u8bc1\u7684AI\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u5355\u5b50\u4e0a\u4e0b\u6587\u5de5\u7a0b(MCE)\u67b6\u6784\u8303\u5f0f,\u5229\u7528\u51fd\u5b50(Functors)\u3001\u5e94\u7528\u51fd\u5b50(Applicative Functors)\u548c\u5355\u5b50(Monads)\u7b49\u4ee3\u6570\u7ed3\u6784\u4e3a\u667a\u80fd\u4f53\u8bbe\u8ba1\u63d0\u4f9b\u5f62\u5f0f\u5316\u57fa\u7840\u3002\u5c06\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u89c6\u4e3a\u8ba1\u7b97\u4e0a\u4e0b\u6587,\u901a\u8fc7\u4ee3\u6570\u62bd\u8c61\u7684\u5185\u5728\u5c5e\u6027\u7ba1\u7406\u72b6\u6001\u4f20\u64ad\u3001\u77ed\u8def\u9519\u8bef\u5904\u7406\u548c\u5f02\u6b65\u6267\u884c\u7b49\u6a2a\u5207\u5173\u6ce8\u70b9\u3002\u4f7f\u7528\u5355\u5b50\u5b9e\u73b0\u5065\u58ee\u7684\u987a\u5e8f\u7ec4\u5408,\u5e94\u7528\u51fd\u5b50\u63d0\u4f9b\u5e76\u884c\u6267\u884c\u7684\u539f\u5219\u6027\u7ed3\u6784,\u5355\u5b50\u8f6c\u6362\u5668(Monad Transformers)\u5b9e\u73b0\u8fd9\u4e9b\u80fd\u529b\u7684\u7cfb\u7edf\u5316\u7ec4\u5408\u3002\u8fdb\u4e00\u6b65\u6269\u5c55\u6846\u67b6\u63cf\u8ff0\u5143\u667a\u80fd\u4f53(Meta-Agents),\u901a\u8fc7\u5143\u7f16\u7a0b\u52a8\u6001\u521b\u5efa\u548c\u7ba1\u7406\u5b50\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002", "result": "\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5355\u5b50\u5b9e\u73b0\u5065\u58ee\u7684\u987a\u5e8f\u7ec4\u5408,\u5e94\u7528\u51fd\u5b50\u5982\u4f55\u4e3a\u5e76\u884c\u6267\u884c\u63d0\u4f9b\u539f\u5219\u6027\u7ed3\u6784,\u4ee5\u53ca\u5355\u5b50\u8f6c\u6362\u5668\u5982\u4f55\u7cfb\u7edf\u5316\u5730\u7ec4\u5408\u8fd9\u4e9b\u80fd\u529b\u3002\u8fd9\u79cd\u5206\u5c42\u65b9\u6cd5\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u4ece\u7b80\u5355\u3001\u53ef\u72ec\u7acb\u9a8c\u8bc1\u7684\u7ec4\u4ef6\u6784\u5efa\u590d\u6742\u3001\u5f39\u6027\u548c\u9ad8\u6548\u7684AI\u667a\u80fd\u4f53\u3002\u6846\u67b6\u6210\u529f\u6269\u5c55\u5230\u5143\u667a\u80fd\u4f53,\u5b9e\u73b0\u4e86\u751f\u6210\u5f0f\u7f16\u6392\u548c\u52a8\u6001\u5b50\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7ba1\u7406\u3002", "conclusion": "\u5355\u5b50\u4e0a\u4e0b\u6587\u5de5\u7a0b\u4e3aAI\u667a\u80fd\u4f53\u67b6\u6784\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u5f62\u5f0f\u5316\u7406\u8bba\u57fa\u7840,\u901a\u8fc7\u4ee3\u6570\u7ed3\u6784\u7684\u7ec4\u5408\u6027\u548c\u53ef\u9a8c\u8bc1\u6027,\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u547d\u4ee4\u5f0f\u667a\u80fd\u4f53\u67b6\u6784\u7684\u8106\u5f31\u6027\u95ee\u9898\u3002\u8be5\u8303\u5f0f\u80fd\u591f\u4ece\u7b80\u5355\u7ec4\u4ef6\u6784\u5efa\u590d\u6742\u667a\u80fd\u4f53\u7cfb\u7edf,\u5e76\u652f\u6301\u5143\u667a\u80fd\u4f53\u7684\u52a8\u6001\u7f16\u6392,\u4e3a\u6784\u5efa\u66f4\u52a0\u5065\u58ee\u3001\u53ef\u7ef4\u62a4\u548c\u9ad8\u6548\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u67b6\u6784\u65b9\u5411\u3002"}}
{"id": "2512.22470", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22470", "abs": "https://arxiv.org/abs/2512.22470", "authors": ["Sadia Asif", "Israel Antonio Rosales Laguan", "Haris Khan", "Shumaila Asif", "Muneeb Asif"], "title": "DarkPatterns-LLM: A Multi-Layer Benchmark for Detecting Manipulative and Harmful AI Behavior", "comment": null, "summary": "The proliferation of Large Language Models (LLMs) has intensified concerns about manipulative or deceptive behaviors that can undermine user autonomy, trust, and well-being. Existing safety benchmarks predominantly rely on coarse binary labels and fail to capture the nuanced psychological and social mechanisms constituting manipulation. We introduce \\textbf{DarkPatterns-LLM}, a comprehensive benchmark dataset and diagnostic framework for fine-grained assessment of manipulative content in LLM outputs across seven harm categories: Legal/Power, Psychological, Emotional, Physical, Autonomy, Economic, and Societal Harm. Our framework implements a four-layer analytical pipeline comprising Multi-Granular Detection (MGD), Multi-Scale Intent Analysis (MSIAN), Threat Harmonization Protocol (THP), and Deep Contextual Risk Alignment (DCRA). The dataset contains 401 meticulously curated examples with instruction-response pairs and expert annotations. Through evaluation of state-of-the-art models including GPT-4, Claude 3.5, and LLaMA-3-70B, we observe significant performance disparities (65.2\\%--89.7\\%) and consistent weaknesses in detecting autonomy-undermining patterns. DarkPatterns-LLM establishes the first standardized, multi-dimensional benchmark for manipulation detection in LLMs, offering actionable diagnostics toward more trustworthy AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DarkPatterns-LLM\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bca\u65ad\u6846\u67b6,\u7528\u4e8e\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4e2d\u7684\u64cd\u7eb5\u6027\u5185\u5bb9,\u6db5\u76d6\u4e03\u5927\u5371\u5bb3\u7c7b\u522b,\u5305\u542b401\u4e2a\u7cbe\u5fc3\u6807\u6ce8\u7684\u6837\u4f8b,\u5e76\u901a\u8fc7\u8bc4\u4f30\u4e3b\u6d41\u6a21\u578b\u63ed\u793a\u4e86\u5176\u5728\u68c0\u6d4b\u81ea\u4e3b\u6027\u7834\u574f\u6a21\u5f0f\u65b9\u9762\u7684\u663e\u8457\u5f31\u70b9\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u57fa\u51c6\u4e3b\u8981\u4f9d\u8d56\u7c97\u7c92\u5ea6\u7684\u4e8c\u5143\u6807\u7b7e,\u65e0\u6cd5\u6355\u6349\u6784\u6210\u64cd\u7eb5\u884c\u4e3a\u7684\u7ec6\u5fae\u5fc3\u7406\u548c\u793e\u4f1a\u673a\u5236\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca,\u5176\u53ef\u80fd\u4ea7\u751f\u7684\u64cd\u7eb5\u6027\u6216\u6b3a\u9a97\u6027\u884c\u4e3a\u5bf9\u7528\u6237\u81ea\u4e3b\u6027\u3001\u4fe1\u4efb\u548c\u798f\u7949\u6784\u6210\u5a01\u80c1,\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u66f4\u7cbe\u7ec6\u3001\u591a\u7ef4\u5ea6\u7684\u64cd\u7eb5\u68c0\u6d4b\u6807\u51c6\u3002", "method": "\u6784\u5efa\u4e86DarkPatterns-LLM\u6846\u67b6,\u5b9e\u65bd\u56db\u5c42\u5206\u6790\u7ba1\u9053:\u591a\u7c92\u5ea6\u68c0\u6d4b(MGD)\u3001\u591a\u5c3a\u5ea6\u610f\u56fe\u5206\u6790(MSIAN)\u3001\u5a01\u80c1\u534f\u8c03\u534f\u8bae(THP)\u548c\u6df1\u5ea6\u4e0a\u4e0b\u6587\u98ce\u9669\u5bf9\u9f50(DCRA)\u3002\u6570\u636e\u96c6\u5305\u542b401\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u6307\u4ee4-\u54cd\u5e94\u5bf9\u6837\u4f8b,\u6db5\u76d6\u4e03\u5927\u5371\u5bb3\u7c7b\u522b(\u6cd5\u5f8b/\u6743\u529b\u3001\u5fc3\u7406\u3001\u60c5\u611f\u3001\u8eab\u4f53\u3001\u81ea\u4e3b\u6027\u3001\u7ecf\u6d4e\u548c\u793e\u4f1a\u5371\u5bb3),\u5e76\u914d\u6709\u4e13\u5bb6\u6807\u6ce8\u3002", "result": "\u5bf9GPT-4\u3001Claude 3.5\u548cLLaMA-3-70B\u7b49\u6700\u5148\u8fdb\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a,\u6a21\u578b\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02(65.2%-89.7%),\u6240\u6709\u6a21\u578b\u5728\u68c0\u6d4b\u7834\u574f\u81ea\u4e3b\u6027\u7684\u6a21\u5f0f\u65b9\u9762\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u5f31\u70b9\u3002", "conclusion": "DarkPatterns-LLM\u5efa\u7acb\u4e86\u9996\u4e2a\u6807\u51c6\u5316\u3001\u591a\u7ef4\u5ea6\u7684\u5927\u8bed\u8a00\u6a21\u578b\u64cd\u7eb5\u68c0\u6d4b\u57fa\u51c6,\u4e3a\u6784\u5efa\u66f4\u53ef\u4fe1\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u5de5\u5177,\u586b\u8865\u4e86\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u5728\u7ec6\u7c92\u5ea6\u64cd\u7eb5\u884c\u4e3a\u68c0\u6d4b\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.22568", "categories": ["cs.AI", "physics.bio-ph", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.22568", "abs": "https://arxiv.org/abs/2512.22568", "authors": ["Rajesh P. N. Rao", "Vishwas Sathish", "Linxing Preston Jiang", "Matthew Bryan", "Prashant Rangarajan"], "title": "Lessons from Neuroscience for AI: How integrating Actions, Compositional Structure and Episodic Memory could enable Safe, Interpretable and Human-Like AI", "comment": null, "summary": "The phenomenal advances in large language models (LLMs) and other foundation models over the past few years have been based on optimizing large-scale transformer models on the surprisingly simple objective of minimizing next-token prediction loss, a form of predictive coding that is also the backbone of an increasingly popular model of brain function in neuroscience and cognitive science. However, current foundation models ignore three other important components of state-of-the-art predictive coding models: tight integration of actions with generative models, hierarchical compositional structure, and episodic memory. We propose that to achieve safe, interpretable, energy-efficient, and human-like AI, foundation models should integrate actions, at multiple scales of abstraction, with a compositional generative architecture and episodic memory. We present recent evidence from neuroscience and cognitive science on the importance of each of these components. We describe how the addition of these missing components to foundation models could help address some of their current deficiencies: hallucinations and superficial understanding of concepts due to lack of grounding, a missing sense of agency/responsibility due to lack of control, threats to safety and trustworthiness due to lack of interpretability, and energy inefficiency. We compare our proposal to current trends, such as adding chain-of-thought (CoT) reasoning and retrieval-augmented generation (RAG) to foundation models, and discuss new ways of augmenting these models with brain-inspired components. We conclude by arguing that a rekindling of the historically fruitful exchange of ideas between brain science and AI will help pave the way towards safe and interpretable human-centered AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u57fa\u4e8e\u9884\u6d4b\u7f16\u7801\u539f\u7406\u53d6\u5f97\u5de8\u5927\u8fdb\u5c55,\u4f46\u7f3a\u5c11\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6:\u52a8\u4f5c\u6574\u5408\u3001\u5c42\u6b21\u5316\u7ec4\u5408\u7ed3\u6784\u548c\u60c5\u666f\u8bb0\u5fc6\u3002\u6587\u7ae0\u4e3b\u5f20\u901a\u8fc7\u878d\u5408\u8fd9\u4e9b\u8111\u79d1\u5b66\u542f\u53d1\u7684\u7ec4\u4ef6\u6765\u6784\u5efa\u66f4\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u3001\u8282\u80fd\u4e14\u7c7b\u4eba\u7684AI\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u57fa\u7840\u6a21\u578b\u867d\u7136\u5728\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272,\u4f46\u5b58\u5728\u5e7b\u89c9\u3001\u6982\u5ff5\u7406\u89e3\u80a4\u6d45\u3001\u7f3a\u4e4f\u4e3b\u4f53\u611f\u548c\u8d23\u4efb\u611f\u3001\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u5bfc\u81f4\u7684\u5b89\u5168\u9690\u60a3\u4ee5\u53ca\u80fd\u6e90\u6548\u7387\u4f4e\u7b49\u95ee\u9898\u3002\u8fd9\u4e9b\u7f3a\u9677\u6e90\u4e8e\u5ffd\u7565\u4e86\u795e\u7ecf\u79d1\u5b66\u9884\u6d4b\u7f16\u7801\u6a21\u578b\u4e2d\u7684\u4e09\u4e2a\u91cd\u8981\u7ec4\u4ef6:\u52a8\u4f5c\u4e0e\u751f\u6210\u6a21\u578b\u7684\u7d27\u5bc6\u6574\u5408\u3001\u5c42\u6b21\u5316\u7ec4\u5408\u7ed3\u6784\u548c\u60c5\u666f\u8bb0\u5fc6\u3002\u9700\u8981\u4ece\u8111\u79d1\u5b66\u4e2d\u6c72\u53d6\u7075\u611f\u6765\u6539\u8fdbAI\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u5c06\u4e09\u4e2a\u8111\u79d1\u5b66\u542f\u53d1\u7684\u7ec4\u4ef6\u6574\u5408\u5230\u57fa\u7840\u6a21\u578b\u4e2d:(1)\u5728\u591a\u4e2a\u62bd\u8c61\u5c3a\u5ea6\u4e0a\u5c06\u52a8\u4f5c\u4e0e\u751f\u6210\u6a21\u578b\u7d27\u5bc6\u6574\u5408;(2)\u5f15\u5165\u5c42\u6b21\u5316\u7ec4\u5408\u67b6\u6784;(3)\u52a0\u5165\u60c5\u666f\u8bb0\u5fc6\u673a\u5236\u3002\u6587\u7ae0\u7efc\u8ff0\u4e86\u795e\u7ecf\u79d1\u5b66\u548c\u8ba4\u77e5\u79d1\u5b66\u4e2d\u5173\u4e8e\u8fd9\u4e9b\u7ec4\u4ef6\u91cd\u8981\u6027\u7684\u6700\u65b0\u8bc1\u636e,\u5e76\u5c06\u8be5\u63d0\u6848\u4e0e\u5f53\u524d\u8d8b\u52bf(\u5982\u601d\u7ef4\u94fe\u63a8\u7406CoT\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210RAG)\u8fdb\u884c\u6bd4\u8f83,\u63a2\u8ba8\u7528\u8111\u542f\u53d1\u7ec4\u4ef6\u589e\u5f3a\u6a21\u578b\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u6587\u7ae0\u8bba\u8bc1\u4e86\u8fd9\u4e9b\u7ec4\u4ef6\u5982\u4f55\u5e2e\u52a9\u89e3\u51b3\u57fa\u7840\u6a21\u578b\u7684\u5f53\u524d\u7f3a\u9677:\u901a\u8fc7\u52a8\u4f5c\u6574\u5408\u5b9e\u73b0\u6982\u5ff5\u63a5\u5730\u4ee5\u51cf\u5c11\u5e7b\u89c9\u548c\u63d0\u5347\u7406\u89e3\u6df1\u5ea6;\u901a\u8fc7\u63a7\u5236\u80fd\u529b\u5efa\u7acb\u4e3b\u4f53\u611f\u548c\u8d23\u4efb\u611f;\u901a\u8fc7\u5c42\u6b21\u5316\u7ec4\u5408\u7ed3\u6784\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u4ece\u800c\u589e\u5f3a\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6;\u901a\u8fc7\u8fd9\u4e9b\u673a\u5236\u63d0\u5347\u80fd\u6e90\u6548\u7387\u3002\u5c55\u793a\u4e86\u8111\u79d1\u5b66\u4e0eAI\u4e4b\u95f4\u601d\u60f3\u4ea4\u6d41\u7684\u6f5c\u5728\u4ef7\u503c\u3002", "conclusion": "\u91cd\u65b0\u70b9\u71c3\u8111\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u4e4b\u95f4\u5386\u53f2\u4e0a\u5bcc\u6709\u6210\u6548\u7684\u601d\u60f3\u4ea4\u6d41,\u5c06\u6709\u52a9\u4e8e\u94fa\u5e73\u901a\u5f80\u5b89\u5168\u3001\u53ef\u89e3\u91ca\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684AI\u4e4b\u8def\u3002\u901a\u8fc7\u6574\u5408\u52a8\u4f5c\u3001\u5c42\u6b21\u5316\u7ec4\u5408\u7ed3\u6784\u548c\u60c5\u666f\u8bb0\u5fc6\u8fd9\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6,\u53ef\u4ee5\u6784\u5efa\u66f4\u63a5\u8fd1\u4eba\u7c7b\u8ba4\u77e5\u3001\u66f4\u5b89\u5168\u53ef\u9760\u7684\u4e0b\u4e00\u4ee3\u57fa\u7840\u6a21\u578b\u3002"}}
{"id": "2512.22579", "categories": ["cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.22579", "abs": "https://arxiv.org/abs/2512.22579", "authors": ["Yong Xiao", "Xubo Li", "Haoran Zhou", "Yingyu Li", "Yayu Gao", "Guangming Shi", "Ping Zhang", "Marwan Krunz"], "title": "SANet: A Semantic-aware Agentic AI Networking Framework for Cross-layer Optimization in 6G", "comment": "Submitted to IEEE Transactions on Mobile Computing", "summary": "Agentic AI networking (AgentNet) is a novel AI-native networking paradigm in which a large number of specialized AI agents collaborate to perform autonomous decision-making, dynamic environmental adaptation, and complex missions. It has the potential to facilitate real-time network management and optimization functions, including self-configuration, self-optimization, and self-adaptation across diverse and complex environments. This paper proposes SANet, a novel semantic-aware AgentNet architecture for wireless networks that can infer the semantic goal of the user and automatically assign agents associated with different layers of the network to fulfill the inferred goal. Motivated by the fact that AgentNet is a decentralized framework in which collaborating agents may generally have different and even conflicting objectives, we formulate the decentralized optimization of SANet as a multi-agent multi-objective problem, and focus on finding the Pareto-optimal solution for agents with distinct and potentially conflicting objectives. We propose three novel metrics for evaluating SANet. Furthermore, we develop a model partition and sharing (MoPS) framework in which large models, e.g., deep learning models, of different agents can be partitioned into shared and agent-specific parts that are jointly constructed and deployed according to agents' local computational resources. Two decentralized optimization algorithms are proposed. We derive theoretical bounds and prove that there exists a three-way tradeoff among optimization, generalization, and conflicting errors. We develop an open-source RAN and core network-based hardware prototype that implements agents to interact with three different layers of the network. Experimental results show that the proposed framework achieved performance gains of up to 14.61% while requiring only 44.37% of FLOPs required by state-of-the-art algorithms.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.22601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22601", "abs": "https://arxiv.org/abs/2512.22601", "authors": ["Tao Zhou", "Lingyu Shu", "Zixing Zhang", "Jing Han"], "title": "Tyee: A Unified, Modular, and Fully-Integrated Configurable Toolkit for Intelligent Physiological Health Care", "comment": null, "summary": "Deep learning has shown great promise in physiological signal analysis, yet its progress is hindered by heterogeneous data formats, inconsistent preprocessing strategies, fragmented model pipelines, and non-reproducible experimental setups. To address these limitations, we present Tyee, a unified, modular, and fully-integrated configurable toolkit designed for intelligent physiological healthcare. Tyee introduces three key innovations: (1) a unified data interface and configurable preprocessing pipeline for 12 kinds of signal modalities; (2) a modular and extensible architecture enabling flexible integration and rapid prototyping across tasks; and (3) end-to-end workflow configuration, promoting reproducible and scalable experimentation. Tyee demonstrates consistent practical effectiveness and generalizability, outperforming or matching baselines across all evaluated tasks (with state-of-the-art results on 12 of 13 datasets). The Tyee toolkit is released at https://github.com/SmileHnu/Tyee and actively maintained.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Tyee,\u4e00\u4e2a\u7528\u4e8e\u667a\u80fd\u751f\u7406\u5065\u5eb7\u76d1\u6d4b\u7684\u7edf\u4e00\u3001\u6a21\u5757\u5316\u3001\u5b8c\u5168\u96c6\u6210\u7684\u53ef\u914d\u7f6e\u5de5\u5177\u5305,\u901a\u8fc7\u7edf\u4e00\u6570\u636e\u63a5\u53e3\u3001\u6a21\u5757\u5316\u67b6\u6784\u548c\u7aef\u5230\u7aef\u5de5\u4f5c\u6d41\u914d\u7f6e,\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u751f\u7406\u4fe1\u53f7\u5206\u6790\u4e2d\u9762\u4e34\u7684\u6570\u636e\u683c\u5f0f\u5f02\u6784\u3001\u9884\u5904\u7406\u4e0d\u4e00\u81f4\u3001\u6a21\u578b\u7ba1\u9053\u788e\u7247\u5316\u548c\u5b9e\u9a8c\u4e0d\u53ef\u590d\u73b0\u7b49\u95ee\u9898,\u572813\u4e2a\u6570\u636e\u96c6\u4e2d\u768412\u4e2a\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u751f\u7406\u4fe1\u53f7\u5206\u6790\u9886\u57df\u867d\u7136\u524d\u666f\u5e7f\u9614,\u4f46\u5176\u53d1\u5c55\u53d7\u5230\u591a\u65b9\u9762\u9650\u5236:\u6570\u636e\u683c\u5f0f\u5f02\u6784\u3001\u9884\u5904\u7406\u7b56\u7565\u4e0d\u4e00\u81f4\u3001\u6a21\u578b\u7ba1\u9053\u788e\u7247\u5316\u4ee5\u53ca\u5b9e\u9a8c\u8bbe\u7f6e\u4e0d\u53ef\u590d\u73b0\u3002\u8fd9\u4e9b\u95ee\u9898\u4e25\u91cd\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u548c\u5b9e\u9645\u5e94\u7528,\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u3001\u6807\u51c6\u5316\u4e14\u53ef\u590d\u73b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u63a8\u52a8\u667a\u80fd\u751f\u7406\u5065\u5eb7\u76d1\u6d4b\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "Tyee\u5de5\u5177\u5305\u63d0\u51fa\u4e86\u4e09\u4e2a\u5173\u952e\u521b\u65b0:(1)\u4e3a12\u79cd\u4fe1\u53f7\u6a21\u6001\u8bbe\u8ba1\u4e86\u7edf\u4e00\u7684\u6570\u636e\u63a5\u53e3\u548c\u53ef\u914d\u7f6e\u7684\u9884\u5904\u7406\u7ba1\u9053,\u89e3\u51b3\u6570\u636e\u5f02\u6784\u95ee\u9898;(2)\u91c7\u7528\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u7684\u67b6\u6784\u8bbe\u8ba1,\u652f\u6301\u8de8\u4efb\u52a1\u7684\u7075\u6d3b\u96c6\u6210\u548c\u5feb\u901f\u539f\u578b\u5f00\u53d1;(3)\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u5de5\u4f5c\u6d41\u914d\u7f6e\u673a\u5236,\u4fc3\u8fdb\u5b9e\u9a8c\u7684\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u8be5\u5de5\u5177\u5305\u63d0\u4f9b\u4e86\u5b8c\u5168\u96c6\u6210\u7684\u914d\u7f6e\u5316\u89e3\u51b3\u65b9\u6848,\u8986\u76d6\u4ece\u6570\u636e\u5904\u7406\u5230\u6a21\u578b\u8bad\u7ec3\u7684\u5168\u6d41\u7a0b\u3002", "result": "Tyee\u5728\u6240\u6709\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272,\u6027\u80fd\u8d85\u8d8a\u6216\u5339\u914d\u57fa\u7ebf\u65b9\u6cd5,\u572813\u4e2a\u6570\u636e\u96c6\u4e2d\u768412\u4e2a\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb(state-of-the-art)\u7684\u7ed3\u679c\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86Tyee\u5177\u6709\u4e00\u81f4\u7684\u5b9e\u7528\u6709\u6548\u6027\u548c\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b,\u80fd\u591f\u5728\u4e0d\u540c\u7684\u751f\u7406\u4fe1\u53f7\u5206\u6790\u4efb\u52a1\u4e2d\u7a33\u5b9a\u53d1\u6325\u4f5c\u7528\u3002", "conclusion": "Tyee\u6210\u529f\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u751f\u7406\u4fe1\u53f7\u5206\u6790\u9886\u57df\u9762\u4e34\u7684\u5173\u952e\u6311\u6218,\u901a\u8fc7\u7edf\u4e00\u7684\u63a5\u53e3\u3001\u6a21\u5757\u5316\u67b6\u6784\u548c\u53ef\u914d\u7f6e\u7684\u5de5\u4f5c\u6d41,\u4e3a\u667a\u80fd\u751f\u7406\u5065\u5eb7\u76d1\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u590d\u73b0\u4e14\u6613\u4e8e\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u5de5\u5177\u5305\u5df2\u5f00\u6e90\u5e76\u6301\u7eed\u7ef4\u62a4,\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u5b9e\u9a8c\u5e73\u53f0,\u6709\u671b\u63a8\u52a8\u751f\u7406\u4fe1\u53f7\u5206\u6790\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2512.22605", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.22605", "abs": "https://arxiv.org/abs/2512.22605", "authors": ["Junshu Dai", "Yu Wang", "Tongya Zheng", "Wei Ji", "Qinghong Guo", "Ji Cao", "Jie Song", "Canghong Jin", "Mingli Song"], "title": "Learning Multi-Modal Mobility Dynamics for Generalized Next Location Recommendation", "comment": null, "summary": "The precise prediction of human mobility has produced significant socioeconomic impacts, such as location recommendations and evacuation suggestions. However, existing methods suffer from limited generalization capability: unimodal approaches are constrained by data sparsity and inherent biases, while multi-modal methods struggle to effectively capture mobility dynamics caused by the semantic gap between static multi-modal representation and spatial-temporal dynamics. Therefore, we leverage multi-modal spatial-temporal knowledge to characterize mobility dynamics for the location recommendation task, dubbed as \\textbf{M}ulti-\\textbf{M}odal \\textbf{Mob}ility (\\textbf{M}$^3$\\textbf{ob}). First, we construct a unified spatial-temporal relational graph (STRG) for multi-modal representation, by leveraging the functional semantics and spatial-temporal knowledge captured by the large language models (LLMs)-enhanced spatial-temporal knowledge graph (STKG). Second, we design a gating mechanism to fuse spatial-temporal graph representations of different modalities, and propose an STKG-guided cross-modal alignment to inject spatial-temporal dynamic knowledge into the static image modality. Extensive experiments on six public datasets show that our proposed method not only achieves consistent improvements in normal scenarios but also exhibits significant generalization ability in abnormal scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u79fb\u52a8\u6027\u9884\u6d4b\u65b9\u6cd5M\u00b3ob,\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u7684\u65f6\u7a7a\u5173\u7cfb\u56fe\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u673a\u5236,\u6709\u6548\u878d\u5408\u591a\u6a21\u6001\u6570\u636e\u4ee5\u63d0\u5347\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\u7684\u6cdb\u5316\u80fd\u529b,\u5728\u4f4d\u7f6e\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u6709\u9650:\u5355\u6a21\u6001\u65b9\u6cd5\u53d7\u6570\u636e\u7a00\u758f\u6027\u548c\u56fa\u6709\u504f\u5dee\u9650\u5236,\u591a\u6a21\u6001\u65b9\u6cd5\u5219\u96be\u4ee5\u6709\u6548\u6355\u6349\u79fb\u52a8\u52a8\u6001,\u56e0\u4e3a\u9759\u6001\u591a\u6a21\u6001\u8868\u793a\u4e0e\u65f6\u7a7a\u52a8\u6001\u4e4b\u95f4\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5229\u7528\u591a\u6a21\u6001\u65f6\u7a7a\u77e5\u8bc6\u6765\u523b\u753b\u79fb\u52a8\u52a8\u6001\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faM\u00b3ob\u65b9\u6cd5,\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u8bbe\u8ba1:(1)\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u7684\u65f6\u7a7a\u77e5\u8bc6\u56fe\u8c31(STKG)\u6355\u83b7\u529f\u80fd\u8bed\u4e49\u548c\u65f6\u7a7a\u77e5\u8bc6,\u6784\u5efa\u7edf\u4e00\u7684\u65f6\u7a7a\u5173\u7cfb\u56fe(STRG)\u8fdb\u884c\u591a\u6a21\u6001\u8868\u793a;(2)\u8bbe\u8ba1\u95e8\u63a7\u673a\u5236\u878d\u5408\u4e0d\u540c\u6a21\u6001\u7684\u65f6\u7a7a\u56fe\u8868\u793a,\u5e76\u63d0\u51faSTKG\u5f15\u5bfc\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\u65b9\u6cd5,\u5c06\u65f6\u7a7a\u52a8\u6001\u77e5\u8bc6\u6ce8\u5165\u9759\u6001\u56fe\u50cf\u6a21\u6001\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e,\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u6b63\u5e38\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347,\u800c\u4e14\u5728\u5f02\u5e38\u573a\u666f\u4e0b\u4e5f\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u591a\u6a21\u6001\u65f6\u7a7a\u77e5\u8bc6\u878d\u5408\u548c\u8de8\u6a21\u6001\u5bf9\u9f50,M\u00b3ob\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u79fb\u52a8\u6027\u9884\u6d4b\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u95ee\u9898,\u5728\u4f4d\u7f6e\u63a8\u8350\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0,\u8bc1\u660e\u4e86\u5229\u7528LLM\u589e\u5f3a\u7684\u65f6\u7a7a\u77e5\u8bc6\u56fe\u8c31\u548c\u7edf\u4e00\u65f6\u7a7a\u5173\u7cfb\u56fe\u5efa\u6a21\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.22625", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.22625", "abs": "https://arxiv.org/abs/2512.22625", "authors": ["Paul Schneider", "Amalie Schramm"], "title": "The Wisdom of Deliberating AI Crowds: Does Deliberation Improve LLM-Based Forecasting?", "comment": "13 pages, 2 figures, 5 tables, for source code and data see https://github.com/priorb-source/delib-ai-wisdom", "summary": "Structured deliberation has been found to improve the performance of human forecasters. This study investigates whether a similar intervention, i.e. allowing LLMs to review each other's forecasts before updating, can improve accuracy in large language models (GPT-5, Claude Sonnet 4.5, Gemini Pro 2.5). Using 202 resolved binary questions from the Metaculus Q2 2025 AI Forecasting Tournament, accuracy was assessed across four scenarios: (1) diverse models with distributed information, (2) diverse models with shared information, (3) homogeneous models with distributed information, and (4) homogeneous models with shared information. Results show that the intervention significantly improves accuracy in scenario (2), reducing Log Loss by 0.020 or about 4 percent in relative terms (p = 0.017). However, when homogeneous groups (three instances of the same model) engaged in the same process, no benefit was observed. Unexpectedly, providing LLMs with additional contextual information did not improve forecast accuracy, limiting our ability to study information pooling as a mechanism. Our findings suggest that deliberation may be a viable strategy for improving LLM forecasting.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u8ba9\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u76f8\u4e92\u5ba1\u9605\u9884\u6d4b\u7ed3\u679c\u662f\u5426\u80fd\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002\u4f7f\u7528202\u4e2a\u5df2\u89e3\u51b3\u7684\u4e8c\u5143\u95ee\u9898,\u7814\u7a76\u53d1\u73b0\u5728\u591a\u6837\u5316\u6a21\u578b\u5171\u4eab\u4fe1\u606f\u7684\u573a\u666f\u4e0b,\u8fd9\u79cd\"\u7ed3\u6784\u5316\u8ba8\u8bba\"\u5e72\u9884\u663e\u8457\u964d\u4f4e\u4e86\u7ea64%\u7684\u5bf9\u6570\u635f\u5931(p=0.017),\u4f46\u5728\u540c\u8d28\u6a21\u578b\u7ec4\u4e2d\u672a\u89c2\u5bdf\u5230\u6539\u8fdb\u6548\u679c\u3002", "motivation": "\u7ed3\u6784\u5316\u8ba8\u8bba\u5df2\u88ab\u8bc1\u660e\u80fd\u63d0\u9ad8\u4eba\u7c7b\u9884\u6d4b\u8005\u7684\u8868\u73b0,\u7814\u7a76\u8005\u5e0c\u671b\u9a8c\u8bc1\u7c7b\u4f3c\u7684\u5e72\u9884\u63aa\u65bd(\u5373\u8ba9LLMs\u76f8\u4e92\u5ba1\u9605\u5f7c\u6b64\u7684\u9884\u6d4b\u540e\u518d\u66f4\u65b0)\u662f\u5426\u4e5f\u80fd\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8ba8\u8bba\u673a\u5236\u662f\u5426\u53ef\u4f5c\u4e3a\u6539\u8fdbLLM\u9884\u6d4b\u7684\u53ef\u884c\u7b56\u7565\u3002", "method": "\u4f7f\u7528\u6765\u81eaMetaculus Q2 2025 AI\u9884\u6d4b\u9526\u6807\u8d5b\u7684202\u4e2a\u5df2\u89e3\u51b3\u7684\u4e8c\u5143\u95ee\u9898,\u5728\u56db\u79cd\u573a\u666f\u4e0b\u8bc4\u4f30\u51c6\u786e\u6027:(1)\u591a\u6837\u5316\u6a21\u578b+\u5206\u5e03\u5f0f\u4fe1\u606f,(2)\u591a\u6837\u5316\u6a21\u578b+\u5171\u4eab\u4fe1\u606f,(3)\u540c\u8d28\u6a21\u578b+\u5206\u5e03\u5f0f\u4fe1\u606f,(4)\u540c\u8d28\u6a21\u578b+\u5171\u4eab\u4fe1\u606f\u3002\u6d4b\u8bd5\u6a21\u578b\u5305\u62ecGPT-5\u3001Claude Sonnet 4.5\u548cGemini Pro 2.5,\u901a\u8fc7\u8ba9\u6a21\u578b\u76f8\u4e92\u5ba1\u9605\u9884\u6d4b\u5e76\u66f4\u65b0\u6765\u5b9e\u73b0\"\u7ed3\u6784\u5316\u8ba8\u8bba\"\u5e72\u9884\u3002", "result": "\u5728\u573a\u666f(2)(\u591a\u6837\u5316\u6a21\u578b+\u5171\u4eab\u4fe1\u606f)\u4e2d,\u5e72\u9884\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027,\u5bf9\u6570\u635f\u5931\u964d\u4f4e\u4e860.020,\u76f8\u5bf9\u6539\u8fdb\u7ea64%(p=0.017)\u3002\u7136\u800c,\u5728\u540c\u8d28\u6a21\u578b\u7ec4(\u4e09\u4e2a\u76f8\u540c\u6a21\u578b\u5b9e\u4f8b)\u4e2d\u672a\u89c2\u5bdf\u5230\u4efb\u4f55\u6539\u8fdb\u3002\u610f\u5916\u7684\u662f,\u63d0\u4f9b\u989d\u5916\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u672a\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027,\u8fd9\u9650\u5236\u4e86\u7814\u7a76\u4fe1\u606f\u6c47\u96c6\u673a\u5236\u7684\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e,\u7ed3\u6784\u5316\u8ba8\u8bba\u53ef\u80fd\u662f\u6539\u8fdbLLM\u9884\u6d4b\u7684\u4e00\u79cd\u53ef\u884c\u7b56\u7565,\u4f46\u5176\u6709\u6548\u6027\u53d6\u51b3\u4e8e\u6a21\u578b\u7684\u591a\u6837\u6027\u3002\u591a\u6837\u5316\u6a21\u578b\u4e4b\u95f4\u7684\u76f8\u4e92\u5ba1\u9605\u80fd\u591f\u5e26\u6765\u663e\u8457\u7684\u51c6\u786e\u6027\u63d0\u5347,\u800c\u540c\u8d28\u6a21\u578b\u4e4b\u95f4\u7684\u8ba8\u8bba\u5219\u65e0\u6548\u3002\u8fd9\u63d0\u793a\u6a21\u578b\u591a\u6837\u6027\u5728\u534f\u4f5c\u9884\u6d4b\u4e2d\u7684\u91cd\u8981\u6027,\u4e3a\u672a\u6765LLM\u9884\u6d4b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2512.22629", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.22629", "abs": "https://arxiv.org/abs/2512.22629", "authors": ["Shiyan Liu", "Jian Ma", "Rui Qu"], "title": "DICE: Discrete Interpretable Comparative Evaluation with Probabilistic Scoring for Retrieval-Augmented Generation", "comment": "Accepted at ResponsibleFM @ NeurIPS 2025", "summary": "As Retrieval-Augmented Generation (RAG) systems evolve toward more sophisticated architectures, ensuring their trustworthiness through explainable and robust evaluation becomes critical. Existing scalar metrics suffer from limited interpretability, inadequate uncertainty quantification, and computational inefficiency in multi-system comparisons, hindering responsible deployment of RAG technologies. We introduce DICE (Discrete Interpretable Comparative Evaluation), a two-stage, evidence-coupled framework that advances explainability and robustness in RAG evaluation. DICE combines deep analytical reasoning with probabilistic $\\{A, B, Tie\\}$ scoring to produce transparent, confidence-aware judgments that support accountable system improvement through interpretable reasoning traces, enabling systematic error diagnosis and actionable insights. To address efficiency challenges at scale, DICE employs a Swiss-system tournament that reduces computational complexity from $O(N^2)$ to $O(N \\log N)$, achieving a 42.9% reduction in our eight-system evaluation while preserving ranking fidelity. Validation on a curated Chinese financial QA dataset demonstrates that DICE achieves 85.7% agreement with human experts, substantially outperforming existing LLM-based metrics such as RAGAS. Our results establish DICE as a responsible, explainable, and efficient paradigm for trustworthy RAG system assessment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DICE(\u79bb\u6563\u53ef\u89e3\u91ca\u6bd4\u8f83\u8bc4\u4f30)\u6846\u67b6,\u8fd9\u662f\u4e00\u4e2a\u4e24\u9636\u6bb5\u3001\u8bc1\u636e\u8026\u5408\u7684RAG\u7cfb\u7edf\u8bc4\u4f30\u65b9\u6cd5,\u901a\u8fc7\u6df1\u5ea6\u5206\u6790\u63a8\u7406\u548c\u6982\u7387\u8bc4\u5206\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027,\u5e76\u91c7\u7528\u745e\u58eb\u5236\u9526\u6807\u8d5b\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(N\u00b2)\u964d\u81f3O(N log N),\u5728\u4e2d\u6587\u91d1\u878d\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u8fbe\u523085.7%\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u53ef\u89e3\u91ca\u6027\u6709\u9650\u3001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0d\u8db3\u4ee5\u53ca\u591a\u7cfb\u7edf\u6bd4\u8f83\u65f6\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898,\u8fd9\u4e9b\u7f3a\u9677\u963b\u788d\u4e86RAG\u6280\u672f\u7684\u8d1f\u8d23\u4efb\u90e8\u7f72\u3002\u968f\u7740RAG\u7cfb\u7edf\u67b6\u6784\u65e5\u76ca\u590d\u6742,\u8feb\u5207\u9700\u8981\u4e00\u79cd\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u786e\u4fdd\u5176\u53ef\u4fe1\u5ea6\u3002", "method": "DICE\u91c7\u7528\u4e24\u9636\u6bb5\u3001\u8bc1\u636e\u8026\u5408\u7684\u6846\u67b6:(1)\u7ed3\u5408\u6df1\u5ea6\u5206\u6790\u63a8\u7406\u4e0e\u6982\u7387{A, B, Tie}\u8bc4\u5206\u673a\u5236,\u751f\u6210\u900f\u660e\u4e14\u5177\u6709\u7f6e\u4fe1\u5ea6\u611f\u77e5\u7684\u5224\u65ad;(2)\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8f68\u8ff9\u652f\u6301\u7cfb\u7edf\u6539\u8fdb,\u5b9e\u73b0\u7cfb\u7edf\u6027\u9519\u8bef\u8bca\u65ad\u548c\u53ef\u64cd\u4f5c\u7684\u6d1e\u5bdf;(3)\u91c7\u7528\u745e\u58eb\u5236\u9526\u6807\u8d5b\u7b97\u6cd5\u89e3\u51b3\u5927\u89c4\u6a21\u8bc4\u4f30\u7684\u6548\u7387\u6311\u6218,\u5c06\u8ba1\u7b97\u590d\u6742\u5ea6\u4eceO(N\u00b2)\u964d\u4f4e\u5230O(N log N),\u540c\u65f6\u4fdd\u6301\u6392\u540d\u51c6\u786e\u6027\u3002", "result": "\u5728\u7cbe\u5fc3\u7b56\u5212\u7684\u4e2d\u6587\u91d1\u878d\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9a8c\u8bc1,DICE\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7684\u4e00\u81f4\u6027\u8fbe\u523085.7%,\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u6307\u6807(\u5982RAGAS)\u3002\u5728\u516b\u7cfb\u7edf\u8bc4\u4f30\u4e2d,\u745e\u58eb\u5236\u9526\u6807\u8d5b\u5b9e\u73b0\u4e8642.9%\u7684\u8ba1\u7b97\u91cf\u51cf\u5c11,\u540c\u65f6\u4fdd\u6301\u4e86\u6392\u540d\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DICE\u4e3a\u53ef\u4fe1\u8d56\u7684RAG\u7cfb\u7edf\u8bc4\u4f30\u5efa\u7acb\u4e86\u4e00\u4e2a\u8d1f\u8d23\u4efb\u3001\u53ef\u89e3\u91ca\u4e14\u9ad8\u6548\u7684\u65b0\u8303\u5f0f\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u900f\u660e\u7684\u63a8\u7406\u8fc7\u7a0b\u3001\u7f6e\u4fe1\u5ea6\u91cf\u5316\u548c\u9ad8\u6548\u7684\u591a\u7cfb\u7edf\u6bd4\u8f83\u80fd\u529b,\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027,\u4e3aRAG\u6280\u672f\u7684\u8d1f\u8d23\u4efb\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2512.22716", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22716", "abs": "https://arxiv.org/abs/2512.22716", "authors": ["Jun Wang"], "title": "Memento-II: Learning by Stateful Reflective Memory", "comment": "32 pages, three figures", "summary": "We propose a theoretical framework for continual and experiential learning in large language model agents that integrates episodic memory with reinforcement learning. The framework identifies reflection as the key mechanism that enables agents to adapt through interaction without back propagation or model fine tuning, thereby relaxing the conventional separation between training and deployment.To formalise this process, we introduce the Stateful Reflective Decision Process, which models reflective learning as a two stage read write interaction with episodic memory. Writing stores interaction outcomes and corresponds to policy evaluation, while reading retrieves relevant past cases and corresponds to policy improvement. We show that this process induces an equivalent Markov decision process over augmented state memory representations, allowing the use of classical tools from dynamic programming and reinforcement learning. We further instantiate the framework using entropy regularised policy iteration and establish convergence guarantees. As episodic memory grows and achieves sufficient coverage of the state space, the resulting policy converges to the optimal solution. This work provides a principled foundation for memory augmented and retrieval based language model agents capable of continual adaptation without parameter updates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u60c5\u666f\u8bb0\u5fc6\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u80fd\u591f\u5728\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u6216\u6a21\u578b\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6301\u7eed\u5b66\u4e60\u548c\u7ecf\u9a8c\u5b66\u4e60\uff0c\u6838\u5fc3\u673a\u5236\u662f\u53cd\u601d\u8fc7\u7a0b\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bad\u7ec3\u548c\u90e8\u7f72\u4e4b\u95f4\u5b58\u5728\u4e25\u683c\u5206\u79bb\uff0c\u65e0\u6cd5\u5728\u90e8\u7f72\u540e\u901a\u8fc7\u4ea4\u4e92\u8fdb\u884c\u9002\u5e94\u6027\u5b66\u4e60\u3002\u4e3a\u4e86\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5728\u4e0d\u66f4\u65b0\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\uff0c\u9700\u8981\u4e00\u4e2a\u5c06\u60c5\u666f\u8bb0\u5fc6\u4e0e\u5f3a\u5316\u5b66\u4e60\u6574\u5408\u7684\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u601d\u673a\u5236\u5b9e\u73b0\u7ecf\u9a8c\u79ef\u7d2f\u548c\u7b56\u7565\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86\u72b6\u6001\u53cd\u601d\u51b3\u7b56\u8fc7\u7a0b\uff08Stateful Reflective Decision Process\uff09\u6846\u67b6\uff0c\u5c06\u53cd\u601d\u5b66\u4e60\u5efa\u6a21\u4e3a\u4e0e\u60c5\u666f\u8bb0\u5fc6\u7684\u4e24\u9636\u6bb5\u8bfb\u5199\u4ea4\u4e92\uff1a\u5199\u5165\u9636\u6bb5\u5b58\u50a8\u4ea4\u4e92\u7ed3\u679c\u5bf9\u5e94\u7b56\u7565\u8bc4\u4f30\uff0c\u8bfb\u53d6\u9636\u6bb5\u68c0\u7d22\u76f8\u5173\u5386\u53f2\u6848\u4f8b\u5bf9\u5e94\u7b56\u7565\u6539\u8fdb\u3002\u8be5\u8fc7\u7a0b\u5728\u589e\u5f3a\u7684\u72b6\u6001-\u8bb0\u5fc6\u8868\u793a\u4e0a\u8bf1\u5bfc\u51fa\u7b49\u4ef7\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5141\u8bb8\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u548c\u5f3a\u5316\u5b66\u4e60\u7684\u7ecf\u5178\u5de5\u5177\u3002\u4f7f\u7528\u71b5\u6b63\u5219\u5316\u7b56\u7565\u8fed\u4ee3\u6765\u5b9e\u4f8b\u5316\u8be5\u6846\u67b6\u3002", "result": "\u5efa\u7acb\u4e86\u6536\u655b\u6027\u4fdd\u8bc1\uff1a\u968f\u7740\u60c5\u666f\u8bb0\u5fc6\u7684\u589e\u957f\u5e76\u5b9e\u73b0\u5bf9\u72b6\u6001\u7a7a\u95f4\u7684\u5145\u5206\u8986\u76d6\uff0c\u751f\u6210\u7684\u7b56\u7565\u4f1a\u6536\u655b\u5230\u6700\u4f18\u89e3\u3002\u8be5\u6846\u67b6\u4e3a\u57fa\u4e8e\u8bb0\u5fc6\u589e\u5f3a\u548c\u68c0\u7d22\u7684\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7\u53cd\u601d\u673a\u5236\u548c\u60c5\u666f\u8bb0\u5fc6\u7684\u6574\u5408\uff0c\u6253\u7834\u4e86\u8bad\u7ec3\u4e0e\u90e8\u7f72\u7684\u4f20\u7edf\u754c\u9650\u3002\u8be5\u6846\u67b6\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u901a\u8fc7\u4ea4\u4e92\u7ecf\u9a8c\u4e0d\u65ad\u6539\u8fdb\u7b56\u7565\uff0c\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u6216\u53c2\u6570\u66f4\u65b0\uff0c\u4e3a\u6784\u5efa\u80fd\u591f\u6301\u7eed\u9002\u5e94\u7684\u8bb0\u5fc6\u589e\u5f3a\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2512.22895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22895", "abs": "https://arxiv.org/abs/2512.22895", "authors": ["Xiaotian Ren", "Nuerxiati Abudurexiti", "Zhengyong Jiang", "Angelos Stefanidis", "Hongbin Liu", "Jionglong Su"], "title": "SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning", "comment": null, "summary": "Portfolio optimization in non-stationary markets is challenging due to regime shifts, dynamic correlations, and the limited interpretability of deep reinforcement learning (DRL) policies. We propose a Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning (SAMP-HDRL). The framework first applies dynamic asset grouping to partition the market into high-quality and ordinary subsets. An upper-level agent extracts global market signals, while lower-level agents perform intra-group allocation under mask constraints. A utility-based capital allocation mechanism integrates risky and risk-free assets, ensuring coherent coordination between global and local decisions. backtests across three market regimes (2019--2021) demonstrate that SAMP-HDRL consistently outperforms nine traditional baselines and nine DRL benchmarks under volatile and oscillating conditions. Compared with the strongest baseline, our method achieves at least 5\\% higher Return, 5\\% higher Sharpe ratio, 5\\% higher Sortino ratio, and 2\\% higher Omega ratio, with substantially larger gains observed in turbulent markets. Ablation studies confirm that upper--lower coordination, dynamic clustering, and capital allocation are indispensable to robustness. SHAP-based interpretability further reveals a complementary ``diversified + concentrated'' mechanism across agents, providing transparent insights into decision-making. Overall, SAMP-HDRL embeds structural market constraints directly into the DRL pipeline, offering improved adaptability, robustness, and interpretability in complex financial environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6295\u8d44\u7ec4\u5408\u7ba1\u7406\u6846\u67b6SAMP-HDRL,\u901a\u8fc7\u52a8\u6001\u8d44\u4ea7\u5206\u7ec4\u3001\u4e0a\u4e0b\u5c42\u667a\u80fd\u4f53\u534f\u8c03\u548c\u6548\u7528\u8d44\u672c\u914d\u7f6e\u673a\u5236,\u5728\u975e\u5e73\u7a33\u5e02\u573a\u4e2d\u5b9e\u73b0\u4e86\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u7684\u8868\u73b0,\u5e76\u901a\u8fc7SHAP\u65b9\u6cd5\u63d0\u5347\u4e86\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u975e\u5e73\u7a33\u5e02\u573a\u4e2d\u7684\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u9762\u4e34\u4e09\u5927\u6311\u6218:\u5e02\u573a\u72b6\u6001\u8f6c\u6362\u3001\u52a8\u6001\u76f8\u5173\u6027\u53d8\u5316,\u4ee5\u53ca\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7684\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u6ce2\u52a8\u548c\u9707\u8361\u5e02\u573a\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5065\u6027\u80fd,\u4e14\u7f3a\u4e4f\u900f\u660e\u7684\u51b3\u7b56\u673a\u5236\u3002", "method": "\u63d0\u51faSAMP-HDRL\u6846\u67b6,\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6:(1)\u52a8\u6001\u8d44\u4ea7\u5206\u7ec4,\u5c06\u5e02\u573a\u5212\u5206\u4e3a\u9ad8\u8d28\u91cf\u548c\u666e\u901a\u8d44\u4ea7\u5b50\u96c6;(2)\u5206\u5c42\u667a\u80fd\u4f53\u67b6\u6784,\u4e0a\u5c42\u667a\u80fd\u4f53\u63d0\u53d6\u5168\u5c40\u5e02\u573a\u4fe1\u53f7,\u4e0b\u5c42\u667a\u80fd\u4f53\u5728\u63a9\u7801\u7ea6\u675f\u4e0b\u6267\u884c\u7ec4\u5185\u8d44\u4ea7\u914d\u7f6e;(3)\u57fa\u4e8e\u6548\u7528\u7684\u8d44\u672c\u914d\u7f6e\u673a\u5236,\u6574\u5408\u98ce\u9669\u8d44\u4ea7\u548c\u65e0\u98ce\u9669\u8d44\u4ea7,\u786e\u4fdd\u5168\u5c40\u4e0e\u5c40\u90e8\u51b3\u7b56\u7684\u534f\u8c03\u4e00\u81f4\u3002", "result": "\u57282019-2021\u5e74\u4e09\u4e2a\u5e02\u573a\u72b6\u6001\u4e0b\u7684\u56de\u6d4b\u8868\u660e,SAMP-HDRL\u5728\u6ce2\u52a8\u548c\u9707\u8361\u6761\u4ef6\u4e0b\u6301\u7eed\u4f18\u4e8e9\u79cd\u4f20\u7edf\u57fa\u51c6\u548c9\u79cd\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u3002\u4e0e\u6700\u5f3a\u57fa\u51c6\u76f8\u6bd4,\u8be5\u65b9\u6cd5\u81f3\u5c11\u5b9e\u73b0\u4e865%\u66f4\u9ad8\u7684\u6536\u76ca\u7387\u30015%\u66f4\u9ad8\u7684\u590f\u666e\u6bd4\u7387\u30015%\u66f4\u9ad8\u7684\u7d22\u63d0\u8bfa\u6bd4\u7387\u548c2%\u66f4\u9ad8\u7684\u6b27\u7c73\u4f3d\u6bd4\u7387,\u5728\u52a8\u8361\u5e02\u573a\u4e2d\u4f18\u52bf\u66f4\u4e3a\u663e\u8457\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e0a\u4e0b\u5c42\u534f\u8c03\u3001\u52a8\u6001\u805a\u7c7b\u548c\u8d44\u672c\u914d\u7f6e\u5bf9\u9c81\u68d2\u6027\u4e0d\u53ef\u6216\u7f3a\u3002", "conclusion": "SAMP-HDRL\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u5e02\u573a\u7ea6\u675f\u76f4\u63a5\u5d4c\u5165\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6d41\u7a0b,\u5728\u590d\u6742\u91d1\u878d\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u9002\u5e94\u6027\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u57fa\u4e8eSHAP\u7684\u53ef\u89e3\u91ca\u6027\u5206\u6790\u63ed\u793a\u4e86\u667a\u80fd\u4f53\u95f4\"\u5206\u6563+\u96c6\u4e2d\"\u7684\u4e92\u8865\u673a\u5236,\u4e3a\u51b3\u7b56\u63d0\u4f9b\u4e86\u900f\u660e\u6d1e\u5bdf,\u4e3a\u975e\u5e73\u7a33\u5e02\u573a\u7684\u6295\u8d44\u7ec4\u5408\u7ba1\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.22899", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.22899", "abs": "https://arxiv.org/abs/2512.22899", "authors": ["Yaping Zhang", "Qixuan Zhang", "Xingquan Zhang", "Zhiyuan Chen", "Wenwen Zhuang", "Yupu Liang", "Lu Xiang", "Yang Zhao", "Jiajun Zhang", "Yu Zhou", "Chengqing Zong"], "title": "HiSciBench: A Hierarchical Multi-disciplinary Benchmark for Scientific Intelligence from Reading to Discovery", "comment": null, "summary": "The rapid advancement of large language models (LLMs) and multimodal foundation models has sparked growing interest in their potential for scientific research. However, scientific intelligence encompasses a broad spectrum of abilities ranging from understanding fundamental knowledge to conducting creative discovery, and existing benchmarks remain fragmented. Most focus on narrow tasks and fail to reflect the hierarchical and multi-disciplinary nature of real scientific inquiry. We introduce \\textbf{HiSciBench}, a hierarchical benchmark designed to evaluate foundation models across five levels that mirror the complete scientific workflow: \\textit{Scientific Literacy} (L1), \\textit{Literature Parsing} (L2), \\textit{Literature-based Question Answering} (L3), \\textit{Literature Review Generation} (L4), and \\textit{Scientific Discovery} (L5). HiSciBench contains 8,735 carefully curated instances spanning six major scientific disciplines, including mathematics, physics, chemistry, biology, geography, and astronomy, and supports multimodal inputs including text, equations, figures, and tables, as well as cross-lingual evaluation. Unlike prior benchmarks that assess isolated abilities, HiSciBench provides an integrated, dependency-aware framework that enables detailed diagnosis of model capabilities across different stages of scientific reasoning. Comprehensive evaluations of leading models, including GPT-5, DeepSeek-R1, and several multimodal systems, reveal substantial performance gaps: while models achieve up to 69\\% accuracy on basic literacy tasks, performance declines sharply to 25\\% on discovery-level challenges. HiSciBench establishes a new standard for evaluating scientific Intelligence and offers actionable insights for developing models that are not only more capable but also more reliable. The benchmark will be publicly released to facilitate future research.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86HiSciBench\uff0c\u4e00\u4e2a\u5206\u5c42\u6b21\u7684\u79d1\u5b66\u667a\u80fd\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b8,735\u4e2a\u5b9e\u4f8b\uff0c\u8986\u76d6\u516d\u5927\u5b66\u79d1\uff0c\u901a\u8fc7\u4e94\u4e2a\u5c42\u7ea7\uff08\u4ece\u79d1\u5b66\u7d20\u517b\u5230\u79d1\u5b66\u53d1\u73b0\uff09\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u80fd\u529b\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u57fa\u7840\u4efb\u52a1\u548c\u9ad8\u7ea7\u53d1\u73b0\u4efb\u52a1\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7684\u79d1\u5b66\u667a\u80fd\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u788e\u7247\u5316\u95ee\u9898\uff0c\u5927\u591a\u805a\u7126\u4e8e\u72ed\u7a84\u4efb\u52a1\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u79d1\u5b66\u7814\u7a76\u7684\u5c42\u6b21\u6027\u548c\u591a\u5b66\u79d1\u6027\u8d28\u3002\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u3001\u4f9d\u8d56\u611f\u77e5\u7684\u6846\u67b6\u6765\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u5728\u79d1\u5b66\u7814\u7a76\u5168\u6d41\u7a0b\u4e2d\u7684\u80fd\u529b\uff0c\u4ece\u57fa\u7840\u77e5\u8bc6\u7406\u89e3\u5230\u521b\u9020\u6027\u53d1\u73b0\u3002", "method": "\u6784\u5efa\u4e86HiSciBench\u5206\u5c42\u57fa\u51c6\uff0c\u5305\u542b\u4e94\u4e2a\u5c42\u7ea7\uff1aL1-\u79d1\u5b66\u7d20\u517b\u3001L2-\u6587\u732e\u89e3\u6790\u3001L3-\u57fa\u4e8e\u6587\u732e\u7684\u95ee\u7b54\u3001L4-\u6587\u732e\u7efc\u8ff0\u751f\u6210\u3001L5-\u79d1\u5b66\u53d1\u73b0\u3002\u57fa\u51c6\u5305\u542b8,735\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u5b9e\u4f8b\uff0c\u8986\u76d6\u6570\u5b66\u3001\u7269\u7406\u3001\u5316\u5b66\u3001\u751f\u7269\u3001\u5730\u7406\u548c\u5929\u6587\u516d\u5927\u5b66\u79d1\uff0c\u652f\u6301\u6587\u672c\u3001\u516c\u5f0f\u3001\u56fe\u8868\u7b49\u591a\u6a21\u6001\u8f93\u5165\u4ee5\u53ca\u8de8\u8bed\u8a00\u8bc4\u4f30\u3002\u91c7\u7528\u96c6\u6210\u7684\u3001\u4f9d\u8d56\u611f\u77e5\u7684\u6846\u67b6\u5bf9\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4e0d\u540c\u9636\u6bb5\u7684\u80fd\u529b\u8fdb\u884c\u8be6\u7ec6\u8bca\u65ad\u3002", "result": "\u5bf9\u5305\u62ecGPT-5\u3001DeepSeek-R1\u7b49\u9886\u5148\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff1a\u5728\u57fa\u7840\u7d20\u517b\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u53ef\u8fbe69%,\u4f46\u5728\u53d1\u73b0\u7ea7\u522b\u7684\u6311\u6218\u4e2d\u6027\u80fd\u6025\u5267\u4e0b\u964d\u81f325%\u3002\u8bc4\u4f30\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u79d1\u5b66\u7814\u7a76\u4e0d\u540c\u5c42\u7ea7\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u5206\u5e03\u548c\u5c40\u9650\u6027\u3002", "conclusion": "HiSciBench\u4e3a\u8bc4\u4f30\u79d1\u5b66\u667a\u80fd\u5efa\u7acb\u4e86\u65b0\u6807\u51c6,\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u3001\u5c42\u6b21\u5316\u7684\u8bc4\u4f30\u6846\u67b6,\u80fd\u591f\u7cfb\u7edf\u8bca\u65ad\u57fa\u7840\u6a21\u578b\u5728\u79d1\u5b66\u7814\u7a76\u5168\u6d41\u7a0b\u4e2d\u7684\u80fd\u529b\u3002\u8bc4\u4f30\u7ed3\u679c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u53ef\u9760\u7684\u79d1\u5b66AI\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002\u8be5\u57fa\u51c6\u5c06\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2512.22931", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22931", "abs": "https://arxiv.org/abs/2512.22931", "authors": ["Ling Xin", "Mojtaba Nayyeri", "Zahra Makki Nayeri", "Steffen Staab"], "title": "Geometric Structural Knowledge Graph Foundation Model", "comment": "Submitted to IEEE TPAMI, under review", "summary": "Structural knowledge graph foundation models aim to generalize reasoning to completely new graphs with unseen entities and relations. A key limitation of existing approaches like Ultra is their reliance on a single relational transformation (e.g., element-wise multiplication) in message passing, which can constrain expressiveness and fail to capture diverse relational and structural patterns exhibited on diverse graphs. In this paper, we propose Gamma, a novel foundation model that introduces multi-head geometric attention to knowledge graph reasoning. Gamma replaces the single relational transformation with multiple parallel ones, including real, complex, split-complex, and dual number based transformations, each designed to model different relational structures. A relational conditioned attention fusion mechanism then adaptively fuses them at link level via a lightweight gating with entropy regularization, allowing the model to robustly emphasize the most appropriate relational bias for each triple pattern. We present a full formalization of these algebraic message functions and discuss how their combination increases expressiveness beyond any single space. Comprehensive experiments on 56 diverse knowledge graphs demonstrate that Gamma consistently outperforms Ultra in zero-shot inductive link prediction, with a 5.5% improvement in mean reciprocal rank on the inductive benchmarks and a 4.4% improvement across all benchmarks, highlighting benefits from complementary geometric representations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGamma\u6a21\u578b,\u901a\u8fc7\u5f15\u5165\u591a\u5934\u51e0\u4f55\u6ce8\u610f\u529b\u673a\u5236\u6765\u589e\u5f3a\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u7684\u57fa\u7840\u6a21\u578b,\u4f7f\u7528\u591a\u79cd\u5e76\u884c\u7684\u5173\u7cfb\u53d8\u6362(\u5b9e\u6570\u3001\u590d\u6570\u3001\u5206\u88c2\u590d\u6570\u548c\u5bf9\u5076\u6570)\u66ff\u4ee3\u5355\u4e00\u53d8\u6362,\u5e76\u901a\u8fc7\u5173\u7cfb\u6761\u4ef6\u6ce8\u610f\u529b\u878d\u5408\u673a\u5236\u81ea\u9002\u5e94\u5730\u9009\u62e9\u6700\u5408\u9002\u7684\u5173\u7cfb\u504f\u7f6e,\u572856\u4e2a\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u96f6\u6837\u672c\u5f52\u7eb3\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5Ultra\u3002", "motivation": "\u73b0\u6709\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u6a21\u578b(\u5982Ultra)\u4f9d\u8d56\u5355\u4e00\u7684\u5173\u7cfb\u53d8\u6362(\u5982\u9010\u5143\u7d20\u4e58\u6cd5)\u8fdb\u884c\u6d88\u606f\u4f20\u9012,\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b,\u65e0\u6cd5\u6355\u6349\u4e0d\u540c\u56fe\u8c31\u4e2d\u5c55\u73b0\u7684\u591a\u6837\u5316\u5173\u7cfb\u548c\u7ed3\u6784\u6a21\u5f0f\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027,\u9700\u8981\u8bbe\u8ba1\u80fd\u591f\u5efa\u6a21\u4e0d\u540c\u5173\u7cfb\u7ed3\u6784\u7684\u591a\u6837\u5316\u51e0\u4f55\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faGamma\u6a21\u578b,\u6838\u5fc3\u521b\u65b0\u5305\u62ec:(1)\u5f15\u5165\u591a\u5934\u51e0\u4f55\u6ce8\u610f\u529b\u673a\u5236,\u4f7f\u7528\u591a\u4e2a\u5e76\u884c\u7684\u5173\u7cfb\u53d8\u6362\u66ff\u4ee3\u5355\u4e00\u53d8\u6362,\u5305\u62ec\u57fa\u4e8e\u5b9e\u6570\u3001\u590d\u6570\u3001\u5206\u88c2\u590d\u6570\u548c\u5bf9\u5076\u6570\u7684\u53d8\u6362,\u6bcf\u79cd\u53d8\u6362\u8bbe\u8ba1\u7528\u4e8e\u5efa\u6a21\u4e0d\u540c\u7684\u5173\u7cfb\u7ed3\u6784;(2)\u8bbe\u8ba1\u5173\u7cfb\u6761\u4ef6\u6ce8\u610f\u529b\u878d\u5408\u673a\u5236,\u901a\u8fc7\u5e26\u6709\u71b5\u6b63\u5219\u5316\u7684\u8f7b\u91cf\u7ea7\u95e8\u63a7\u5728\u94fe\u63a5\u7ea7\u522b\u81ea\u9002\u5e94\u878d\u5408\u8fd9\u4e9b\u53d8\u6362,\u4f7f\u6a21\u578b\u80fd\u591f\u4e3a\u6bcf\u4e2a\u4e09\u5143\u7ec4\u6a21\u5f0f\u9009\u62e9\u6700\u5408\u9002\u7684\u5173\u7cfb\u504f\u7f6e;(3)\u5bf9\u8fd9\u4e9b\u4ee3\u6570\u6d88\u606f\u51fd\u6570\u8fdb\u884c\u5b8c\u6574\u5f62\u5f0f\u5316,\u5e76\u8ba8\u8bba\u5b83\u4eec\u7684\u7ec4\u5408\u5982\u4f55\u63d0\u5347\u8868\u8fbe\u80fd\u529b\u8d85\u8d8a\u4efb\u4f55\u5355\u4e00\u7a7a\u95f4\u3002", "result": "\u572856\u4e2a\u4e0d\u540c\u7684\u77e5\u8bc6\u56fe\u8c31\u4e0a\u8fdb\u884c\u7684\u7efc\u5408\u5b9e\u9a8c\u8868\u660e,Gamma\u5728\u96f6\u6837\u672c\u5f52\u7eb3\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\u4e2d\u6301\u7eed\u4f18\u4e8eUltra\u6a21\u578b,\u5728\u5f52\u7eb3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u5012\u6570\u6392\u540d(MRR)\u63d0\u53475.5%,\u5728\u6240\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u63d0\u53474.4%,\u8bc1\u660e\u4e86\u4e92\u8865\u51e0\u4f55\u8868\u793a\u5e26\u6765\u7684\u4f18\u52bf\u3002", "conclusion": "Gamma\u6a21\u578b\u901a\u8fc7\u5f15\u5165\u591a\u5934\u51e0\u4f55\u6ce8\u610f\u529b\u548c\u591a\u6837\u5316\u7684\u4ee3\u6570\u53d8\u6362\u7a7a\u95f4,\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u53d7\u9650\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u4f7f\u7528\u591a\u79cd\u4e92\u8865\u51e0\u4f55\u8868\u793a\u548c\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u672a\u89c1\u5b9e\u4f53\u548c\u5173\u7cfb\u4e0a\u7684\u6cdb\u5316\u63a8\u7406\u80fd\u529b,\u4e3a\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2512.22933", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.22933", "abs": "https://arxiv.org/abs/2512.22933", "authors": ["Danni Xu", "Shaojing Fan", "Xuanang Cheng", "Mohan Kankanhalli"], "title": "Multimodal Fact-Checking: An Agent-based Approach", "comment": "Code and dataset will be released at https://github.com/xudanni0927/AgentFact", "summary": "The rapid spread of multimodal misinformation poses a growing challenge for automated fact-checking systems. Existing approaches, including large vision language models (LVLMs) and deep multimodal fusion methods, often fall short due to limited reasoning and shallow evidence utilization. A key bottleneck is the lack of dedicated datasets that provide complete real-world multimodal misinformation instances accompanied by annotated reasoning processes and verifiable evidence. To address this limitation, we introduce RW-Post, a high-quality and explainable dataset for real-world multimodal fact-checking. RW-Post aligns real-world multimodal claims with their original social media posts, preserving the rich contextual information in which the claims are made. In addition, the dataset includes detailed reasoning and explicitly linked evidence, which are derived from human written fact-checking articles via a large language model assisted extraction pipeline, enabling comprehensive verification and explanation. Building upon RW-Post, we propose AgentFact, an agent-based multimodal fact-checking framework designed to emulate the human verification workflow. AgentFact consists of five specialized agents that collaboratively handle key fact-checking subtasks, including strategy planning, high-quality evidence retrieval, visual analysis, reasoning, and explanation generation. These agents are orchestrated through an iterative workflow that alternates between evidence searching and task-aware evidence filtering and reasoning, facilitating strategic decision-making and systematic evidence analysis. Extensive experimental results demonstrate that the synergy between RW-Post and AgentFact substantially improves both the accuracy and interpretability of multimodal fact-checking.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u7684\u6311\u6218,\u63d0\u51fa\u4e86RW-Post\u6570\u636e\u96c6\u548cAgentFact\u6846\u67b6\u3002RW-Post\u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u771f\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u4e8b\u5b9e\u6838\u67e5\u6570\u636e\u96c6,\u5305\u542b\u5b8c\u6574\u7684\u63a8\u7406\u8fc7\u7a0b\u548c\u53ef\u9a8c\u8bc1\u8bc1\u636e;AgentFact\u662f\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u591a\u6a21\u6001\u4e8b\u5b9e\u6838\u67e5\u6846\u67b6,\u901a\u8fc7\u4e94\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u534f\u4f5c\u5b8c\u6210\u9a8c\u8bc1\u4efb\u52a1,\u663e\u8457\u63d0\u5347\u4e86\u4e8b\u5b9e\u6838\u67e5\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u65b9\u6cd5(\u5305\u62ec\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u6df1\u5ea6\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5)\u5b58\u5728\u63a8\u7406\u80fd\u529b\u6709\u9650\u548c\u8bc1\u636e\u5229\u7528\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u5173\u952e\u74f6\u9888\u5728\u4e8e\u7f3a\u4e4f\u4e13\u95e8\u7684\u6570\u636e\u96c6,\u8fd9\u4e9b\u6570\u636e\u96c6\u9700\u8981\u63d0\u4f9b\u5b8c\u6574\u7684\u771f\u5b9e\u4e16\u754c\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u5b9e\u4f8b,\u5e76\u914d\u6709\u6807\u6ce8\u7684\u63a8\u7406\u8fc7\u7a0b\u548c\u53ef\u9a8c\u8bc1\u7684\u8bc1\u636e\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u5feb\u901f\u4f20\u64ad\u7684\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u6838\u5fc3\u8d21\u732e:(1)RW-Post\u6570\u636e\u96c6:\u5c06\u771f\u5b9e\u4e16\u754c\u7684\u591a\u6a21\u6001\u58f0\u660e\u4e0e\u539f\u59cb\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u5bf9\u9f50,\u4fdd\u7559\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f,\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u63d0\u53d6\u7ba1\u9053\u4ece\u4eba\u5de5\u64b0\u5199\u7684\u4e8b\u5b9e\u6838\u67e5\u6587\u7ae0\u4e2d\u83b7\u53d6\u8be6\u7ec6\u63a8\u7406\u548c\u660e\u786e\u5173\u8054\u7684\u8bc1\u636e\u3002(2)AgentFact\u6846\u67b6:\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u591a\u6a21\u6001\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf,\u5305\u542b\u4e94\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53(\u7b56\u7565\u89c4\u5212\u3001\u9ad8\u8d28\u91cf\u8bc1\u636e\u68c0\u7d22\u3001\u89c6\u89c9\u5206\u6790\u3001\u63a8\u7406\u548c\u89e3\u91ca\u751f\u6210),\u901a\u8fc7\u8fed\u4ee3\u5de5\u4f5c\u6d41\u7a0b\u5728\u8bc1\u636e\u641c\u7d22\u548c\u4efb\u52a1\u611f\u77e5\u7684\u8bc1\u636e\u8fc7\u6ee4\u63a8\u7406\u4e4b\u95f4\u4ea4\u66ff,\u6a21\u62df\u4eba\u7c7b\u9a8c\u8bc1\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e,RW-Post\u6570\u636e\u96c6\u4e0eAgentFact\u6846\u67b6\u7684\u534f\u540c\u4f5c\u7528\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u4e8b\u5b9e\u6838\u67e5\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e13\u95e8\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u548c\u8fed\u4ee3\u5f0f\u8bc1\u636e\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b,\u5b9e\u73b0\u4e86\u6218\u7565\u51b3\u7b56\u548c\u7cfb\u7edf\u5316\u8bc1\u636e\u5206\u6790,\u6709\u6548\u6539\u5584\u4e86\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u9ad8\u8d28\u91cf\u7684RW-Post\u6570\u636e\u96c6\u548c\u8bbe\u8ba1AgentFact\u667a\u80fd\u4f53\u6846\u67b6,\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u4e8b\u5b9e\u6838\u67e5\u4e2d\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u548c\u8bc1\u636e\u5229\u7528\u6d45\u5c42\u7684\u95ee\u9898\u3002RW-Post\u63d0\u4f9b\u4e86\u5305\u542b\u5b8c\u6574\u63a8\u7406\u8fc7\u7a0b\u548c\u53ef\u9a8c\u8bc1\u8bc1\u636e\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e,AgentFact\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u9a8c\u8bc1\u6d41\u7a0b\u5b9e\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c,\u4e24\u8005\u7ed3\u5408\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027,\u4e3a\u5e94\u5bf9\u591a\u6a21\u6001\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.23036", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23036", "abs": "https://arxiv.org/abs/2512.23036", "authors": ["Danial Hooshyar", "Yeongwook Yang", "Gustav \u0160\u00ed\u0159", "Tommi K\u00e4rkk\u00e4inen", "Raija H\u00e4m\u00e4l\u00e4inen", "Mutlu Cukurova", "Roger Azevedo"], "title": "Problems With Large Language Models for Learner Modelling: Why LLMs Alone Fall Short for Responsible Tutoring in K--12 Education", "comment": null, "summary": "The rapid rise of large language model (LLM)-based tutors in K--12 education has fostered a misconception that generative models can replace traditional learner modelling for adaptive instruction. This is especially problematic in K--12 settings, which the EU AI Act classifies as high-risk domain requiring responsible design. Motivated by these concerns, this study synthesises evidence on limitations of LLM-based tutors and empirically investigates one critical issue: the accuracy, reliability, and temporal coherence of assessing learners' evolving knowledge over time. We compare a deep knowledge tracing (DKT) model with a widely used LLM, evaluated zero-shot and fine-tuned, using a large open-access dataset. Results show that DKT achieves the highest discrimination performance (AUC = 0.83) on next-step correctness prediction and consistently outperforms the LLM across settings. Although fine-tuning improves the LLM's AUC by approximately 8\\% over the zero-shot baseline, it remains 6\\% below DKT and produces higher early-sequence errors, where incorrect predictions are most harmful for adaptive support. Temporal analyses further reveal that DKT maintains stable, directionally correct mastery updates, whereas LLM variants exhibit substantial temporal weaknesses, including inconsistent and wrong-direction updates. These limitations persist despite the fine-tuned LLM requiring nearly 198 hours of high-compute training, far exceeding the computational demands of DKT. Our qualitative analysis of multi-skill mastery estimation further shows that, even after fine-tuning, the LLM produced inconsistent mastery trajectories, while DKT maintained smooth and coherent updates. Overall, the findings suggest that LLMs alone are unlikely to match the effectiveness of established intelligent tutoring systems, and that responsible tutoring requires hybrid frameworks that incorporate learner modelling.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u6bd4\u4e86\u6df1\u5ea6\u77e5\u8bc6\u8ffd\u8e2a(DKT)\u6a21\u578b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5728K-12\u6559\u80b2\u573a\u666f\u4e2d\u8bc4\u4f30\u5b66\u4e60\u8005\u77e5\u8bc6\u72b6\u6001\u7684\u80fd\u529b,\u53d1\u73b0DKT\u5728\u9884\u6d4b\u51c6\u786e\u6027\u3001\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8eLLM(\u5305\u62ec\u96f6\u6837\u672c\u548c\u5fae\u8c03\u7248\u672c),\u8868\u660e\u5355\u7eaf\u4f9d\u8d56LLM\u65e0\u6cd5\u66ff\u4ee3\u4f20\u7edf\u5b66\u4e60\u8005\u5efa\u6a21,\u9700\u8981\u6df7\u5408\u6846\u67b6\u6765\u5b9e\u73b0\u8d1f\u8d23\u4efb\u7684\u81ea\u9002\u5e94\u6559\u5b66\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u5bfc\u5e08\u7cfb\u7edf\u5728K-12\u6559\u80b2\u4e2d\u5feb\u901f\u5174\u8d77,\u51fa\u73b0\u4e86\u4e00\u79cd\u8bef\u89e3,\u8ba4\u4e3a\u751f\u6210\u5f0f\u6a21\u578b\u53ef\u4ee5\u66ff\u4ee3\u4f20\u7edf\u7684\u5b66\u4e60\u8005\u5efa\u6a21\u6765\u5b9e\u73b0\u81ea\u9002\u5e94\u6559\u5b66\u3002\u7531\u4e8eK-12\u6559\u80b2\u88ab\u6b27\u76dfAI\u6cd5\u6848\u5f52\u7c7b\u4e3a\u9ad8\u98ce\u9669\u9886\u57df,\u9700\u8981\u8d1f\u8d23\u4efb\u7684\u8bbe\u8ba1,\u56e0\u6b64\u6709\u5fc5\u8981\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30LLM\u5728\u51c6\u786e\u8bc4\u4f30\u5b66\u4e60\u8005\u968f\u65f6\u95f4\u6f14\u53d8\u7684\u77e5\u8bc6\u72b6\u6001\u65b9\u9762\u7684\u80fd\u529b\u3001\u53ef\u9760\u6027\u548c\u65f6\u95f4\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528\u5927\u89c4\u6a21\u5f00\u653e\u6570\u636e\u96c6,\u5bf9\u6bd4\u8bc4\u4f30\u6df1\u5ea6\u77e5\u8bc6\u8ffd\u8e2a(DKT)\u6a21\u578b\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684\u5927\u8bed\u8a00\u6a21\u578b(\u5305\u62ec\u96f6\u6837\u672c\u548c\u5fae\u8c03\u7248\u672c)\u5728\u5b66\u4e60\u8005\u77e5\u8bc6\u72b6\u6001\u8bc4\u4f30\u4e0a\u7684\u8868\u73b0\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec:\u4e0b\u4e00\u6b65\u6b63\u786e\u6027\u9884\u6d4b\u7684\u533a\u5206\u6027\u80fd(AUC)\u3001\u65e9\u671f\u5e8f\u5217\u9519\u8bef\u7387\u3001\u65f6\u95f4\u7a33\u5b9a\u6027\u3001\u638c\u63e1\u5ea6\u66f4\u65b0\u7684\u65b9\u5411\u6b63\u786e\u6027,\u4ee5\u53ca\u591a\u6280\u80fd\u638c\u63e1\u5ea6\u4f30\u8ba1\u7684\u4e00\u81f4\u6027\u3002\u540c\u65f6\u5bf9\u6bd4\u4e86\u4e0d\u540c\u65b9\u6cd5\u7684\u8ba1\u7b97\u6210\u672c\u3002", "result": "DKT\u6a21\u578b\u5728\u4e0b\u4e00\u6b65\u6b63\u786e\u6027\u9884\u6d4b\u4e0a\u8fbe\u5230\u6700\u9ad8\u7684AUC\u503c(0.83),\u5728\u6240\u6709\u8bbe\u7f6e\u4e2d\u5747\u4f18\u4e8eLLM\u3002\u867d\u7136\u5fae\u8c03\u4f7fLLM\u7684AUC\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u63d0\u9ad8\u7ea68%,\u4f46\u4ecd\u6bd4DKT\u4f4e6%,\u4e14\u5728\u65e9\u671f\u5e8f\u5217\u4e2d\u4ea7\u751f\u66f4\u9ad8\u7684\u9519\u8bef\u7387\u3002\u65f6\u95f4\u5206\u6790\u663e\u793aDKT\u4fdd\u6301\u7a33\u5b9a\u4e14\u65b9\u5411\u6b63\u786e\u7684\u638c\u63e1\u5ea6\u66f4\u65b0,\u800cLLM\u53d8\u4f53\u8868\u73b0\u51fa\u663e\u8457\u7684\u65f6\u95f4\u5f31\u70b9,\u5305\u62ec\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u65b9\u5411\u7684\u66f4\u65b0\u3002\u5c3d\u7ba1\u5fae\u8c03\u7684LLM\u9700\u8981\u8fd1198\u5c0f\u65f6\u7684\u9ad8\u8ba1\u7b97\u91cf\u8bad\u7ec3,\u8fdc\u8d85DKT\u7684\u8ba1\u7b97\u9700\u6c42,\u4f46\u8fd9\u4e9b\u5c40\u9650\u6027\u4f9d\u7136\u5b58\u5728\u3002\u5b9a\u6027\u5206\u6790\u8fdb\u4e00\u6b65\u8868\u660e,\u5373\u4f7f\u7ecf\u8fc7\u5fae\u8c03,LLM\u5728\u591a\u6280\u80fd\u638c\u63e1\u5ea6\u4f30\u8ba1\u4e2d\u4ecd\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u8f68\u8ff9,\u800cDKT\u4fdd\u6301\u5e73\u6ed1\u8fde\u8d2f\u7684\u66f4\u65b0\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e,\u5355\u72ec\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u592a\u53ef\u80fd\u8fbe\u5230\u6210\u719f\u667a\u80fd\u5bfc\u5e08\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002\u5728K-12\u7b49\u9ad8\u98ce\u9669\u6559\u80b2\u573a\u666f\u4e2d\u5b9e\u73b0\u8d1f\u8d23\u4efb\u7684\u81ea\u9002\u5e94\u6559\u5b66,\u9700\u8981\u7ed3\u5408\u5b66\u4e60\u8005\u5efa\u6a21\u7684\u6df7\u5408\u6846\u67b6,\u800c\u4e0d\u80fd\u4ec5\u4f9d\u8d56\u751f\u6210\u5f0fLLM\u3002\u4f20\u7edf\u7684\u77e5\u8bc6\u8ffd\u8e2a\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u65f6\u95f4\u4e00\u81f4\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4ecd\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.23090", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23090", "abs": "https://arxiv.org/abs/2512.23090", "authors": ["Armin Berger", "Manuela Bergau", "Helen Schneider", "Saad Ahmad", "Tom Anglim Lagones", "Gianluca Brugnara", "Martha Foltyn-Dumitru", "Kai Schlamp", "Philipp Vollmuth", "Rafet Sifa"], "title": "Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients", "comment": null, "summary": "Recent Reinforcement Learning (RL) advances for Large Language Models (LLMs) have improved reasoning tasks, yet their resource-constrained application to medical imaging remains underexplored. We introduce ChexReason, a vision-language model trained via R1-style methodology (SFT followed by GRPO) using only 2,000 SFT samples, 1,000 RL samples, and a single A100 GPU. Evaluations on CheXpert and NIH benchmarks reveal a fundamental tension: GRPO recovers in-distribution performance (23% improvement on CheXpert, macro-F1 = 0.346) but degrades cross-dataset transferability (19% drop on NIH). This mirrors high-resource models like NV-Reason-CXR-3B, suggesting the issue stems from the RL paradigm rather than scale. We identify a generalization paradox where the SFT checkpoint uniquely improves on NIH before optimization, indicating teacher-guided reasoning captures more institution-agnostic features. Furthermore, cross-model comparisons show structured reasoning scaffolds benefit general-purpose VLMs but offer minimal gain for medically pre-trained models. Consequently, curated supervised fine-tuning may outperform aggressive RL for clinical deployment requiring robustness across diverse populations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86ChexReason\uff0c\u4e00\u4e2a\u901a\u8fc7R1\u98ce\u683c\u65b9\u6cd5\u8bad\u7ec3\u7684\u533b\u5b66\u5f71\u50cf\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u533b\u5b66\u5f71\u50cf\u9886\u57df\u7684\u6cdb\u5316\u6096\u8bba\uff1aGRPO\u4f18\u5316\u867d\u80fd\u63d0\u5347\u5206\u5e03\u5185\u6027\u80fd\uff0c\u4f46\u4f1a\u635f\u5bb3\u8de8\u6570\u636e\u96c6\u8fc1\u79fb\u80fd\u529b\uff0c\u8fd9\u4e00\u95ee\u9898\u6e90\u4e8eRL\u8303\u5f0f\u672c\u8eab\u800c\u975e\u6a21\u578b\u89c4\u6a21\u3002\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u9700\u8981\u8de8\u4eba\u7fa4\u9c81\u68d2\u6027\u7684\u4e34\u5e8a\u90e8\u7f72\uff0c\u7cbe\u5fc3\u7b56\u5212\u7684\u76d1\u7763\u5fae\u8c03\u53ef\u80fd\u4f18\u4e8e\u6fc0\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u8d44\u6e90\u53d7\u9650\u7684\u533b\u5b66\u5f71\u50cf\u5e94\u7528\u4e2d\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u533b\u5b66\u5f71\u50cf\u6a21\u578b\u9700\u8981\u5728\u4e0d\u540c\u533b\u7597\u673a\u6784\u548c\u4eba\u7fa4\u4e2d\u4fdd\u6301\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76RL\u65b9\u6cd5\u5728\u8be5\u9886\u57df\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "method": "\u91c7\u7528R1\u98ce\u683c\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\u76d1\u7763\u5fae\u8c03(SFT)\u540e\u63a5GRPO\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u3002\u4f7f\u7528\u6781\u5c11\u91cf\u6570\u636e(2000\u4e2aSFT\u6837\u672c\u548c1000\u4e2aRL\u6837\u672c)\u548c\u5355\u4e2aA100 GPU\u8bad\u7ec3ChexReason\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u3002\u5728CheXpert\u548cNIH\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e0e\u9ad8\u8d44\u6e90\u6a21\u578b(\u5982NV-Reason-CXR-3B)\u8fdb\u884c\u8de8\u6a21\u578b\u6bd4\u8f83\uff0c\u5206\u6790\u7ed3\u6784\u5316\u63a8\u7406\u652f\u67b6\u5bf9\u4e0d\u540c\u7c7b\u578bVLM\u7684\u5f71\u54cd\u3002", "result": "GRPO\u5728\u5206\u5e03\u5185\u6570\u636e\u96c6CheXpert\u4e0a\u5b9e\u73b023%\u7684\u6027\u80fd\u63d0\u5347(macro-F1\u8fbe\u52300.346)\uff0c\u4f46\u5728\u8de8\u6570\u636e\u96c6NIH\u4e0a\u6027\u80fd\u4e0b\u964d19%\u3002\u8fd9\u79cd\u73b0\u8c61\u5728\u9ad8\u8d44\u6e90\u6a21\u578b\u4e2d\u540c\u6837\u5b58\u5728\uff0c\u8868\u660e\u95ee\u9898\u6e90\u4e8eRL\u8303\u5f0f\u800c\u975e\u89c4\u6a21\u3002\u53d1\u73b0\u6cdb\u5316\u6096\u8bba\uff1aSFT\u68c0\u67e5\u70b9\u5728\u4f18\u5316\u524d\u80fd\u5728NIH\u4e0a\u72ec\u7279\u5730\u63d0\u5347\u6027\u80fd\uff0c\u8bf4\u660e\u6559\u5e08\u5f15\u5bfc\u7684\u63a8\u7406\u6355\u83b7\u4e86\u66f4\u591a\u673a\u6784\u65e0\u5173\u7279\u5f81\u3002\u7ed3\u6784\u5316\u63a8\u7406\u652f\u67b6\u5bf9\u901a\u7528VLM\u6709\u76ca\uff0c\u4f46\u5bf9\u533b\u5b66\u9884\u8bad\u7ec3\u6a21\u578b\u589e\u76ca\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u533b\u5b66\u5f71\u50cf\u9886\u57df\u5b58\u5728\u6839\u672c\u6027\u5f20\u529b\uff1a\u867d\u80fd\u63d0\u5347\u5206\u5e03\u5185\u6027\u80fd\uff0c\u4f46\u4f1a\u635f\u5bb3\u8de8\u6570\u636e\u96c6\u8fc1\u79fb\u80fd\u529b\uff0c\u4e14\u8be5\u95ee\u9898\u6e90\u4e8eRL\u8303\u5f0f\u672c\u8eab\u800c\u975e\u6a21\u578b\u89c4\u6a21\u3002\u5bf9\u4e8e\u9700\u8981\u8de8\u4e0d\u540c\u4eba\u7fa4\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u4e34\u5e8a\u90e8\u7f72\u573a\u666f\uff0c\u7cbe\u5fc3\u7b56\u5212\u7684\u76d1\u7763\u5fae\u8c03\u53ef\u80fd\u6bd4\u6fc0\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u66f4\u6709\u6548\u3002\u8fd9\u4e3a\u533b\u5b66AI\u7684\u8bad\u7ec3\u7b56\u7565\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\uff0c\u5f3a\u8c03\u4e86\u6cdb\u5316\u80fd\u529b\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u5173\u952e\u6027\u3002"}}
{"id": "2512.23126", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23126", "abs": "https://arxiv.org/abs/2512.23126", "authors": ["Yu Li", "Tian Lan", "Zhengling Qi"], "title": "InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization", "comment": null, "summary": "Direct Preference Optimization (DPO) and its variants have become standard for aligning Large Language Models due to their simplicity and offline stability. However, we identify two fundamental limitations. First, the optimal policy depends on arbitrary modeling choices (scalarization function, reference policy), yielding behavior reflecting parameterization artifacts rather than true preferences. Second, treating response generation in isolation fails to leverage comparative information in pairwise data, leaving the model's capacity for intrinsic self-reflection untapped. To address it, we propose Intrinsic Self-reflective Preference Optimization (\\q), deriving a globally optimal policy conditioning on both context and alternative responses. We prove this formulation superior to DPO/RLHF while guaranteeing invariance to scalarization and reference choices. \\q~serves as a plug-and-play enhancement without architectural changes or inference overhead. Experiments demonstrate consistent improvements in win rates and length-controlled metrics, validating that unlocking self-reflection yields more robust, human-aligned LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5185\u5728\u81ea\u53cd\u601d\u504f\u597d\u4f18\u5316(Intrinsic Self-reflective Preference Optimization)\u65b9\u6cd5,\u901a\u8fc7\u8ba9\u6a21\u578b\u5728\u751f\u6210\u54cd\u5e94\u65f6\u540c\u65f6\u8003\u8651\u4e0a\u4e0b\u6587\u548c\u66ff\u4ee3\u54cd\u5e94,\u89e3\u51b3\u4e86DPO\u53ca\u5176\u53d8\u4f53\u4e2d\u5b58\u5728\u7684\u6700\u4f18\u7b56\u7565\u4f9d\u8d56\u4efb\u610f\u5efa\u6a21\u9009\u62e9\u548c\u672a\u5145\u5206\u5229\u7528\u6210\u5bf9\u6570\u636e\u6bd4\u8f83\u4fe1\u606f\u7684\u95ee\u9898,\u5728\u4fdd\u8bc1\u5bf9\u6807\u91cf\u5316\u548c\u53c2\u8003\u7b56\u7565\u9009\u62e9\u4e0d\u53d8\u6027\u7684\u540c\u65f6,\u5b9e\u73b0\u4e86\u4f18\u4e8eDPO/RLHF\u7684\u5168\u5c40\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u6027\u5c40\u9650:1)\u6700\u4f18\u7b56\u7565\u4f9d\u8d56\u4e8e\u4efb\u610f\u7684\u5efa\u6a21\u9009\u62e9(\u5982\u6807\u91cf\u5316\u51fd\u6570\u3001\u53c2\u8003\u7b56\u7565),\u5bfc\u81f4\u6a21\u578b\u884c\u4e3a\u53cd\u6620\u7684\u662f\u53c2\u6570\u5316\u7684\u4eba\u5de5\u75d5\u8ff9\u800c\u975e\u771f\u5b9e\u504f\u597d;2)\u5b64\u7acb\u5730\u5904\u7406\u54cd\u5e94\u751f\u6210,\u672a\u80fd\u5229\u7528\u6210\u5bf9\u6570\u636e\u4e2d\u7684\u6bd4\u8f83\u4fe1\u606f,\u4f7f\u6a21\u578b\u7684\u5185\u5728\u81ea\u53cd\u601d\u80fd\u529b\u672a\u88ab\u5145\u5206\u6316\u6398\u3002", "method": "\u63d0\u51fa\u5185\u5728\u81ea\u53cd\u601d\u504f\u597d\u4f18\u5316\u65b9\u6cd5,\u63a8\u5bfc\u51fa\u4e00\u4e2a\u5168\u5c40\u6700\u4f18\u7b56\u7565,\u8be5\u7b56\u7565\u540c\u65f6\u4ee5\u4e0a\u4e0b\u6587\u548c\u66ff\u4ee3\u54cd\u5e94\u4e3a\u6761\u4ef6\u8fdb\u884c\u5efa\u6a21\u3002\u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u4f18\u4e8eDPO/RLHF,\u540c\u65f6\u4fdd\u8bc1\u5bf9\u6807\u91cf\u5316\u51fd\u6570\u548c\u53c2\u8003\u7b56\u7565\u9009\u62e9\u7684\u4e0d\u53d8\u6027\u3002\u8be5\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u7684\u589e\u5f3a\u6a21\u5757,\u65e0\u9700\u67b6\u6784\u6539\u53d8\u6216\u589e\u52a0\u63a8\u7406\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u80dc\u7387\u548c\u957f\u5ea6\u63a7\u5236\u6307\u6807\u4e0a\u5747\u53d6\u5f97\u4e86\u4e00\u81f4\u6027\u7684\u6539\u8fdb,\u9a8c\u8bc1\u4e86\u89e3\u9501\u81ea\u53cd\u601d\u80fd\u529b\u80fd\u591f\u4ea7\u751f\u66f4\u9c81\u68d2\u3001\u66f4\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5185\u5728\u81ea\u53cd\u601d\u673a\u5236,\u4f7f\u6a21\u578b\u5728\u751f\u6210\u65f6\u540c\u65f6\u8003\u8651\u4e0a\u4e0b\u6587\u548c\u66ff\u4ee3\u54cd\u5e94,\u6210\u529f\u89e3\u51b3\u4e86DPO\u65b9\u6cd5\u7684\u56fa\u6709\u5c40\u9650\u6027,\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u7b56\u7565\u5b66\u4e60\u6548\u679c,\u4e14\u8be5\u65b9\u6cd5\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u7684\u4e0d\u53d8\u6027\u548c\u5b9e\u7528\u7684\u5373\u63d2\u5373\u7528\u7279\u6027,\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.23163", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23163", "abs": "https://arxiv.org/abs/2512.23163", "authors": ["Max Parks", "Kheli Atluru", "Meera Vinod", "Mike Kuniavsky", "Jud Brewer", "Sean White", "Sarah Adler", "Wendy Ju"], "title": "Why We Need a New Framework for Emotional Intelligence in AI", "comment": null, "summary": "In this paper, we develop the position that current frameworks for evaluating emotional intelligence (EI) in artificial intelligence (AI) systems need refinement because they do not adequately or comprehensively measure the various aspects of EI relevant in AI. Human EI often involves a phenomenological component and a sense of understanding that artificially intelligent systems lack; therefore, some aspects of EI are irrelevant in evaluating AI systems. However, EI also includes an ability to sense an emotional state, explain it, respond appropriately, and adapt to new contexts (e.g., multicultural), and artificially intelligent systems can do such things to greater or lesser degrees. Several benchmark frameworks specialize in evaluating the capacity of different AI models to perform some tasks related to EI, but these often lack a solid foundation regarding the nature of emotion and what it is to be emotionally intelligent. In this project, we begin by reviewing different theories about emotion and general EI, evaluating the extent to which each is applicable to artificial systems. We then critically evaluate the available benchmark frameworks, identifying where each falls short in light of the account of EI developed in the first section. Lastly, we outline some options for improving evaluation strategies to avoid these shortcomings in EI evaluation in AI systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u60c5\u7eea\u667a\u80fd(EI)\u8bc4\u4f30\u6846\u67b6\u7684\u4e0d\u8db3,\u6307\u51fa\u8fd9\u4e9b\u6846\u67b6\u672a\u80fd\u5168\u9762\u8861\u91cfAI\u76f8\u5173\u7684EI\u5404\u4e2a\u65b9\u9762\u3002\u6587\u7ae0\u56de\u987e\u4e86\u60c5\u7eea\u548cEI\u7406\u8bba,\u6279\u5224\u6027\u8bc4\u4f30\u4e86\u73b0\u6709\u57fa\u51c6\u6846\u67b6,\u5e76\u63d0\u51fa\u4e86\u6539\u8fdbAI\u7cfb\u7edfEI\u8bc4\u4f30\u7b56\u7565\u7684\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u5de5\u667a\u80fd\u60c5\u7eea\u667a\u80fd\u8bc4\u4f30\u6846\u67b6\u5b58\u5728\u7f3a\u9677,\u672a\u80fd\u5145\u5206\u6216\u5168\u9762\u5730\u8861\u91cfAI\u7cfb\u7edf\u4e2d\u76f8\u5173\u7684\u60c5\u7eea\u667a\u80fd\u5404\u4e2a\u65b9\u9762\u3002\u4eba\u7c7b\u60c5\u7eea\u667a\u80fd\u6d89\u53ca\u73b0\u8c61\u5b66\u6210\u5206\u548c\u7406\u89e3\u611f,\u800cAI\u7cfb\u7edf\u7f3a\u4e4f\u8fd9\u4e9b\u7279\u6027,\u56e0\u6b64\u67d0\u4e9bEI\u65b9\u9762\u5728\u8bc4\u4f30AI\u7cfb\u7edf\u65f6\u5e76\u4e0d\u76f8\u5173\u3002\u540c\u65f6,\u73b0\u6709\u57fa\u51c6\u6846\u67b6\u7f3a\u4e4f\u5173\u4e8e\u60c5\u7eea\u672c\u8d28\u548c\u60c5\u7eea\u667a\u80fd\u7684\u575a\u5b9e\u7406\u8bba\u57fa\u7840\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e09\u6b65\u65b9\u6cd5:(1)\u56de\u987e\u4e0d\u540c\u7684\u60c5\u7eea\u7406\u8bba\u548c\u4e00\u822c\u60c5\u7eea\u667a\u80fd\u7406\u8bba,\u8bc4\u4f30\u6bcf\u79cd\u7406\u8bba\u5bf9\u4eba\u5de5\u7cfb\u7edf\u7684\u9002\u7528\u7a0b\u5ea6;(2)\u6279\u5224\u6027\u8bc4\u4f30\u73b0\u6709\u7684\u57fa\u51c6\u8bc4\u4f30\u6846\u67b6,\u6839\u636e\u7b2c\u4e00\u90e8\u5206\u5efa\u7acb\u7684EI\u7406\u8bba\u8bc6\u522b\u5404\u6846\u67b6\u7684\u4e0d\u8db3\u4e4b\u5904;(3)\u6982\u8ff0\u6539\u8fdb\u8bc4\u4f30\u7b56\u7565\u7684\u82e5\u5e72\u9009\u9879,\u4ee5\u907f\u514dAI\u7cfb\u7edfEI\u8bc4\u4f30\u4e2d\u7684\u8fd9\u4e9b\u7f3a\u9677\u3002", "result": "\u7814\u7a76\u53d1\u73b0,AI\u7cfb\u7edf\u867d\u7136\u7f3a\u4e4f\u4eba\u7c7b\u60c5\u7eea\u667a\u80fd\u7684\u73b0\u8c61\u5b66\u6210\u5206,\u4f46\u80fd\u591f\u5728\u4e0d\u540c\u7a0b\u5ea6\u4e0a\u611f\u77e5\u60c5\u7eea\u72b6\u6001\u3001\u89e3\u91ca\u60c5\u7eea\u3001\u505a\u51fa\u9002\u5f53\u54cd\u5e94\u5e76\u9002\u5e94\u65b0\u60c5\u5883(\u5982\u591a\u6587\u5316\u73af\u5883)\u3002\u73b0\u6709\u7684\u4e13\u95e8\u8bc4\u4f30AI\u6a21\u578b\u6267\u884cEI\u76f8\u5173\u4efb\u52a1\u80fd\u529b\u7684\u57fa\u51c6\u6846\u67b6,\u5728\u60c5\u7eea\u672c\u8d28\u548c\u60c5\u7eea\u667a\u80fd\u7684\u7406\u8bba\u57fa\u7840\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u9700\u8981\u6539\u8fdbAI\u7cfb\u7edf\u7684\u60c5\u7eea\u667a\u80fd\u8bc4\u4f30\u7b56\u7565,\u5efa\u8bae\u57fa\u4e8e\u5bf9\u60c5\u7eea\u548cEI\u7406\u8bba\u7684\u6df1\u5165\u7406\u89e3\u6765\u91cd\u65b0\u8bbe\u8ba1\u8bc4\u4f30\u6846\u67b6\u3002\u8bc4\u4f30\u5e94\u533a\u5206\u4eba\u7c7bEI\u4e2d\u4e0d\u9002\u7528\u4e8eAI\u7684\u73b0\u8c61\u5b66\u6210\u5206,\u540c\u65f6\u5173\u6ce8AI\u7cfb\u7edf\u5728\u60c5\u7eea\u611f\u77e5\u3001\u89e3\u91ca\u3001\u54cd\u5e94\u548c\u60c5\u5883\u9002\u5e94\u7b49\u65b9\u9762\u7684\u5b9e\u9645\u80fd\u529b,\u4ece\u800c\u5efa\u7acb\u66f4\u52a0\u79d1\u5b66\u548c\u5168\u9762\u7684AI\u60c5\u7eea\u667a\u80fd\u8bc4\u4f30\u4f53\u7cfb\u3002"}}
{"id": "2512.23184", "categories": ["cs.AI", "econ.EM"], "pdf": "https://arxiv.org/pdf/2512.23184", "abs": "https://arxiv.org/abs/2512.23184", "authors": ["Hongshen Sun", "Juanjuan Zhang"], "title": "From Model Choice to Model Belief: Establishing a New Measure for LLM-Based Research", "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate human behavior, but common practices to use LLM-generated data are inefficient. Treating an LLM's output (\"model choice\") as a single data point underutilizes the information inherent to the probabilistic nature of LLMs. This paper introduces and formalizes \"model belief,\" a measure derived from an LLM's token-level probabilities that captures the model's belief distribution over choice alternatives in a single generation run. The authors prove that model belief is asymptotically equivalent to the mean of model choices (a non-trivial property) but forms a more statistically efficient estimator, with lower variance and a faster convergence rate. Analogous properties are shown to hold for smooth functions of model belief and model choice often used in downstream applications. The authors demonstrate the performance of model belief through a demand estimation study, where an LLM simulates consumer responses to different prices. In practical settings with limited numbers of runs, model belief explains and predicts ground-truth model choice better than model choice itself, and reduces the computation needed to reach sufficiently accurate estimates by roughly a factor of 20. The findings support using model belief as the default measure to extract more information from LLM-generated data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\"\u6a21\u578b\u4fe1\u5ff5\"(model belief)\u6982\u5ff5,\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684token\u7ea7\u6982\u7387\u5206\u5e03\u6765\u66f4\u9ad8\u6548\u5730\u63d0\u53d6LLM\u751f\u6210\u6570\u636e\u4e2d\u7684\u4fe1\u606f\u3002\u76f8\u6bd4\u4f20\u7edf\u7684\"\u6a21\u578b\u9009\u62e9\"\u65b9\u6cd5,\u6a21\u578b\u4fe1\u5ff5\u5177\u6709\u66f4\u4f4e\u7684\u65b9\u5dee\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6,\u5728\u9700\u6c42\u4f30\u8ba1\u7814\u7a76\u4e2d\u5c06\u8ba1\u7b97\u9700\u6c42\u51cf\u5c11\u7ea620\u500d\u3002", "motivation": "\u5f53\u524d\u4f7f\u7528LLM\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u65f6,\u5e38\u89c1\u505a\u6cd5\u662f\u5c06LLM\u7684\u8f93\u51fa\u4f5c\u4e3a\u5355\u4e00\u6570\u636e\u70b9,\u8fd9\u79cd\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b,\u672a\u80fd\u5145\u5206\u5229\u7528LLM\u6982\u7387\u6027\u8d28\u4e2d\u56fa\u6709\u7684\u4fe1\u606f\u3002\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u4eceLLM\u751f\u6210\u7684\u6570\u636e\u4e2d\u63d0\u53d6\u66f4\u591a\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u5e76\u5f62\u5f0f\u5316\"\u6a21\u578b\u4fe1\u5ff5\"\u6982\u5ff5,\u8fd9\u662f\u4e00\u79cd\u4eceLLM\u7684token\u7ea7\u6982\u7387\u4e2d\u63d0\u53d6\u7684\u5ea6\u91cf,\u80fd\u591f\u5728\u5355\u6b21\u751f\u6210\u8fd0\u884c\u4e2d\u6355\u83b7\u6a21\u578b\u5728\u9009\u62e9\u5907\u9009\u9879\u4e0a\u7684\u4fe1\u5ff5\u5206\u5e03\u3002\u4f5c\u8005\u8bc1\u660e\u4e86\u6a21\u578b\u4fe1\u5ff5\u5728\u6e10\u8fd1\u610f\u4e49\u4e0a\u7b49\u4ef7\u4e8e\u6a21\u578b\u9009\u62e9\u7684\u5747\u503c,\u4f46\u5f62\u6210\u4e86\u66f4\u5177\u7edf\u8ba1\u6548\u7387\u7684\u4f30\u8ba1\u5668,\u5177\u6709\u66f4\u4f4e\u7684\u65b9\u5dee\u548c\u66f4\u5feb\u7684\u6536\u655b\u7387\u3002", "result": "\u901a\u8fc7\u9700\u6c42\u4f30\u8ba1\u7814\u7a76\u9a8c\u8bc1\u4e86\u6a21\u578b\u4fe1\u5ff5\u7684\u6027\u80fd,\u5176\u4e2dLLM\u6a21\u62df\u6d88\u8d39\u8005\u5bf9\u4e0d\u540c\u4ef7\u683c\u7684\u54cd\u5e94\u3002\u5728\u5b9e\u9645\u6709\u9650\u8fd0\u884c\u6b21\u6570\u7684\u8bbe\u7f6e\u4e2d,\u6a21\u578b\u4fe1\u5ff5\u6bd4\u6a21\u578b\u9009\u62e9\u672c\u8eab\u66f4\u597d\u5730\u89e3\u91ca\u548c\u9884\u6d4b\u771f\u5b9e\u7684\u6a21\u578b\u9009\u62e9,\u5e76\u5c06\u8fbe\u5230\u8db3\u591f\u51c6\u786e\u4f30\u8ba1\u6240\u9700\u7684\u8ba1\u7b97\u91cf\u51cf\u5c11\u4e86\u7ea620\u500d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u652f\u6301\u5c06\u6a21\u578b\u4fe1\u5ff5\u4f5c\u4e3a\u4eceLLM\u751f\u6210\u6570\u636e\u4e2d\u63d0\u53d6\u66f4\u591a\u4fe1\u606f\u7684\u9ed8\u8ba4\u5ea6\u91cf\u65b9\u6cd5\u3002\u6a21\u578b\u4fe1\u5ff5\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u5177\u6709\u6e10\u8fd1\u7b49\u4ef7\u6027\u548c\u66f4\u4f18\u7684\u7edf\u8ba1\u6548\u7387,\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4e5f\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2512.23217", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23217", "abs": "https://arxiv.org/abs/2512.23217", "authors": ["Jingming Li"], "title": "TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI", "comment": null, "summary": "A critical gap exists in LLM task-specific benchmarks. Thermal comfort, a sophisticated interplay of environmental factors and personal perceptions involving sensory integration and adaptive decision-making, serves as an ideal paradigm for evaluating real-world cognitive capabilities of AI systems. To address this, we propose TCEval, the first evaluation framework that assesses three core cognitive capacities of AI, cross-modal reasoning, causal association, and adaptive decision-making, by leveraging thermal comfort scenarios and large language model (LLM) agents. The methodology involves initializing LLM agents with virtual personality attributes, guiding them to generate clothing insulation selections and thermal comfort feedback, and validating outputs against the ASHRAE Global Database and Chinese Thermal Comfort Database. Experiments on four LLMs show that while agent feedback has limited exact alignment with humans, directional consistency improves significantly with a 1 PMV tolerance. Statistical tests reveal that LLM-generated PMV distributions diverge markedly from human data, and agents perform near-randomly in discrete thermal comfort classification. These results confirm the feasibility of TCEval as an ecologically valid Cognitive Turing Test for AI, demonstrating that current LLMs possess foundational cross-modal reasoning ability but lack precise causal understanding of the nonlinear relationships between variables in thermal comfort. TCEval complements traditional benchmarks, shifting AI evaluation focus from abstract task proficiency to embodied, context-aware perception and decision-making, offering valuable insights for advancing AI in human-centric applications like smart buildings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTCEval,\u4e00\u4e2a\u57fa\u4e8e\u70ed\u8212\u9002\u573a\u666f\u7684LLM\u8bc4\u4f30\u6846\u67b6,\u901a\u8fc7\u8bc4\u4f30\u8de8\u6a21\u6001\u63a8\u7406\u3001\u56e0\u679c\u5173\u8054\u548c\u81ea\u9002\u5e94\u51b3\u7b56\u4e09\u5927\u8ba4\u77e5\u80fd\u529b,\u53d1\u73b0\u5f53\u524dLLM\u5177\u5907\u57fa\u7840\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\u4f46\u7f3a\u4e4f\u5bf9\u70ed\u8212\u9002\u53d8\u91cf\u95f4\u975e\u7ebf\u6027\u5173\u7cfb\u7684\u7cbe\u786e\u56e0\u679c\u7406\u89e3\u3002", "motivation": "\u73b0\u6709LLM\u4efb\u52a1\u7279\u5b9a\u57fa\u51c6\u5b58\u5728\u5173\u952e\u7f3a\u53e3,\u7f3a\u4e4f\u5bf9AI\u7cfb\u7edf\u771f\u5b9e\u4e16\u754c\u8ba4\u77e5\u80fd\u529b\u7684\u8bc4\u4f30\u3002\u70ed\u8212\u9002\u6d89\u53ca\u73af\u5883\u56e0\u7d20\u4e0e\u4e2a\u4eba\u611f\u77e5\u7684\u590d\u6742\u4ea4\u4e92,\u5305\u542b\u611f\u5b98\u6574\u5408\u548c\u81ea\u9002\u5e94\u51b3\u7b56,\u662f\u8bc4\u4f30AI\u8ba4\u77e5\u80fd\u529b\u7684\u7406\u60f3\u8303\u5f0f\u3002\u9700\u8981\u5c06AI\u8bc4\u4f30\u4ece\u62bd\u8c61\u4efb\u52a1\u80fd\u529b\u8f6c\u5411\u5177\u8eab\u5316\u3001\u60c5\u5883\u611f\u77e5\u7684\u611f\u77e5\u548c\u51b3\u7b56\u80fd\u529b\u8bc4\u4f30\u3002", "method": "\u63d0\u51faTCEval\u8bc4\u4f30\u6846\u67b6,\u901a\u8fc7\u70ed\u8212\u9002\u573a\u666f\u8bc4\u4f30LLM\u7684\u4e09\u5927\u6838\u5fc3\u8ba4\u77e5\u80fd\u529b(\u8de8\u6a21\u6001\u63a8\u7406\u3001\u56e0\u679c\u5173\u8054\u3001\u81ea\u9002\u5e94\u51b3\u7b56)\u3002\u65b9\u6cd5\u5305\u62ec:\u4e3aLLM\u667a\u80fd\u4f53\u521d\u59cb\u5316\u865a\u62df\u4eba\u683c\u5c5e\u6027,\u5f15\u5bfc\u5176\u751f\u6210\u670d\u88c5\u9694\u70ed\u9009\u62e9\u548c\u70ed\u8212\u9002\u53cd\u9988,\u5e76\u4f7f\u7528ASHRAE\u5168\u7403\u6570\u636e\u5e93\u548c\u4e2d\u56fd\u70ed\u8212\u9002\u6570\u636e\u5e93\u9a8c\u8bc1\u8f93\u51fa\u3002\u5bf9\u56db\u4e2aLLM\u8fdb\u884c\u5b9e\u9a8c\u6d4b\u8bd5\u5e76\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u667a\u80fd\u4f53\u53cd\u9988\u4e0e\u4eba\u7c7b\u7684\u7cbe\u786e\u5bf9\u9f50\u6709\u9650,\u4f46\u57281 PMV\u5bb9\u5dee\u4e0b\u65b9\u5411\u4e00\u81f4\u6027\u663e\u8457\u63d0\u9ad8\u3002\u7edf\u8ba1\u68c0\u9a8c\u8868\u660eLLM\u751f\u6210\u7684PMV\u5206\u5e03\u4e0e\u4eba\u7c7b\u6570\u636e\u663e\u8457\u504f\u79bb,\u667a\u80fd\u4f53\u5728\u79bb\u6563\u70ed\u8212\u9002\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\u3002\u7ed3\u679c\u8bc1\u5b9e\u5f53\u524dLLM\u5177\u5907\u57fa\u7840\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b,\u4f46\u7f3a\u4e4f\u5bf9\u70ed\u8212\u9002\u53d8\u91cf\u95f4\u975e\u7ebf\u6027\u5173\u7cfb\u7684\u7cbe\u786e\u56e0\u679c\u7406\u89e3\u3002", "conclusion": "TCEval\u4f5c\u4e3a\u751f\u6001\u6709\u6548\u7684\u8ba4\u77e5\u56fe\u7075\u6d4b\u8bd5\u5177\u6709\u53ef\u884c\u6027,\u80fd\u591f\u8bc4\u4f30AI\u7684\u771f\u5b9e\u8ba4\u77e5\u80fd\u529b\u3002\u8be5\u6846\u67b6\u8865\u5145\u4e86\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5,\u5c06AI\u8bc4\u4f30\u91cd\u70b9\u4ece\u62bd\u8c61\u4efb\u52a1\u719f\u7ec3\u5ea6\u8f6c\u5411\u5177\u8eab\u5316\u3001\u60c5\u5883\u611f\u77e5\u7684\u611f\u77e5\u548c\u51b3\u7b56\u80fd\u529b,\u4e3a\u63a8\u8fdb\u667a\u80fd\u5efa\u7b51\u7b49\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684AI\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2512.23324", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.23324", "abs": "https://arxiv.org/abs/2512.23324", "authors": ["Raven Beutner", "Bernd Finkbeiner"], "title": "On Conformant Planning and Model-Checking of $\\exists^*\\forall^*$ Hyperproperties", "comment": "ECAI 2025", "summary": "We study the connection of two problems within the planning and verification community: Conformant planning and model-checking of hyperproperties. Conformant planning is the task of finding a sequential plan that achieves a given objective independent of non-deterministic action effects during the plan's execution. Hyperproperties are system properties that relate multiple execution traces of a system and, e.g., capture information-flow and fairness policies. In this paper, we show that model-checking of $\\exists^*\\forall^*$ hyperproperties is closely related to the problem of computing a conformant plan. Firstly, we show that we can efficiently reduce a hyperproperty model-checking instance to a conformant planning instance, and prove that our encoding is sound and complete. Secondly, we establish the converse direction: Every conformant planning problem is, itself, a hyperproperty model-checking task.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u81f4\u6027\u89c4\u5212(Conformant Planning)\u4e0e\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c(Hyperproperty Model-Checking)\u4e4b\u95f4\u7684\u8054\u7cfb,\u8bc1\u660e\u4e86\u2203*\u2200*\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u95ee\u9898\u53ef\u4ee5\u9ad8\u6548\u5f52\u7ea6\u4e3a\u4e00\u81f4\u6027\u89c4\u5212\u95ee\u9898,\u5e76\u4e14\u53cd\u5411\u8bc1\u660e\u4e86\u6bcf\u4e2a\u4e00\u81f4\u6027\u89c4\u5212\u95ee\u9898\u672c\u8eab\u4e5f\u662f\u4e00\u4e2a\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u4efb\u52a1,\u5efa\u7acb\u4e86\u4e24\u4e2a\u95ee\u9898\u4e4b\u95f4\u7684\u53cc\u5411\u7b49\u4ef7\u5173\u7cfb\u3002", "motivation": "\u89c4\u5212\u4e0e\u9a8c\u8bc1\u793e\u533a\u4e2d\u5b58\u5728\u4e24\u4e2a\u91cd\u8981\u95ee\u9898:\u4e00\u81f4\u6027\u89c4\u5212\u548c\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u3002\u4e00\u81f4\u6027\u89c4\u5212\u9700\u8981\u627e\u5230\u4e00\u4e2a\u987a\u5e8f\u8ba1\u5212,\u4f7f\u5176\u5728\u6267\u884c\u8fc7\u7a0b\u4e2d\u4e0d\u53d7\u975e\u786e\u5b9a\u6027\u52a8\u4f5c\u5f71\u54cd\u800c\u8fbe\u6210\u76ee\u6807;\u8d85\u6027\u8d28\u5219\u5173\u8054\u7cfb\u7edf\u7684\u591a\u6761\u6267\u884c\u8f68\u8ff9,\u53ef\u4ee5\u6355\u83b7\u4fe1\u606f\u6d41\u548c\u516c\u5e73\u6027\u7b56\u7565\u3002\u7814\u7a76\u8fd9\u4e24\u4e2a\u95ee\u9898\u4e4b\u95f4\u7684\u8054\u7cfb\u6709\u52a9\u4e8e\u7406\u89e3\u5b83\u4eec\u7684\u672c\u8d28\u5173\u7cfb,\u5e76\u53ef\u80fd\u4e3a\u89e3\u51b3\u8fd9\u4e24\u7c7b\u95ee\u9898\u63d0\u4f9b\u65b0\u7684\u601d\u8def\u548c\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u91c7\u7528\u53cc\u5411\u5f52\u7ea6\u7684\u65b9\u6cd5\u5efa\u7acb\u4e24\u4e2a\u95ee\u9898\u4e4b\u95f4\u7684\u8054\u7cfb\u3002\u9996\u5148,\u5c06\u2203*\u2200*\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u5b9e\u4f8b\u9ad8\u6548\u5f52\u7ea6\u4e3a\u4e00\u81f4\u6027\u89c4\u5212\u5b9e\u4f8b,\u5e76\u8bc1\u660e\u8be5\u7f16\u7801\u7684\u6b63\u786e\u6027\u548c\u5b8c\u5907\u6027\u3002\u5176\u6b21,\u5efa\u7acb\u53cd\u5411\u5173\u7cfb,\u8bc1\u660e\u6bcf\u4e2a\u4e00\u81f4\u6027\u89c4\u5212\u95ee\u9898\u672c\u8eab\u5c31\u662f\u4e00\u4e2a\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u4efb\u52a1\u3002\u901a\u8fc7\u8fd9\u79cd\u53cc\u5411\u5f52\u7ea6,\u63ed\u793a\u4e86\u4e24\u4e2a\u95ee\u9898\u5728\u8ba1\u7b97\u590d\u6742\u6027\u548c\u95ee\u9898\u672c\u8d28\u4e0a\u7684\u7b49\u4ef7\u6027\u3002", "result": "\u7814\u7a76\u6210\u529f\u5efa\u7acb\u4e86\u2203*\u2200*\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u4e0e\u4e00\u81f4\u6027\u89c4\u5212\u4e4b\u95f4\u7684\u53cc\u5411\u7b49\u4ef7\u5173\u7cfb\u3002\u8bc1\u660e\u4e86\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u5b9e\u4f8b\u53ef\u4ee5\u9ad8\u6548\u5f52\u7ea6\u4e3a\u4e00\u81f4\u6027\u89c4\u5212\u5b9e\u4f8b,\u8be5\u5f52\u7ea6\u662f\u6b63\u786e\u4e14\u5b8c\u5907\u7684\u3002\u540c\u65f6\u8bc1\u660e\u4e86\u53cd\u5411\u5173\u7cfb:\u6bcf\u4e2a\u4e00\u81f4\u6027\u89c4\u5212\u95ee\u9898\u90fd\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u4efb\u52a1\u3002\u8fd9\u4e00\u7ed3\u679c\u63ed\u793a\u4e86\u4e24\u4e2a\u770b\u4f3c\u4e0d\u540c\u9886\u57df\u95ee\u9898\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86\u4e00\u81f4\u6027\u89c4\u5212\u4e0e\u2203*\u2200*\u8d85\u6027\u8d28\u6a21\u578b\u68c0\u9a8c\u4e4b\u95f4\u7684\u7406\u8bba\u7b49\u4ef7\u5173\u7cfb,\u8bc1\u660e\u4e86\u8fd9\u4e24\u4e2a\u95ee\u9898\u5728\u672c\u8d28\u4e0a\u662f\u76f8\u4e92\u5173\u8054\u7684\u3002\u8fd9\u4e00\u53d1\u73b0\u4e0d\u4ec5\u6df1\u5316\u4e86\u5bf9\u8fd9\u4e24\u7c7b\u95ee\u9898\u7684\u7406\u8bba\u8ba4\u8bc6,\u4e5f\u4e3a\u8de8\u9886\u57df\u5e94\u7528\u89c4\u5212\u6280\u672f\u89e3\u51b3\u6a21\u578b\u68c0\u9a8c\u95ee\u9898(\u6216\u53cd\u4e4b)\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840,\u6709\u671b\u4fc3\u8fdb\u89c4\u5212\u548c\u9a8c\u8bc1\u793e\u533a\u4e4b\u95f4\u7684\u6280\u672f\u4ea4\u6d41\u4e0e\u65b9\u6cd5\u8fc1\u79fb\u3002"}}
{"id": "2512.23328", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.23328", "abs": "https://arxiv.org/abs/2512.23328", "authors": ["Huan-ang Gao", "Zikang Zhang", "Tianwei Luo", "Kaisen Yang", "Xinzhe Juan", "Jiahao Qiu", "Tianxing Chen", "Bingxiang He", "Hao Zhao", "Hao Zhou", "Shilong Liu", "Mengdi Wang"], "title": "CubeBench: Diagnosing Interactive, Long-Horizon Spatial Reasoning Under Partial Observations", "comment": "Webpage: https://cubebench.c7w.tech/", "summary": "Large Language Model (LLM) agents, while proficient in the digital realm, face a significant gap in physical-world deployment due to the challenge of forming and maintaining a robust spatial mental model. We identify three core cognitive challenges hindering this transition: spatial reasoning, long-horizon state tracking via mental simulation, and active exploration under partial observation. To isolate and evaluate these faculties, we introduce CubeBench, a novel generative benchmark centered on the Rubik's Cube. CubeBench uses a three-tiered diagnostic framework that progressively assesses agent capabilities, from foundational state tracking with full symbolic information to active exploration with only partial visual data. Our experiments on leading LLMs reveal critical limitations, including a uniform 0.00% pass rate on all long-horizon tasks, exposing a fundamental failure in long-term planning. We also propose a diagnostic framework to isolate these cognitive bottlenecks by providing external solver tools. By analyzing the failure modes, we provide key insights to guide the development of more physically-grounded intelligent agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCubeBench\u57fa\u51c6\u6d4b\u8bd5,\u901a\u8fc7\u9b54\u65b9\u4efb\u52a1\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u7269\u7406\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u7a7a\u95f4\u8ba4\u77e5\u80fd\u529b,\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u957f\u671f\u89c4\u5212\u65b9\u9762\u7684\u6839\u672c\u6027\u7f3a\u9677(\u957f\u671f\u4efb\u52a1\u901a\u8fc7\u7387\u4e3a0%),\u5e76\u63d0\u4f9b\u4e86\u8bca\u65ad\u6846\u67b6\u4ee5\u6307\u5bfc\u5f00\u53d1\u66f4\u5177\u7269\u7406\u57fa\u7840\u7684\u667a\u80fd\u4f53\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u867d\u7136\u5728\u6570\u5b57\u9886\u57df\u8868\u73b0\u51fa\u8272,\u4f46\u5728\u7269\u7406\u4e16\u754c\u90e8\u7f72\u65f6\u9762\u4e34\u91cd\u5927\u6311\u6218,\u4e3b\u8981\u662f\u96be\u4ee5\u5f62\u6210\u548c\u7ef4\u6301\u7a33\u5065\u7684\u7a7a\u95f4\u5fc3\u667a\u6a21\u578b\u3002\u7814\u7a76\u8005\u8bc6\u522b\u51fa\u4e09\u4e2a\u6838\u5fc3\u8ba4\u77e5\u6311\u6218:\u7a7a\u95f4\u63a8\u7406\u3001\u901a\u8fc7\u5fc3\u667a\u6a21\u62df\u8fdb\u884c\u957f\u671f\u72b6\u6001\u8ddf\u8e2a\u3001\u4ee5\u53ca\u5728\u90e8\u5206\u89c2\u5bdf\u6761\u4ef6\u4e0b\u7684\u4e3b\u52a8\u63a2\u7d22\u3002\u4e3a\u4e86\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u548c\u9694\u79bb\u8fd9\u4e9b\u80fd\u529b,\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u63d0\u51faCubeBench\u57fa\u51c6\u6d4b\u8bd5,\u4ee5\u9b54\u65b9\u4e3a\u4e2d\u5fc3\u8bbe\u8ba1\u751f\u6210\u5f0f\u8bc4\u4f30\u4efb\u52a1\u3002\u91c7\u7528\u4e09\u5c42\u8bca\u65ad\u6846\u67b6,\u9010\u6b65\u8bc4\u4f30\u667a\u80fd\u4f53\u80fd\u529b:\u4ece\u5177\u6709\u5b8c\u6574\u7b26\u53f7\u4fe1\u606f\u7684\u57fa\u7840\u72b6\u6001\u8ddf\u8e2a,\u5230\u4ec5\u6709\u90e8\u5206\u89c6\u89c9\u6570\u636e\u7684\u4e3b\u52a8\u63a2\u7d22\u3002\u6b64\u5916,\u8fd8\u63d0\u51fa\u4e86\u8bca\u65ad\u6846\u67b6,\u901a\u8fc7\u63d0\u4f9b\u5916\u90e8\u6c42\u89e3\u5668\u5de5\u5177\u6765\u9694\u79bb\u8ba4\u77e5\u74f6\u9888,\u5e76\u5bf9\u5931\u8d25\u6a21\u5f0f\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5bf9\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u5173\u952e\u5c40\u9650\u6027:\u6240\u6709\u957f\u671f\u4efb\u52a1\u7684\u901a\u8fc7\u7387\u5747\u4e3a0.00%,\u66b4\u9732\u4e86LLM\u5728\u957f\u671f\u89c4\u5212\u65b9\u9762\u7684\u6839\u672c\u6027\u5931\u8d25\u3002\u901a\u8fc7\u5931\u8d25\u6a21\u5f0f\u5206\u6790,\u8bc6\u522b\u51fa\u5177\u4f53\u7684\u8ba4\u77e5\u74f6\u9888,\u4e3a\u7406\u89e3\u5f53\u524dLLM\u5728\u7269\u7406\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u4e0d\u8db3\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u7269\u7406\u4e16\u754c\u7684\u7a7a\u95f4\u8ba4\u77e5\u548c\u957f\u671f\u89c4\u5212\u80fd\u529b\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3,\u7279\u522b\u662f\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u5b8c\u5168\u5931\u8d25\u3002\u901a\u8fc7CubeBench\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bca\u65ad\u6846\u67b6,\u672c\u7814\u7a76\u7cfb\u7edf\u6027\u5730\u63ed\u793a\u4e86\u8fd9\u4e9b\u8ba4\u77e5\u74f6\u9888,\u4e3a\u5f00\u53d1\u66f4\u5177\u7269\u7406\u57fa\u7840\u3001\u80fd\u591f\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u6709\u6548\u8fd0\u4f5c\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u5173\u952e\u6d1e\u5bdf\u548c\u6307\u5bfc\u65b9\u5411\u3002"}}
{"id": "2512.23412", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23412", "abs": "https://arxiv.org/abs/2512.23412", "authors": ["Jiawei Chen", "Xintian Shen", "Lihao Zheng", "Zhenwei Shao", "Hongyuan Zhang", "Pengfei Yu", "Xudong Rao", "Ning Mao", "Xiaobo Liu", "Lian Wen", "Chaoqun Du", "Feng Gu", "Wei He", "Qizhen Li", "Shanshan Li", "Zide Liu", "Jing Luo", "Lifu Mu", "Xuhao Pan", "Chang Ren", "Haoyi Sun", "Qian Wang", "Wei Wang", "Hongfu Yang", "Jiqing Zhan", "Chunpeng Zhou", "Zheng Zhou", "Hao Ma", "Tao Wei", "Pan Zhou", "Wei Chen"], "title": "MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning", "comment": "Technique Report", "summary": "Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and multimodal chain-of-thought (CoT) reasoning. MindWatcher can autonomously decide whether and how to invoke diverse tools and coordinate their use, without relying on human prompts or workflows. The interleaved thinking paradigm enables the model to switch between thinking and tool calling at any intermediate stage, while its multimodal CoT capability allows manipulation of images during reasoning to yield more precise search results. We implement automated data auditing and evaluation pipelines, complemented by manually curated high-quality datasets for training, and we construct a benchmark, called MindWatcher-Evaluate Bench (MWE-Bench), to evaluate its performance. MindWatcher is equipped with a comprehensive suite of auxiliary reasoning tools, enabling it to address broad-domain multimodal problems. A large-scale, high-quality local image retrieval database, covering eight categories including cars, animals, and plants, endows model with robust object recognition despite its small size. Finally, we design a more efficient training infrastructure for MindWatcher, enhancing training speed and hardware utilization. Experiments not only demonstrate that MindWatcher matches or exceeds the performance of larger or more recent models through superior tool invocation, but also uncover critical insights for agent training, such as the genetic inheritance phenomenon in agentic RL.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MindWatcher\uff0c\u4e00\u4e2a\u96c6\u6210\u4ea4\u9519\u601d\u7ef4\u548c\u591a\u6a21\u6001\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u5de5\u5177\u96c6\u6210\u63a8\u7406(TIR)\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u81ea\u4e3b\u51b3\u7b56\u5de5\u5177\u8c03\u7528\u5e76\u534f\u8c03\u4f7f\u7528\uff0c\u65e0\u9700\u4eba\u5de5\u63d0\u793a\u6216\u5de5\u4f5c\u6d41\u3002\u901a\u8fc7\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u8bad\u7ec3\u3001\u4e13\u7528\u8bc4\u4f30\u57fa\u51c6\u548c\u9ad8\u6548\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\uff0cMindWatcher\u5728\u6027\u80fd\u4e0a\u5339\u654c\u6216\u8d85\u8d8a\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7684\u667a\u80fd\u4f53\u5728\u5904\u7406\u9700\u8981\u5de5\u5177\u8c03\u7528\u7684\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u65f6\u8868\u73b0\u51fa\u6709\u9650\u7684\u667a\u80fd\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u63d0\u793a\u6216\u9884\u5b9a\u4e49\u5de5\u4f5c\u6d41\uff0c\u7f3a\u4e4f\u81ea\u4e3b\u63a8\u7406\u548c\u7075\u6d3b\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u4e3b\u8fdb\u884c\u591a\u6b65\u63a8\u7406\u3001\u52a8\u6001\u51b3\u7b56\u5de5\u5177\u4f7f\u7528\uff0c\u5e76\u5904\u7406\u591a\u6a21\u6001\u4fe1\u606f\uff08\u7279\u522b\u662f\u56fe\u50cf\uff09\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "method": "\u63d0\u51faMindWatcher\u667a\u80fd\u4f53\uff0c\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a(1)\u4ea4\u9519\u601d\u7ef4\u8303\u5f0f\uff0c\u4f7f\u6a21\u578b\u80fd\u5728\u4efb\u610f\u4e2d\u95f4\u9636\u6bb5\u5728\u601d\u8003\u548c\u5de5\u5177\u8c03\u7528\u4e4b\u95f4\u5207\u6362\uff1b(2)\u591a\u6a21\u6001\u601d\u7ef4\u94fe(CoT)\u63a8\u7406\u80fd\u529b\uff0c\u652f\u6301\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u56fe\u50cf\u64cd\u4f5c\u4ee5\u83b7\u5f97\u66f4\u7cbe\u786e\u7684\u641c\u7d22\u7ed3\u679c\uff1b(3)\u81ea\u52a8\u5316\u6570\u636e\u5ba1\u6838\u548c\u8bc4\u4f30\u7ba1\u9053\uff0c\u7ed3\u5408\u4eba\u5de5\u7b56\u5212\u7684\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u96c6\uff1b(4)\u6784\u5efaMWE-Bench\u8bc4\u4f30\u57fa\u51c6\uff1b(5)\u914d\u5907\u5168\u9762\u7684\u8f85\u52a9\u63a8\u7406\u5de5\u5177\u5957\u4ef6\uff1b(6)\u5efa\u7acb\u6db5\u76d6\u6c7d\u8f66\u3001\u52a8\u7269\u3001\u690d\u7269\u7b49\u516b\u4e2a\u7c7b\u522b\u7684\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u672c\u5730\u56fe\u50cf\u68c0\u7d22\u6570\u636e\u5e93\uff1b(7)\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\u4ee5\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u548c\u786c\u4ef6\u5229\u7528\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMindWatcher\u901a\u8fc7\u5353\u8d8a\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff0c\u5728\u6027\u80fd\u4e0a\u5339\u654c\u6216\u8d85\u8d8a\u66f4\u5927\u89c4\u6a21\u6216\u66f4\u65b0\u7684\u6a21\u578b\u3002\u5c3d\u7ba1\u6a21\u578b\u89c4\u6a21\u8f83\u5c0f\uff0c\u4f46\u51ed\u501f\u5f3a\u5927\u7684\u672c\u5730\u56fe\u50cf\u68c0\u7d22\u6570\u636e\u5e93\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u7269\u4f53\u8bc6\u522b\u80fd\u529b\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u667a\u80fd\u4f53\u8bad\u7ec3\u7684\u5173\u952e\u6d1e\u5bdf\uff0c\u5982\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9057\u4f20\u7ee7\u627f\u73b0\u8c61\u3002", "conclusion": "MindWatcher\u6210\u529f\u5c55\u793a\u4e86\u96c6\u6210\u4ea4\u9519\u601d\u7ef4\u548c\u591a\u6a21\u6001\u63a8\u7406\u7684\u5de5\u5177\u96c6\u6210\u63a8\u7406\u667a\u80fd\u4f53\u7684\u6709\u6548\u6027\u3002\u901a\u8fc7\u81ea\u4e3b\u5de5\u5177\u8c03\u7528\u548c\u534f\u8c03\u80fd\u529b\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u5e7f\u6cdb\u9886\u57df\u7684\u591a\u6a21\u6001\u590d\u6742\u51b3\u7b56\u4efb\u52a1\u3002\u7814\u7a76\u8bc1\u660e\u4e86\u5373\u4f7f\u662f\u8f83\u5c0f\u89c4\u6a21\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u4f18\u79c0\u7684\u5de5\u5177\u96c6\u6210\u8bbe\u8ba1\u3001\u9ad8\u8d28\u91cf\u6570\u636e\u548c\u9ad8\u6548\u8bad\u7ec3\u57fa\u7840\u8bbe\u65bd\uff0c\u4e5f\u80fd\u8fbe\u5230\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.23424", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23424", "abs": "https://arxiv.org/abs/2512.23424", "authors": ["Jinye Du", "Quan Yuan", "Zuyao Zhang", "Yanzhi Yi", "Jiahui Hu", "Wangyi Chen", "Yiyang Zhu", "Qishui Zheng", "Wenxiang Zou", "Xiangyu Chang", "Zuohe Zheng", "Zichun Ye", "Chao Liu", "Shanni Li", "Renwei Zhang", "Yiping Deng", "Xinwei Hu", "Xuefeng Jin", "Jie Zhao"], "title": "AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis", "comment": null, "summary": "Modern AI models demand high-performance computation kernels. The growing complexity of LLMs, multimodal architectures, and recommendation systems, combined with techniques like sparsity and quantization, creates significant computational challenges. Moreover, frequent hardware updates and diverse chip architectures further complicate this landscape, requiring tailored kernel implementations for each platform. However, manual optimization cannot keep pace with these demands, creating a critical bottleneck in AI system development. Recent advances in LLM code generation capabilities have opened new possibilities for automating kernel development. In this work, we propose AKG kernel agent (AI-driven Kernel Generator), a multi-agent system that automates kernel generation, migration, and performance tuning. AKG kernel agent is designed to support multiple domain-specific languages (DSLs), including Triton, TileLang, CPP, and CUDA-C, enabling it to target different hardware backends while maintaining correctness and portability. The system's modular design allows rapid integration of new DSLs and hardware targets. When evaluated on KernelBench using Triton DSL across GPU and NPU backends, AKG kernel agent achieves an average speedup of 1.46$\\times$ over PyTorch Eager baselines implementations, demonstrating its effectiveness in accelerating kernel development for modern AI workloads.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AKG kernel agent(AI\u9a71\u52a8\u7684\u5185\u6838\u751f\u6210\u5668),\u8fd9\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf,\u80fd\u591f\u81ea\u52a8\u5316\u751f\u6210\u3001\u8fc1\u79fb\u548c\u6027\u80fd\u8c03\u4f18AI\u8ba1\u7b97\u5185\u6838,\u652f\u6301\u591a\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00(DSL),\u5728KernelBench\u8bc4\u4f30\u4e2d\u76f8\u6bd4PyTorch Eager\u57fa\u7ebf\u5b9e\u73b0\u5e73\u5747\u52a0\u901f1.46\u500d\u3002", "motivation": "\u73b0\u4ee3AI\u6a21\u578b(\u5982\u5927\u8bed\u8a00\u6a21\u578b\u3001\u591a\u6a21\u6001\u67b6\u6784\u3001\u63a8\u8350\u7cfb\u7edf)\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u5185\u6838\u9700\u6c42\u65e5\u76ca\u589e\u957f,\u7ed3\u5408\u7a00\u758f\u6027\u548c\u91cf\u5316\u7b49\u6280\u672f\u5e26\u6765\u5de8\u5927\u8ba1\u7b97\u6311\u6218\u3002\u9891\u7e41\u7684\u786c\u4ef6\u66f4\u65b0\u548c\u591a\u6837\u5316\u7684\u82af\u7247\u67b6\u6784\u8981\u6c42\u4e3a\u6bcf\u4e2a\u5e73\u53f0\u5b9a\u5236\u5185\u6838\u5b9e\u73b0,\u800c\u4eba\u5de5\u4f18\u5316\u65e0\u6cd5\u8ddf\u4e0a\u8fd9\u4e9b\u9700\u6c42,\u6210\u4e3aAI\u7cfb\u7edf\u5f00\u53d1\u7684\u5173\u952e\u74f6\u9888\u3002\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u8fdb\u6b65\u4e3a\u81ea\u52a8\u5316\u5185\u6838\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002", "method": "\u63d0\u51faAKG kernel agent\u591a\u667a\u80fd\u4f53\u7cfb\u7edf,\u7528\u4e8e\u81ea\u52a8\u5316\u5185\u6838\u751f\u6210\u3001\u8fc1\u79fb\u548c\u6027\u80fd\u8c03\u4f18\u3002\u7cfb\u7edf\u652f\u6301\u591a\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00(DSL),\u5305\u62ecTriton\u3001TileLang\u3001CPP\u548cCUDA-C,\u80fd\u591f\u9488\u5bf9\u4e0d\u540c\u786c\u4ef6\u540e\u7aef\u4fdd\u6301\u6b63\u786e\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1,\u5141\u8bb8\u5feb\u901f\u96c6\u6210\u65b0\u7684DSL\u548c\u786c\u4ef6\u76ee\u6807\u3002", "result": "\u5728KernelBench\u4e0a\u4f7f\u7528Triton DSL\u5bf9GPU\u548cNPU\u540e\u7aef\u8fdb\u884c\u8bc4\u4f30,AKG kernel agent\u76f8\u6bd4PyTorch Eager\u57fa\u7ebf\u5b9e\u73b0\u5e73\u5747\u5b9e\u73b0\u4e861.46\u500d\u7684\u52a0\u901f,\u8bc1\u660e\u4e86\u5176\u5728\u52a0\u901f\u73b0\u4ee3AI\u5de5\u4f5c\u8d1f\u8f7d\u5185\u6838\u5f00\u53d1\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "AKG kernel agent\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u591aDSL\u652f\u6301,\u6709\u6548\u89e3\u51b3\u4e86AI\u8ba1\u7b97\u5185\u6838\u5f00\u53d1\u4e2d\u7684\u81ea\u52a8\u5316\u96be\u9898,\u5728\u4fdd\u8bc1\u6b63\u786e\u6027\u548c\u53ef\u79fb\u690d\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347,\u4e3a\u5e94\u5bf9\u5feb\u901f\u6f14\u8fdb\u7684AI\u786c\u4ef6\u548c\u6a21\u578b\u67b6\u6784\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.23457", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23457", "abs": "https://arxiv.org/abs/2512.23457", "authors": ["Kongcheng Zhang", "Qi Yao", "Shunyu Liu", "Wenjian Zhang", "Min Cen", "Yang Zhou", "Wenkai Fang", "Yiru Zhao", "Baisheng Lai", "Mingli Song"], "title": "Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following", "comment": null, "summary": "Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.23508", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.23508", "abs": "https://arxiv.org/abs/2512.23508", "authors": ["Alessio Benavoli", "Alessandro Facchini", "Marco Zaffalon"], "title": "Why AI Safety Requires Uncertainty, Incomplete Preferences, and Non-Archimedean Utilities", "comment": null, "summary": "How can we ensure that AI systems are aligned with human values and remain safe? We can study this problem through the frameworks of the AI assistance and the AI shutdown games. The AI assistance problem concerns designing an AI agent that helps a human to maximise their utility function(s). However, only the human knows these function(s); the AI assistant must learn them. The shutdown problem instead concerns designing AI agents that: shut down when a shutdown button is pressed; neither try to prevent nor cause the pressing of the shutdown button; and otherwise accomplish their task competently. In this paper, we show that addressing these challenges requires AI agents that can reason under uncertainty and handle both incomplete and non-Archimedean preferences.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.23601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23601", "abs": "https://arxiv.org/abs/2512.23601", "authors": ["Manh Hung Nguyen", "Adish Singla"], "title": "Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation", "comment": "Preprint", "summary": "Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind'' effect, where they generate similar responses within the same model and produce homogeneous outputs across different models. As a consequence, students may be exposed to overly similar and repetitive LLM-generated problems, which harms diversity of thought. Drawing inspiration from Wallas's theory of creativity and Guilford's framework of divergent-convergent thinking, we propose CreativeDC, a two-phase prompting method that explicitly scaffolds the LLM's reasoning into distinct phases. By decoupling creative exploration from constraint satisfaction, our method enables LLMs to explore a broader space of ideas before committing to a final problem. We evaluate CreativeDC for creative problem generation using a comprehensive set of metrics that capture diversity, novelty, and utility. The results show that CreativeDC achieves significantly higher diversity and novelty compared to baselines while maintaining high utility. Moreover, scaling analysis shows that CreativeDC generates a larger effective number of distinct problems as more are sampled, increasing at a faster rate than baseline methods.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.23624", "categories": ["cs.AI", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.23624", "abs": "https://arxiv.org/abs/2512.23624", "authors": ["Chien-Ting Tung", "Chenming Hu"], "title": "Physics-Informed Neural Networks for Device and Circuit Modeling: A Case Study of NeuroSPICE", "comment": "Submitted to IEEE Electron Device Letters", "summary": "We present NeuroSPICE, a physics-informed neural network (PINN) framework for device and circuit simulation. Unlike conventional SPICE, which relies on time-discretized numerical solvers, NeuroSPICE leverages PINNs to solve circuit differential-algebraic equations (DAEs) by minimizing the residual of the equations through backpropagation. It models device and circuit waveforms using analytical equations in time domain with exact temporal derivatives. While PINNs do not outperform SPICE in speed or accuracy during training, they offer unique advantages such as surrogate models for design optimization and inverse problems. NeuroSPICE's flexibility enables the simulation of emerging devices, including highly nonlinear systems such as ferroelectric memories.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.23626", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23626", "abs": "https://arxiv.org/abs/2512.23626", "authors": ["Federico Baldo", "Charles K. Assaad"], "title": "Regret-Based Federated Causal Discovery with Unknown Interventions", "comment": null, "summary": "Most causal discovery methods recover a completed partially directed acyclic graph representing a Markov equivalence class from observational data. Recent work has extended these methods to federated settings to address data decentralization and privacy constraints, but often under idealized assumptions that all clients share the same causal model. Such assumptions are unrealistic in practice, as client-specific policies or protocols, for example, across hospitals, naturally induce heterogeneous and unknown interventions. In this work, we address federated causal discovery under unknown client-level interventions. We propose I-PERI, a novel federated algorithm that first recovers the CPDAG of the union of client graphs and then orients additional edges by exploiting structural differences induced by interventions across clients. This yields a tighter equivalence class, which we call the $\\mathbf\u03a6$-Markov Equivalence Class, represented by the $\\mathbf\u03a6$-CPDAG. We provide theoretical guarantees on the convergence of I-PERI, as well as on its privacy-preserving properties, and present empirical evaluations on synthetic data demonstrating the effectiveness of the proposed algorithm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86I-PERI\u7b97\u6cd5,\u7528\u4e8e\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u5904\u7406\u5ba2\u6237\u7aef\u7ea7\u522b\u672a\u77e5\u5e72\u9884\u7684\u56e0\u679c\u53d1\u73b0\u95ee\u9898,\u901a\u8fc7\u6062\u590d\u5ba2\u6237\u7aef\u56fe\u7684\u5e76\u96c6CPDAG\u5e76\u5229\u7528\u5e72\u9884\u5f15\u8d77\u7684\u7ed3\u6784\u5dee\u5f02\u6765\u5b9a\u5411\u66f4\u591a\u8fb9,\u4ece\u800c\u83b7\u5f97\u66f4\u7d27\u7684\u7b49\u4ef7\u7c7b\u03a6-Markov\u7b49\u4ef7\u7c7b", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6240\u6709\u5ba2\u6237\u7aef\u5171\u4eab\u76f8\u540c\u7684\u56e0\u679c\u6a21\u578b,\u4f46\u8fd9\u5728\u5b9e\u8df5\u4e2d\u5e76\u4e0d\u73b0\u5b9e\u3002\u4e0d\u540c\u5ba2\u6237\u7aef(\u5982\u4e0d\u540c\u533b\u9662)\u7531\u4e8e\u7279\u5b9a\u7684\u653f\u7b56\u6216\u534f\u8bae,\u81ea\u7136\u4f1a\u4ea7\u751f\u5f02\u6784\u4e14\u672a\u77e5\u7684\u5e72\u9884\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u5ba2\u6237\u7aef\u7ea7\u522b\u672a\u77e5\u5e72\u9884\u7684\u8054\u90a6\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5,\u4ee5\u5e94\u5bf9\u6570\u636e\u53bb\u4e2d\u5fc3\u5316\u3001\u9690\u79c1\u7ea6\u675f\u548c\u6a21\u578b\u5f02\u6784\u6027\u7684\u6311\u6218", "method": "\u63d0\u51faI-PERI\u7b97\u6cd5,\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u8054\u90a6\u7b97\u6cd5,\u5206\u4e24\u6b65\u8fdb\u884c:(1)\u9996\u5148\u6062\u590d\u5ba2\u6237\u7aef\u56fe\u5e76\u96c6\u7684CPDAG(\u5b8c\u6210\u90e8\u5206\u6709\u5411\u65e0\u73af\u56fe);(2)\u7136\u540e\u901a\u8fc7\u5229\u7528\u4e0d\u540c\u5ba2\u6237\u7aef\u95f4\u5e72\u9884\u5f15\u8d77\u7684\u7ed3\u6784\u5dee\u5f02\u6765\u5b9a\u5411\u989d\u5916\u7684\u8fb9\u3002\u8fd9\u4ea7\u751f\u4e86\u4e00\u4e2a\u66f4\u7d27\u7684\u7b49\u4ef7\u7c7b,\u79f0\u4e3a\u03a6-Markov\u7b49\u4ef7\u7c7b,\u7531\u03a6-CPDAG\u8868\u793a", "result": "\u4e3aI-PERI\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6536\u655b\u6027\u7684\u7406\u8bba\u4fdd\u8bc1\u4ee5\u53ca\u9690\u79c1\u4fdd\u62a4\u7279\u6027\u7684\u7406\u8bba\u8bc1\u660e\u3002\u5728\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e,\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u662f\u6709\u6548\u7684,\u80fd\u591f\u5728\u8054\u90a6\u8bbe\u7f6e\u4e0b\u5904\u7406\u672a\u77e5\u5ba2\u6237\u7aef\u7ea7\u522b\u5e72\u9884\u7684\u56e0\u679c\u53d1\u73b0\u95ee\u9898", "conclusion": "I-PERI\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u8054\u90a6\u56e0\u679c\u53d1\u73b0\u4e2d\u5ba2\u6237\u7aef\u5f02\u6784\u5e72\u9884\u7684\u95ee\u9898,\u901a\u8fc7\u5229\u7528\u5e72\u9884\u5f15\u8d77\u7684\u7ed3\u6784\u5dee\u5f02\u83b7\u5f97\u4e86\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u7d27\u7684\u7b49\u4ef7\u7c7b(\u03a6-Markov\u7b49\u4ef7\u7c7b),\u540c\u65f6\u4fdd\u8bc1\u4e86\u7b97\u6cd5\u7684\u6536\u655b\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u7279\u6027,\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8054\u90a6\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u548c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.23676", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.23676", "abs": "https://arxiv.org/abs/2512.23676", "authors": ["Jichen Feng", "Yifan Zhang", "Chenggong Zhang", "Yifu Lu", "Shilong Liu", "Mengdi Wang"], "title": "Web World Models", "comment": "Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models", "summary": "Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics'' are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
